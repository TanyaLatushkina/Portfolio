{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927f56a1",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Первичный-анализ\" data-toc-modified-id=\"Первичный-анализ-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Первичный анализ</a></span></li><li><span><a href=\"#Подготовим-данные-для-обучения\" data-toc-modified-id=\"Подготовим-данные-для-обучения-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовим данные для обучения</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подготовим-таргет\" data-toc-modified-id=\"Подготовим-таргет-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Подготовим таргет</a></span></li><li><span><a href=\"#Подготовим-тренировочны-датасет\" data-toc-modified-id=\"Подготовим-тренировочны-датасет-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Подготовим тренировочны датасет</a></span><ul class=\"toc-item\"><li><span><a href=\"#Соединим-датафреймы-и-добавим-таргет.\" data-toc-modified-id=\"Соединим-датафреймы-и-добавим-таргет.-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Соединим датафреймы и добавим таргет.</a></span></li><li><span><a href=\"#Проверим-дубликаты\" data-toc-modified-id=\"Проверим-дубликаты-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Проверим дубликаты</a></span></li><li><span><a href=\"#Очистим-текст\" data-toc-modified-id=\"Очистим-текст-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Очистим текст</a></span></li><li><span><a href=\"#Разделим-выборку-на-тренировочную-и-валидационную\" data-toc-modified-id=\"Разделим-выборку-на-тренировочную-и-валидационную-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Разделим выборку на тренировочную и валидационную</a></span></li></ul></li></ul></li><li><span><a href=\"#Подготовим-необходимые-классы-и-функции-для-обучения\" data-toc-modified-id=\"Подготовим-необходимые-классы-и-функции-для-обучения-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Подготовим необходимые классы и функции для обучения</a></span></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#CNN\" data-toc-modified-id=\"CNN-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>CNN</a></span></li><li><span><a href=\"#Bidirectional-LSTM\" data-toc-modified-id=\"Bidirectional-LSTM-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Bidirectional LSTM</a></span></li><li><span><a href=\"#LSTM-+-PackedSequence\" data-toc-modified-id=\"LSTM-+-PackedSequence-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>LSTM + PackedSequence</a></span></li></ul></li><li><span><a href=\"#Transformers-+-Bert\" data-toc-modified-id=\"Transformers-+-Bert-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Transformers + Bert</a></span></li><li><span><a href=\"#Итог\" data-toc-modified-id=\"Итог-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Итог</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407b9129",
   "metadata": {},
   "source": [
    "# Бинарная классификация задач Kuzovkin.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5bc47f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using \"CPU\" device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/tanya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# подгружаем библиотеки\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "#import optuna\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from wordcloud import WordCloud\n",
    "#from optuna.samplers import TPESampler\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM #AutoModel \n",
    "#from catboost import CatBoostClassifier\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, TensorDataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "\n",
    "nltk.download('stopwords') # поддерживает удаление стоп-слов\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Currently using \"{device.upper()}\" device.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7f922e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# константы\n",
    "SEED = 42\n",
    "\n",
    "model_name = 'cointegrated/LaBSE-en-ru'  # веса для обучения Bert\n",
    "df_task = '/Users/tanya/Documents/DS/Projects/Kuzovkin_info/data-1719430924811.csv' # путь в файлу с текстом задач\n",
    "df_topics = '/Users/tanya/Documents/DS/Projects/Kuzovkin_info/topics.csv' # путь к файлу со списком тем \n",
    "bert_embeddings = '/Users/tanya/Documents/DS/Projects/Kuzovkin_info/bert_embeddings.csv' # путь к эмбеддингам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0284d2",
   "metadata": {},
   "source": [
    "## Первичный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "314334d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# датасет с задачами\n",
    "\n",
    "try:\n",
    "    df_task = pd.read_csv(df_task)\n",
    "except Exception as ex: \n",
    "    print(ex)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbb08430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# датасет с иерархическим спиком\n",
    "\n",
    "try:\n",
    "    df_topics = pd.read_csv(df_topics)\n",
    "except Exception as ex: \n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2bef9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_info(data):\n",
    "    \n",
    "    '''\n",
    "    Функция для первичного изучения] датасета. Нав вход принимает сам датасет, \n",
    "    на выход получаем общую информацитю о датасете.\n",
    "    '''\n",
    "    \n",
    "    display(data.sample(10))\n",
    "    display(data.info())\n",
    "    print(data.duplicated().sum())\n",
    "    print('Количество записпей: ', data.shape[0], 'Количество столбцов: ', data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5b9b9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task</th>\n",
       "      <th>answer</th>\n",
       "      <th>topics_id</th>\n",
       "      <th>text_of_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29079</th>\n",
       "      <td>38810</td>\n",
       "      <td>Известно, что \\(\\Delta АВС = \\Delta А_{1}В_{1}С_{1}\\). Точки \\(D\\) и \\(Е\\) - середины сто­рон \\(АВ\\) и \\(ВС\\), а точки \\(D_{1}\\) и \\(E_{1}\\) - середины сторон \\(А_{1}В_{1}\\) и \\(B_{1}C_{1}\\) соответственно. Докажите, что \\(DЕ = D_{1}E_{1}\\).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12553</th>\n",
       "      <td>15142</td>\n",
       "      <td>Найдите наиболее рациональным способом значение выражения: ')0,6^{6} \\cdot 5^{6}\\)</td>\n",
       "      <td>729</td>\n",
       "      <td>121</td>\n",
       "      <td>\\(0,6^{6} \\cdot 5,6^{6} = (\\frac{3}{5} \\cdot 5)^{6} = 3^{6} = 729\\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682</th>\n",
       "      <td>28326</td>\n",
       "      <td>Нагрузка с сопротивлением \\(R\\), подключена к двум параллельно включенным батареям. Батареи имеют ЭДС \\(E_{1}\\) и \\(E_{2}\\) и внутренние сопротивления \\(r_{1}\\) и \\(r_{2}\\). Определить токи, идущие через сопротивления \\(r_{1}\\), \\(r_{2}\\), \\(R\\) и параметры (ЭДС и внутреннее сопротивление) источника, на который можно заменить батареи без изменения тока на нагрузке.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389</td>\n",
       "      <td>Ток через нагрузку I = E/R0, токи через батареи и параметры эквивалентного источника при соединении одноименных клемм батарей: \\(I_{1}=\\frac{|E_{1}(r_{2}+R)|}{(r_{1}+r_{2})R_{0}}\\), \\(I_{2}=\\frac{|E_{2}(r_{1}+R)|}{(r_{1}+r_{2})R_{0}}\\), \\(E=\\frac{E_{1}r_{2}+E_{2}r_{1}}{r_{1}+r_{2}}\\), \\(r=\\frac{r_{1}r_{2}}{r_{1}+r_{2}}\\), где \\(R_{0}=r+R\\); токи через батареи и параметры эквивалентного о источника при соединении разноименных клемм батарей: \\(I_{1}=\\frac{E_{1}(r_{2}+R)+E_{2}R}{R_{0}(r_{1}+r_{2})}\\), \\(I_{2}=\\frac{E_{2}(r_{1}+R)+E_{1}R}{R_{0}(r_{1}+r_{2})}\\), \\(E=\\frac{E_{1}r_{2}-E_{2}r_{1}}{r_{1}+r_{2}}\\), \\(r=\\frac{r_{1}r_{2}}{r_{1}+r_{2}}\\), где \\(R_{0}=r+R\\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29746</th>\n",
       "      <td>43108</td>\n",
       "      <td>Вычислите скорость изменения функции в точке \\(x_0\\): \\(y=\\sqrt{4x^2-20x+25}\\),\\(x_0=3\\).</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18882</th>\n",
       "      <td>40362</td>\n",
       "      <td>Расположите в системе координат пря­моугольную трапецию с основаниями \\(a\\) и \\(b\\) (\\(a &lt; b\\)) и высотой \\(h\\) так, чтобы две стороны трапеции лежали на осях координат. Определите координаты вершин трапеции.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29866</th>\n",
       "      <td>43477</td>\n",
       "      <td>Используя данные о производной \\(y=f'(x)\\), приведенные в таблице, укажите: точки максимума функции\\(y=f(x)\\).&lt;br&gt; &lt;img src='https://hot_data_kuzovkin_info_private.hb.ru-msk.vkcs.cloud/picture_to_tasks/math/mordkovich_10_11/рисунок: таблица 1.png'&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29013</th>\n",
       "      <td>38611</td>\n",
       "      <td>Стороны \\(АЕ\\) и \\(ВС\\) выпуклого пятиугольника \\(ABCDE\\), вписанного в окружность, параллельны. Прямые \\(ВС\\) и \\(DE\\) пересекаются в точке \\(К\\). Докажите, что \\(DK \\cdot DA = DC \\cdot DB\\).</td>\n",
       "      <td>Утверджение доказано.</td>\n",
       "      <td>505</td>\n",
       "      <td>Рассмотрите точку \\(L\\), в которой пересенаются прямые \\(АЕ\\) и \\(CD\\). Пусть градусные меры дуг \\(ВС\\), \\(CD\\), \\(DE\\) и \\(EA\\) равны \\(2\\alpha_{1}\\), (2\\alpha_{2}\\), (2\\beta_{2}\\) и (2\\beta_{1}\\) (Рис. 259). Тогда \\(\\angle DAB = \\alpha_{1} + \\alpha_{2}\\). Градусная мера дуги \\(АВ\\) равна 2(\\alpha_{2} + \\beta_{2})\\), поэтому \\(\\angle DCK = \\angle DLE = 2(\\alpha_{w} + \\beta_{2}) + 2\\alpha_{2} - 2\\beta_{2} = \\angle DAB\\). Аналогично \\(\\angle DEL = \\angle DBA\\). Следовательно, \\(\\Delta DAB \\backsim \\Delta DCK\\).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37018</th>\n",
       "      <td>29556</td>\n",
       "      <td>В результате трения о шелк стеклянной палочке был сообщен положительный заряд. Все ли атомы, из которых состоит заряженная стеклянная палочка, нейтральны? Изменилась ли масса стеклянной палочки после сообщения ей положительного заряда? Обоснуйте свой ответ.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41980</th>\n",
       "      <td>49870</td>\n",
       "      <td>На ребрах \\(CD\\) и \\(DD_{1}\\) куба \\(ABCDA_{1}B_{1}C_{1}D_{1}\\) взяты соответственно точки \\(P\\) и \\(D_{2}\\) - середины этих ребер. Постройте развертки многогранников \\(U\\left ( C \\right )\\), отсеченных от куба плоскостями, перпендикулярными прямой \\(A_{1}C\\) и проходящими через следующие точки: а)\\(C_{1}\\); б)\\(P\\); в)\\(D_{2}\\). Склейте модели многогранников \\(U\\left ( C \\right )\\).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>653</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30069</th>\n",
       "      <td>44169</td>\n",
       "      <td>Докажите, что плоскость, проходящая через середины ребер \\(AB\\),\\(AC\\) и \\(AD\\) тетраэдра \\(ABCD\\), параллельна плоскости \\(BCD\\).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>567</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "29079  38810   \n",
       "12553  15142   \n",
       "15682  28326   \n",
       "29746  43108   \n",
       "18882  40362   \n",
       "29866  43477   \n",
       "29013  38611   \n",
       "37018  29556   \n",
       "41980  49870   \n",
       "30069  44169   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                     task  \\\n",
       "29079                                                                                                                                                   Известно, что \\(\\Delta АВС = \\Delta А_{1}В_{1}С_{1}\\). Точки \\(D\\) и \\(Е\\) - середины сто­рон \\(АВ\\) и \\(ВС\\), а точки \\(D_{1}\\) и \\(E_{1}\\) - середины сторон \\(А_{1}В_{1}\\) и \\(B_{1}C_{1}\\) соответственно. Докажите, что \\(DЕ = D_{1}E_{1}\\).   \n",
       "12553                                                                                                                                                                                                                                                                                                                  Найдите наиболее рациональным способом значение выражения: ')0,6^{6} \\cdot 5^{6}\\)   \n",
       "15682                     Нагрузка с сопротивлением \\(R\\), подключена к двум параллельно включенным батареям. Батареи имеют ЭДС \\(E_{1}\\) и \\(E_{2}\\) и внутренние сопротивления \\(r_{1}\\) и \\(r_{2}\\). Определить токи, идущие через сопротивления \\(r_{1}\\), \\(r_{2}\\), \\(R\\) и параметры (ЭДС и внутреннее сопротивление) источника, на который можно заменить батареи без изменения тока на нагрузке.   \n",
       "29746                                                                                                                                                                                                                                                                                                           Вычислите скорость изменения функции в точке \\(x_0\\): \\(y=\\sqrt{4x^2-20x+25}\\),\\(x_0=3\\).   \n",
       "18882                                                                                                                                                                                    Расположите в системе координат пря­моугольную трапецию с основаниями \\(a\\) и \\(b\\) (\\(a < b\\)) и высотой \\(h\\) так, чтобы две стороны трапеции лежали на осях координат. Определите координаты вершин трапеции.   \n",
       "29866                                                                                                                                            Используя данные о производной \\(y=f'(x)\\), приведенные в таблице, укажите: точки максимума функции\\(y=f(x)\\).<br> <img src='https://hot_data_kuzovkin_info_private.hb.ru-msk.vkcs.cloud/picture_to_tasks/math/mordkovich_10_11/рисунок: таблица 1.png'>   \n",
       "29013                                                                                                                                                                                                    Стороны \\(АЕ\\) и \\(ВС\\) выпуклого пятиугольника \\(ABCDE\\), вписанного в окружность, параллельны. Прямые \\(ВС\\) и \\(DE\\) пересекаются в точке \\(К\\). Докажите, что \\(DK \\cdot DA = DC \\cdot DB\\).   \n",
       "37018                                                                                                                                   В результате трения о шелк стеклянной палочке был сообщен положительный заряд. Все ли атомы, из которых состоит заряженная стеклянная палочка, нейтральны? Изменилась ли масса стеклянной палочки после сообщения ей положительного заряда? Обоснуйте свой ответ.   \n",
       "41980  На ребрах \\(CD\\) и \\(DD_{1}\\) куба \\(ABCDA_{1}B_{1}C_{1}D_{1}\\) взяты соответственно точки \\(P\\) и \\(D_{2}\\) - середины этих ребер. Постройте развертки многогранников \\(U\\left ( C \\right )\\), отсеченных от куба плоскостями, перпендикулярными прямой \\(A_{1}C\\) и проходящими через следующие точки: а)\\(C_{1}\\); б)\\(P\\); в)\\(D_{2}\\). Склейте модели многогранников \\(U\\left ( C \\right )\\).   \n",
       "30069                                                                                                                                                                                                                                                                  Докажите, что плоскость, проходящая через середины ребер \\(AB\\),\\(AC\\) и \\(AD\\) тетраэдра \\(ABCD\\), параллельна плоскости \\(BCD\\).   \n",
       "\n",
       "                      answer  topics_id  \\\n",
       "29079                    NaN        160   \n",
       "12553                    729        121   \n",
       "15682                    NaN        389   \n",
       "29746                      2        104   \n",
       "18882                    NaN        502   \n",
       "29866                    NaN        111   \n",
       "29013  Утверджение доказано.        505   \n",
       "37018                    NaN        400   \n",
       "41980                    NaN        653   \n",
       "30069                    NaN        567   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text_of_solution  \n",
       "29079                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN  \n",
       "12553                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \\(0,6^{6} \\cdot 5,6^{6} = (\\frac{3}{5} \\cdot 5)^{6} = 3^{6} = 729\\)  \n",
       "15682  Ток через нагрузку I = E/R0, токи через батареи и параметры эквивалентного источника при соединении одноименных клемм батарей: \\(I_{1}=\\frac{|E_{1}(r_{2}+R)|}{(r_{1}+r_{2})R_{0}}\\), \\(I_{2}=\\frac{|E_{2}(r_{1}+R)|}{(r_{1}+r_{2})R_{0}}\\), \\(E=\\frac{E_{1}r_{2}+E_{2}r_{1}}{r_{1}+r_{2}}\\), \\(r=\\frac{r_{1}r_{2}}{r_{1}+r_{2}}\\), где \\(R_{0}=r+R\\); токи через батареи и параметры эквивалентного о источника при соединении разноименных клемм батарей: \\(I_{1}=\\frac{E_{1}(r_{2}+R)+E_{2}R}{R_{0}(r_{1}+r_{2})}\\), \\(I_{2}=\\frac{E_{2}(r_{1}+R)+E_{1}R}{R_{0}(r_{1}+r_{2})}\\), \\(E=\\frac{E_{1}r_{2}-E_{2}r_{1}}{r_{1}+r_{2}}\\), \\(r=\\frac{r_{1}r_{2}}{r_{1}+r_{2}}\\), где \\(R_{0}=r+R\\)  \n",
       "29746                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN  \n",
       "18882                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN  \n",
       "29866                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN  \n",
       "29013                                                                                                                                                          Рассмотрите точку \\(L\\), в которой пересенаются прямые \\(АЕ\\) и \\(CD\\). Пусть градусные меры дуг \\(ВС\\), \\(CD\\), \\(DE\\) и \\(EA\\) равны \\(2\\alpha_{1}\\), (2\\alpha_{2}\\), (2\\beta_{2}\\) и (2\\beta_{1}\\) (Рис. 259). Тогда \\(\\angle DAB = \\alpha_{1} + \\alpha_{2}\\). Градусная мера дуги \\(АВ\\) равна 2(\\alpha_{2} + \\beta_{2})\\), поэтому \\(\\angle DCK = \\angle DLE = 2(\\alpha_{w} + \\beta_{2}) + 2\\alpha_{2} - 2\\beta_{2} = \\angle DAB\\). Аналогично \\(\\angle DEL = \\angle DBA\\). Следовательно, \\(\\Delta DAB \\backsim \\Delta DCK\\).   \n",
       "37018                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN  \n",
       "41980                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN  \n",
       "30069                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42648 entries, 0 to 42647\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                42648 non-null  int64 \n",
      " 1   task              42648 non-null  object\n",
      " 2   answer            24048 non-null  object\n",
      " 3   topics_id         42648 non-null  int64 \n",
      " 4   text_of_solution  22678 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Количество записпей:  42648 Количество столбцов:  5\n"
     ]
    }
   ],
   "source": [
    "df_info(df_task) # общая информация о датасете с текстом задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ad90828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>parent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>80</td>\n",
       "      <td>Квадратный корень из двучлена вида A±√B. Формула сложного радикала</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>419</td>\n",
       "      <td>масса. плотность</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>395</td>\n",
       "      <td>Удельное сопротивление проводника</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>Решение тригонометрических неравенств</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>Куб суммы и куб разности</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>631</td>\n",
       "      <td>теорема Менелая</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>430</td>\n",
       "      <td>системы логарифмических неравенств</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>532</td>\n",
       "      <td>Простейшие задачи в координатах</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>Метод математической индукции</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>627</td>\n",
       "      <td>Параллельность прямых в пространстве</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                                                name  \\\n",
       "79    80  Квадратный корень из двучлена вида A±√B. Формула сложного радикала   \n",
       "418  419                                                    масса. плотность   \n",
       "394  395                                   Удельное сопротивление проводника   \n",
       "261  262                               Решение тригонометрических неравенств   \n",
       "135  136                                            Куб суммы и куб разности   \n",
       "630  631                                                     теорема Менелая   \n",
       "429  430                                  системы логарифмических неравенств   \n",
       "531  532                                     Простейшие задачи в координатах   \n",
       "47    48                                       Метод математической индукции   \n",
       "626  627                                Параллельность прямых в пространстве   \n",
       "\n",
       "     parent  \n",
       "79       70  \n",
       "418     418  \n",
       "394     385  \n",
       "261     256  \n",
       "135     128  \n",
       "630     485  \n",
       "429     425  \n",
       "531     502  \n",
       "47       46  \n",
       "626     564  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 688 entries, 0 to 687\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      688 non-null    int64 \n",
      " 1   name    688 non-null    object\n",
      " 2   parent  688 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 16.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Количество записпей:  688 Количество столбцов:  3\n"
     ]
    }
   ],
   "source": [
    "df_info(df_topics) # общая информация о датасете со списком тем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ea70f",
   "metadata": {},
   "source": [
    "__Вывод:__\n",
    "\n",
    "1) В df_task есть значительное количество пропусков в колонках answer и text_of_solution. Так как достоверно восстановить мы их не можем, нам придется удалить эти признаки.\n",
    "\n",
    "2) Сами тексты задач имеют специфическе символы (формулы, обозначения), русские и английские буквы. Необходимо подобрать такую модель трансформера, которая учитывала бы эти особенности.\n",
    "\n",
    "3) В df_topics у нас иерархический список, где у каждой темы есть id родителя. Необходимо разделить все темы на два класса Математика и Физика."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024e419",
   "metadata": {},
   "source": [
    "## Подготовим данные для обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3b77b",
   "metadata": {},
   "source": [
    "### Подготовим таргет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "358f5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# рекурсионная функция для классификации задач\n",
    "\n",
    "def get_parent_id(idx):\n",
    "    \n",
    "    '''\n",
    "    Функция на вход принимает индекс задачи, для которой нужно искать родителя. \n",
    "    На выходе получаем имя верхнегг родителя \n",
    "    '''\n",
    "    \n",
    "    row = df_topics.loc[df_topics.id == idx, :]\n",
    "    parent, name = row['parent'].values[0], row['name'].values[0]\n",
    "    if parent == 0:\n",
    "        return name\n",
    "    return get_parent_id(parent)\n",
    "\n",
    "def label_rows(df_topics):\n",
    "    \n",
    "    '''\n",
    "    Функция принимает на вход весь датафрейм.\n",
    "    На выходе получаем датафрейм с новой колонкой, где записаны родители верхнего уровня.\n",
    "    '''\n",
    "    \n",
    "    df_to_label = df_topics[df_topics['parent'] != 0]\n",
    "    for i in df_to_label['id'].unique():\n",
    "        name = get_parent_id(i)\n",
    "        df_topics.loc[df_topics.id == i, 'subject'] = name\n",
    "    df_topics.loc[df_topics.subject.isna(), 'subject'] = df_topics.loc[df_topics.subject.isna(), 'name'].values\n",
    "    return df_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "29238a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>parent</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Математика</td>\n",
       "      <td>0</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Арифметика и начала Алгебры</td>\n",
       "      <td>1</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Арифметика</td>\n",
       "      <td>2</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Натуральные числа</td>\n",
       "      <td>3</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cложение и вычитание натуральных чисел</td>\n",
       "      <td>4</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>684</td>\n",
       "      <td>теорема Пуассона</td>\n",
       "      <td>560</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>685</td>\n",
       "      <td>Первоначальные понятия математической статистики</td>\n",
       "      <td>560</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>686</td>\n",
       "      <td>Оценка вероятности по относительной частоте. Доверительный интервал</td>\n",
       "      <td>685</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>687</td>\n",
       "      <td>Оценка параметров в статистике</td>\n",
       "      <td>685</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>688</td>\n",
       "      <td>Плотность вероятности. Числовые характеристики непрерывных случайных величин</td>\n",
       "      <td>560</td>\n",
       "      <td>Математика</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  \\\n",
       "0      1   \n",
       "1      2   \n",
       "2      3   \n",
       "3      4   \n",
       "4      5   \n",
       "..   ...   \n",
       "683  684   \n",
       "684  685   \n",
       "685  686   \n",
       "686  687   \n",
       "687  688   \n",
       "\n",
       "                                                                             name  \\\n",
       "0                                                                      Математика   \n",
       "1                                                     Арифметика и начала Алгебры   \n",
       "2                                                                      Арифметика   \n",
       "3                                                               Натуральные числа   \n",
       "4                                          Cложение и вычитание натуральных чисел   \n",
       "..                                                                            ...   \n",
       "683                                                              теорема Пуассона   \n",
       "684                              Первоначальные понятия математической статистики   \n",
       "685           Оценка вероятности по относительной частоте. Доверительный интервал   \n",
       "686                                                Оценка параметров в статистике   \n",
       "687  Плотность вероятности. Числовые характеристики непрерывных случайных величин   \n",
       "\n",
       "     parent     subject  \n",
       "0         0  Математика  \n",
       "1         1  Математика  \n",
       "2         2  Математика  \n",
       "3         3  Математика  \n",
       "4         4  Математика  \n",
       "..      ...         ...  \n",
       "683     560  Математика  \n",
       "684     560  Математика  \n",
       "685     685  Математика  \n",
       "686     685  Математика  \n",
       "687     560  Математика  \n",
       "\n",
       "[688 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# применяем рекурсивнную функцию\n",
    "label_rows(df_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "721af0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# граффик баланса классов\n",
    "topics_counts = df_topics['subject'].value_counts()\n",
    "labels=topics_counts.index\n",
    "sns.set(font_scale = 1)\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.pie(\n",
    "    x=topics_counts, \n",
    "    labels=topics_counts.index,\n",
    "    autopct='%1.2f%%',\n",
    "    colors=sns.color_palette('Set2'),\n",
    "    startangle=90,\n",
    "    explode=[0, 0.12]\n",
    ")\n",
    "plt.title('Баланс класcов')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b2829",
   "metadata": {},
   "source": [
    "__Вывод:__ Задач по математики а два раза больше, зем задач по физике."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaa533d",
   "metadata": {},
   "source": [
    "### Подготовим тренировочны датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce9bfe",
   "metadata": {},
   "source": [
    "#### Соединим датафреймы и добавим таргет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "04ce98de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task</th>\n",
       "      <th>answer</th>\n",
       "      <th>topics_id</th>\n",
       "      <th>text_of_solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20218</th>\n",
       "      <td>46992</td>\n",
       "      <td>Постройте график функции: \\(y=cos(x+\\frac{\\pi}{6})\\).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17607</th>\n",
       "      <td>35921</td>\n",
       "      <td>По бизнес-плану предполагается вложить в четырёхлетний проект 20 млн рублей. По итогам каждого года планируется прирост вложенных средств на 13% по сравнению с началом года. Начисленные проценты остаются вложенными в проект. Кроме этого, сразу после начислений процентов нужны дополнительные вложения: целое число \\(n\\) млн рублей в первый и второй годы, а также целое число \\(m\\) млн рублей третий и четвёртый годы. Найдите наименьшие значения \\(n\\) и \\(m\\), при которых первоначальные вложения за два года как минимум удвоятся, а за четыре года как минимум утроятся.</td>\n",
       "      <td>7 и 4</td>\n",
       "      <td>475</td>\n",
       "      <td>7 и 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18693</th>\n",
       "      <td>39649</td>\n",
       "      <td>Отрезок, концы которого лежат на боковых сторонах трапеции, параллелен ее основаниям и проходит через точку пересечения диагоналей.\\nНайдите длину этого отрезка, если основания трапеции равны \\(a\\) и \\(b\\).</td>\n",
       "      <td>\\(\\fraq{2ab}{a + b}\\).</td>\n",
       "      <td>517</td>\n",
       "      <td>Рассмотрим \\(\\Delta ВОС\\) и \\(\\Delta DОА\\): \\(\\angle BOC = \\angle AOD\\) как вертикальные; \\(\\angle BCO = \\angle DAO\\) как внутренние накрест лежащие при \\(BC \\parallel AD\\) и секущей \\(AС \\Rightarrow \\Delta ВОС \\sim \\Delta DOA\\) по двум углам.\\nИз подобия следует: \\(\\fraq{BC}{AD} = \\fraq{OC}{AO} = \\fraq{BO}{OD} = \\fraq{a}{2} \\Rightarrow BO = \\fraq{a \\cdot OD}{b}\\); \\(CO = \\fraq{AO \\cdot a}{b}\\), тогда \\(BD = BO + OD = \\fraq{(a + b) \\cdot OD}{b}\\), \\(AC = AO + OC = \\fraq{(a + b) \\cdot AO}{b}\\). Рассмотрим \\(\\Delta DOF\\) и \\(\\Delta DBC\\): \\(\\angle D\\) - общий; \\(\\angle DOF = \\angle DBC\\) - как соответственные при \\(BC \\parallel EF\\) и секущей \\(BD \\Rightarrow \\Delta DOF \\sim \\Delta DBC\\) по двум углам.\\nИз подобия треугельников следует: \\(\\fraq{DO}{BD} = \\fraq{OF}{BC} \\Rightarrow OF = \\fraq{DO \\cdot BC}{BD} = \\fraq{DO \\cdot a \\cdot b}{(a + b) \\cdot DO} = \\fraq{ab}{a + b}\\). Аналогично доказывается, что \\(\\Delta АОЕ \\sim \\Delta АСВ \\Rightarrow \\fraq{AO}{AC} = \\fraq{OE}{BC} \\Rightarrow OE = \\fraq{AO \\cdot BC}{AC} = \\fraq{AO \\cdot a \\cdot b}{(a + b) \\cdot AO} = \\fraq{ab}{a + b}\\), \\(FE = 2OE = \\fraq{2ab}{a + b}\\).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32792</th>\n",
       "      <td>7353</td>\n",
       "      <td>Известно, что последовательности \\(\\left \\{ x_{n} \\right \\}\\) и \\(\\left \\{ y_{n} \\right \\} \\)являются неограниченными. Выясните, является ли последовательность \\(\\left \\{ z_{n} \\right \\}\\) и,обязательно ограниченной,может ли она быть неограниченной, или всегда является ограниченной (если последовательность \\(\\left \\{ z_{n} \\right \\}\\) существует):\\(z_{n}=x_{n}-y_{n} \\)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>Так как последовательности \\(\\left \\{ x_{n} \\right \\}\\) и \\(\\left \\{ y_{n} \\right \\}\\)ограничены, существуют такие числа A и B, что  \\(\\forall n\\in N \\left ( \\left | x_{n} \\right |\\leqslant A \\right )\\wedge \\left ( \\left | y_{n} \\right |\\leqslant B \\right ) \\) \\nНеравенства \\(\\left | x_{n}-y_{n} \\right |\\leqslant \\left | x_{n} \\right |+\\left | y_{n} \\right |\\leqslant A+B\\) показывают, что последовательность \\(z_{n}=x_{n}+y_{n}\\) обязательно ограничена.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11679</th>\n",
       "      <td>7156</td>\n",
       "      <td>Найти производные\\(f(x)=\\sqrt{2x-1}\\)</td>\n",
       "      <td>\\(f^{'}(x)=\\frac{1}{\\sqrt{2x-1}}\\)</td>\n",
       "      <td>105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31107</th>\n",
       "      <td>48510</td>\n",
       "      <td>На  продолжнении стороны \\(AC \\Delta ABC\\) за  точку \\(C\\) взяли точку \\(M\\) так, что \\(CM : AC = 4 : 5\\). Через точку \\(M\\) провели прямую, которая делит стороны \\(AB и  BC \\Delta\\) в  одинаковом отношении. Найдите это отношение.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>631</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22569</th>\n",
       "      <td>12067</td>\n",
       "      <td>Упростите выражение: \\(\\frac{6x^{2}-15x+25}{4x^{2}-25}+\\frac{x}{5-2x}\\)</td>\n",
       "      <td>\\(\\frac{2x-5}{2x+5}\\)</td>\n",
       "      <td>85</td>\n",
       "      <td>\\(\\frac{6x^{2}-15x+25}{4x^{2}-25}+\\frac{x}{5-2x}=\\frac{6x^{2}-15x+25}{(2x-5)(2x+5)}-\\frac{x}{2x-5}=\\frac{6x^{2}-15x+25-x(2x+5)}{(2x-5)(2x+5)}=\\frac{6x^{2}-15x+25-2x^{2}-5x}{(2x5)(2x+5)}=\\frac{4x^{2}-20x+25}{(2x-5)(2x+5)}=\\frac{(2x-5)^{2}}{(2x-5)(2x+5)}=\\frac{2x-5}{2x+5}\\)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37366</th>\n",
       "      <td>31029</td>\n",
       "      <td>Возьмите большую кастрюлю с водой. Поместите в нее маленькую кастрюльку с водой так, чтобы она плавала, не касаясь дна большой кастрюли. Поставьте их на плиту и начните нагревать. Что будет с водой в маленькой кастрюле во время кипения воды в большой кастрюле? Почему? Бросьте в большую кастрюлю горсть соли. Что произойдет после этого с водой в маленькой кастрюле? Объясните наблюдаемые явления.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414</td>\n",
       "      <td>В чистой воде газ растворим лучше, чем в растворе соли, а газированная вода - это перенасыщенный раствор диоксида углерода \\(CO_{2}\\) (углекислого газа) в воде. Чтобы избыток газа выделился, нужны \"зародыши\", например микропузырьки воздуха. Однако добавление к газированной воде речного песка не приведет к выделению газа. Правильное объяснение включает два механизма процесса: как только кристаллы соли попадут в стакан, они начнут растворяться, и вокруг них образуется пленка концентрированного раствора; в результате растворимость газа вблизи кристаллов резко уменьшается, появляются маленькие пузырьки газа - \"зародыши\". Как только \"зародыши\" вырастают, они отрываются от кристаллов, и в соприкосновение с солью приходят новые порции раствора. Этот процесс продолжается до тех пор, пока вся соль не растворится или пока не выделится весь диоксид углерода.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18942</th>\n",
       "      <td>40582</td>\n",
       "      <td>Длина вектора \\(\\vec{АВ}\\) равна 5. Найдите координаты точки \\(В\\), если \\(А(4; -2)\\), а точка \\(В\\) лежит на прямой \\(у = 2х\\).</td>\n",
       "      <td>\\((1; 2)\\) или \\((-1; -2)\\).</td>\n",
       "      <td>524</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27313</th>\n",
       "      <td>32815</td>\n",
       "      <td>Решите неравенство. \\( \\sqrt[3]{27-5x} &lt; x+3  \\)</td>\n",
       "      <td>\\( \\left (0; +\\infty \\right )\\)</td>\n",
       "      <td>443</td>\n",
       "      <td>\\( \\left (0; +\\infty \\right )\\)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "20218  46992   \n",
       "17607  35921   \n",
       "18693  39649   \n",
       "32792   7353   \n",
       "11679   7156   \n",
       "31107  48510   \n",
       "22569  12067   \n",
       "37366  31029   \n",
       "18942  40582   \n",
       "27313  32815   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           task  \\\n",
       "20218                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Постройте график функции: \\(y=cos(x+\\frac{\\pi}{6})\\).   \n",
       "17607  По бизнес-плану предполагается вложить в четырёхлетний проект 20 млн рублей. По итогам каждого года планируется прирост вложенных средств на 13% по сравнению с началом года. Начисленные проценты остаются вложенными в проект. Кроме этого, сразу после начислений процентов нужны дополнительные вложения: целое число \\(n\\) млн рублей в первый и второй годы, а также целое число \\(m\\) млн рублей третий и четвёртый годы. Найдите наименьшие значения \\(n\\) и \\(m\\), при которых первоначальные вложения за два года как минимум удвоятся, а за четыре года как минимум утроятся.   \n",
       "18693                                                                                                                                                                                                                                                                                                                                                                            Отрезок, концы которого лежат на боковых сторонах трапеции, параллелен ее основаниям и проходит через точку пересечения диагоналей.\\nНайдите длину этого отрезка, если основания трапеции равны \\(a\\) и \\(b\\).   \n",
       "32792                                                                                                                                                                                                       Известно, что последовательности \\(\\left \\{ x_{n} \\right \\}\\) и \\(\\left \\{ y_{n} \\right \\} \\)являются неограниченными. Выясните, является ли последовательность \\(\\left \\{ z_{n} \\right \\}\\) и,обязательно ограниченной,может ли она быть неограниченной, или всегда является ограниченной (если последовательность \\(\\left \\{ z_{n} \\right \\}\\) существует):\\(z_{n}=x_{n}-y_{n} \\)   \n",
       "11679                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Найти производные\\(f(x)=\\sqrt{2x-1}\\)   \n",
       "31107                                                                                                                                                                                                                                                                                                                                                    На  продолжнении стороны \\(AC \\Delta ABC\\) за  точку \\(C\\) взяли точку \\(M\\) так, что \\(CM : AC = 4 : 5\\). Через точку \\(M\\) провели прямую, которая делит стороны \\(AB и  BC \\Delta\\) в  одинаковом отношении. Найдите это отношение.   \n",
       "22569                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Упростите выражение: \\(\\frac{6x^{2}-15x+25}{4x^{2}-25}+\\frac{x}{5-2x}\\)   \n",
       "37366                                                                                                                                                                              Возьмите большую кастрюлю с водой. Поместите в нее маленькую кастрюльку с водой так, чтобы она плавала, не касаясь дна большой кастрюли. Поставьте их на плиту и начните нагревать. Что будет с водой в маленькой кастрюле во время кипения воды в большой кастрюле? Почему? Бросьте в большую кастрюлю горсть соли. Что произойдет после этого с водой в маленькой кастрюле? Объясните наблюдаемые явления.   \n",
       "18942                                                                                                                                                                                                                                                                                                                                                                                                                                                          Длина вектора \\(\\vec{АВ}\\) равна 5. Найдите координаты точки \\(В\\), если \\(А(4; -2)\\), а точка \\(В\\) лежит на прямой \\(у = 2х\\).   \n",
       "27313                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Решите неравенство. \\( \\sqrt[3]{27-5x} < x+3  \\)   \n",
       "\n",
       "                                   answer  topics_id  \\\n",
       "20218                                 NaN         87   \n",
       "17607                               7 и 4        475   \n",
       "18693              \\(\\fraq{2ab}{a + b}\\).        517   \n",
       "32792                                 NaN         55   \n",
       "11679  \\(f^{'}(x)=\\frac{1}{\\sqrt{2x-1}}\\)        105   \n",
       "31107                                 NaN        631   \n",
       "22569               \\(\\frac{2x-5}{2x+5}\\)         85   \n",
       "37366                                 NaN        414   \n",
       "18942       \\((1; 2)\\) или \\((-1; -2)\\).         524   \n",
       "27313     \\( \\left (0; +\\infty \\right )\\)        443   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             text_of_solution  \n",
       "20218                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN  \n",
       "17607                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   7 и 4  \n",
       "18693  Рассмотрим \\(\\Delta ВОС\\) и \\(\\Delta DОА\\): \\(\\angle BOC = \\angle AOD\\) как вертикальные; \\(\\angle BCO = \\angle DAO\\) как внутренние накрест лежащие при \\(BC \\parallel AD\\) и секущей \\(AС \\Rightarrow \\Delta ВОС \\sim \\Delta DOA\\) по двум углам.\\nИз подобия следует: \\(\\fraq{BC}{AD} = \\fraq{OC}{AO} = \\fraq{BO}{OD} = \\fraq{a}{2} \\Rightarrow BO = \\fraq{a \\cdot OD}{b}\\); \\(CO = \\fraq{AO \\cdot a}{b}\\), тогда \\(BD = BO + OD = \\fraq{(a + b) \\cdot OD}{b}\\), \\(AC = AO + OC = \\fraq{(a + b) \\cdot AO}{b}\\). Рассмотрим \\(\\Delta DOF\\) и \\(\\Delta DBC\\): \\(\\angle D\\) - общий; \\(\\angle DOF = \\angle DBC\\) - как соответственные при \\(BC \\parallel EF\\) и секущей \\(BD \\Rightarrow \\Delta DOF \\sim \\Delta DBC\\) по двум углам.\\nИз подобия треугельников следует: \\(\\fraq{DO}{BD} = \\fraq{OF}{BC} \\Rightarrow OF = \\fraq{DO \\cdot BC}{BD} = \\fraq{DO \\cdot a \\cdot b}{(a + b) \\cdot DO} = \\fraq{ab}{a + b}\\). Аналогично доказывается, что \\(\\Delta АОЕ \\sim \\Delta АСВ \\Rightarrow \\fraq{AO}{AC} = \\fraq{OE}{BC} \\Rightarrow OE = \\fraq{AO \\cdot BC}{AC} = \\fraq{AO \\cdot a \\cdot b}{(a + b) \\cdot AO} = \\fraq{ab}{a + b}\\), \\(FE = 2OE = \\fraq{2ab}{a + b}\\).  \n",
       "32792                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Так как последовательности \\(\\left \\{ x_{n} \\right \\}\\) и \\(\\left \\{ y_{n} \\right \\}\\)ограничены, существуют такие числа A и B, что  \\(\\forall n\\in N \\left ( \\left | x_{n} \\right |\\leqslant A \\right )\\wedge \\left ( \\left | y_{n} \\right |\\leqslant B \\right ) \\) \\nНеравенства \\(\\left | x_{n}-y_{n} \\right |\\leqslant \\left | x_{n} \\right |+\\left | y_{n} \\right |\\leqslant A+B\\) показывают, что последовательность \\(z_{n}=x_{n}+y_{n}\\) обязательно ограничена.  \n",
       "11679                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN  \n",
       "31107                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN  \n",
       "22569                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \\(\\frac{6x^{2}-15x+25}{4x^{2}-25}+\\frac{x}{5-2x}=\\frac{6x^{2}-15x+25}{(2x-5)(2x+5)}-\\frac{x}{2x-5}=\\frac{6x^{2}-15x+25-x(2x+5)}{(2x-5)(2x+5)}=\\frac{6x^{2}-15x+25-2x^{2}-5x}{(2x5)(2x+5)}=\\frac{4x^{2}-20x+25}{(2x-5)(2x+5)}=\\frac{(2x-5)^{2}}{(2x-5)(2x+5)}=\\frac{2x-5}{2x+5}\\)  \n",
       "37366                                                                                                                                                                                                                                                                             В чистой воде газ растворим лучше, чем в растворе соли, а газированная вода - это перенасыщенный раствор диоксида углерода \\(CO_{2}\\) (углекислого газа) в воде. Чтобы избыток газа выделился, нужны \"зародыши\", например микропузырьки воздуха. Однако добавление к газированной воде речного песка не приведет к выделению газа. Правильное объяснение включает два механизма процесса: как только кристаллы соли попадут в стакан, они начнут растворяться, и вокруг них образуется пленка концентрированного раствора; в результате растворимость газа вблизи кристаллов резко уменьшается, появляются маленькие пузырьки газа - \"зародыши\". Как только \"зародыши\" вырастают, они отрываются от кристаллов, и в соприкосновение с солью приходят новые порции раствора. Этот процесс продолжается до тех пор, пока вся соль не растворится или пока не выделится весь диоксид углерода.  \n",
       "18942                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN  \n",
       "27313                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \\( \\left (0; +\\infty \\right )\\)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42648 entries, 0 to 42647\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                42648 non-null  int64 \n",
      " 1   task              42648 non-null  object\n",
      " 2   answer            24048 non-null  object\n",
      " 3   topics_id         42648 non-null  int64 \n",
      " 4   text_of_solution  22678 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Количество записпей:  42648 Количество столбцов:  5\n"
     ]
    }
   ],
   "source": [
    "df_info(df_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "32e5ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# соединим два датафрейма\n",
    "\n",
    "df_train = df_topics.merge(df_task, left_on='id', right_on='topics_id')\n",
    "\n",
    "# уберем лишник колонки\n",
    "\n",
    "df_train.drop(['id_x', 'name', 'parent', 'id_y', 'answer', 'topics_id', 'text_of_solution'],\n",
    "              axis=1,\n",
    "              inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "60c5c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(row):\n",
    "    \n",
    "    '''\n",
    "    Функция для определения таргета. На вход получает сам датафрейм. \n",
    "    На выходе, столбец с таргетом. \n",
    "    Математика - таргет 1. Физика - таргет 0. \n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        if row.subject == 'Математика':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "21af14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим функцию по добавлению таргета\n",
    "df_train['target'] = df_train.apply(make_target, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081fd46f",
   "metadata": {},
   "source": [
    "#### Проверим дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "639c24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество дубликатов в данных\n",
    "df_train.duplicated().sum()\n",
    "\n",
    "# удалим дубликаты\n",
    "df_train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "984d74db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>task</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Математика</td>\n",
       "      <td>Равносильны ли уравнения: \\(cosx=0\\) и \\(sin^2x=1\\).</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Математика</td>\n",
       "      <td>Равносильны ли уравнения: \\(\\frac{log_x(x+1)}{log_x2}=1\\) и \\(log_2(x+1)=1\\).</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Математика</td>\n",
       "      <td>Равносильны ли уравнения: \\(\\frac{x+3}{x+3}=1\\) и \\(\\frac{x^2+3}{x^2+3}=1\\).</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Математика</td>\n",
       "      <td>Равносильны ли уравнения: \\(log_{x^2}x^2=1 \\)  и \\(log_xx=1\\) .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Математика</td>\n",
       "      <td>Какое из двух уравнений является следствием другого: \\(x^2=25\\) и \\(x^2-\\frac{1}{x+5}=25-\\frac{1}{x+5}\\).</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  \\\n",
       "0  Математика   \n",
       "1  Математика   \n",
       "2  Математика   \n",
       "3  Математика   \n",
       "4  Математика   \n",
       "\n",
       "                                                                                                        task  \\\n",
       "0                                                       Равносильны ли уравнения: \\(cosx=0\\) и \\(sin^2x=1\\).   \n",
       "1                              Равносильны ли уравнения: \\(\\frac{log_x(x+1)}{log_x2}=1\\) и \\(log_2(x+1)=1\\).   \n",
       "2                               Равносильны ли уравнения: \\(\\frac{x+3}{x+3}=1\\) и \\(\\frac{x^2+3}{x^2+3}=1\\).   \n",
       "3                                            Равносильны ли уравнения: \\(log_{x^2}x^2=1 \\)  и \\(log_xx=1\\) .   \n",
       "4  Какое из двух уравнений является следствием другого: \\(x^2=25\\) и \\(x^2-\\frac{1}{x+5}=25-\\frac{1}{x+5}\\).   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d778eb",
   "metadata": {},
   "source": [
    "#### Очистим текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "960e1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполню очистку текста и лемматизирую его. \n",
    "disabled_pipes = ['parser', 'ner']\n",
    "nlp = spacy.load('ru_core_news_sm', disable=disabled_pipes)\n",
    "\n",
    "\n",
    "def clean_text(input_text):    \n",
    "    \n",
    "    '''\n",
    "    Функция для очистки текста.\n",
    "    На вход принимает текст задач. На выходе получаем очищенный текст \n",
    "    '''\n",
    "    \n",
    "    # HTML-теги: первый шаг - удалить из входного текста все HTML-теги\n",
    "    clean_text = re.sub('<[^<]+?>', ' ', input_text)\n",
    "    \n",
    "    # URL и ссылки: далее - удаляем из текста все URL и ссылки\n",
    "    clean_text = re.sub(r'http\\S+', ' ', clean_text)\n",
    "\n",
    "    \n",
    "    # Приводим все входные данные к нижнему регистру\n",
    "    clean_text = clean_text.lower()\n",
    "\n",
    "    # Убираем все пробелы\n",
    "    # Так как все данные теперь представлены словами - удалим пробелы\n",
    "    clean_text = re.sub('\\s+', ' ', clean_text)\n",
    "\n",
    "    # Разворачиваем сокращения: текст часто содержит конструкции вроде \"don't\" или \"won't\", \n",
    "    #поэтому развернём подобные сокращения\n",
    "    clean_text = contractions.fix(clean_text)\n",
    "\n",
    "    \n",
    "    # Убираем специальные символы: избавляемся от всего, что не является \"словами\"\n",
    "    pattern = '[^а-яА-ЯёЁ0-9a-zA-Z\\s]'\n",
    "    clean_text = re.sub(pattern, ' ', clean_text)\n",
    "    \n",
    "    # Записываем числа прописью: 100 превращается в \"сто\" (для компьютера)\n",
    "    temp = inflect.engine()\n",
    "    words = []\n",
    "    for word in clean_text.split():\n",
    "        if word.isdigit():\n",
    "            words.append(temp.number_to_words(word))\n",
    "        else:\n",
    "            words.append(word)\n",
    "    clean_text = ' '.join(words)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Стоп-слова: удаление стоп-слов - это стандартная практика очистки текстов\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    tokens = word_tokenize(clean_text, language='russian')\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    clean_text = ' '.join(tokens) \n",
    "   \n",
    "    # Знаки препинания: далее - удаляем из текста все знаки препинания\n",
    "    clean_text = re.sub(r'[^\\w\\s]', ' ', clean_text)\n",
    "    \n",
    "    # Удаляем пробелы\n",
    "    clean_text = re.sub('\\s+', ' ', clean_text).strip()\n",
    "\n",
    "    # И наконец - возвращаем очищенный текст\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def lemmatization(text):\n",
    "\n",
    "    '''\n",
    "    Функция лемметезации текста\n",
    "    На вход получает очищенный текст.\n",
    "    На выходе лемметизированныцй текст\n",
    "    '''\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    return ' '.join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fdf6dc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09678943dd264637b5e85f2ce0d35bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_train['clean_text'] = df_train['task'].progress_apply(clean_text) # очистка текста для train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "289e8e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f717ae9f69604c148e9f294d47404b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_train['lemm_text'] = df_train['clean_text'].progress_apply(lemmatization) # лемм. текста для train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "37386d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>task</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21057</th>\n",
       "      <td>Физика</td>\n",
       "      <td>Мягкая легкая металлическая пружина висит, погрузившись нижним концом в соленую воду на небольшую глубину (рисунок ниже). Что произойдет после замыкания ключа?&lt;br&gt; &lt;img src='https://hot_data_kuzovkin_info_private.hb.bizmrg.com/picture_to_tasks/physics/gendenshtein_8/magnit_optika/105_gendenshteyn_96.png'&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>мягкая легкая металлическая пружина висит погрузившись нижним концом соленую воду небольшую глубину рисунок ниже произойдет замыкания ключа</td>\n",
       "      <td>мягкий лёгкий металлический пружина висеть погрузившись нижний конец солёный вода небольшой глубина рисунок ниже произойти замыкание ключ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33061</th>\n",
       "      <td>Математика</td>\n",
       "      <td>На  рисунке ниже стрелочками отмечены параллельные прямые. На  рисунке изображён параллелограмм. Найдите на рисунках ниже длину отрезка, обозначенного буквой \\(х\\).&lt;br&gt; &lt;img src='https://hot_data_kuzovkin_info_private.hb.ru-msk.vkcs.cloud/picture_to_tasks/math/Volchkevich_mat_vertical_9/245.png'&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>рисунке ниже стрелочками отмечены параллельные прямые рисунке изображён параллелограмм найдите рисунках ниже длину отрезка обозначенного буквой х</td>\n",
       "      <td>рисунке низкий стрелочка отметить параллельный прямой рисунке изображён параллелограмм найти рисунок ниже длина отрезка обозначенного буква х</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12138</th>\n",
       "      <td>Математика</td>\n",
       "      <td>Через данную точку внутри окружности проведите хорду, которая делится этой точкой пополам.</td>\n",
       "      <td>1</td>\n",
       "      <td>данную точку внутри окружности проведите хорду которая делится точкой пополам</td>\n",
       "      <td>данную точка внутри окружность проведите хорду которая делиться точка пополам</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19025</th>\n",
       "      <td>Математика</td>\n",
       "      <td>Решите уравнение: \\(cos^{2}x-3cosx+a=0\\)</td>\n",
       "      <td>1</td>\n",
       "      <td>решите уравнение cos two x 3cosx a zero</td>\n",
       "      <td>решить уравнение cos two x 3cosx a zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19351</th>\n",
       "      <td>Математика</td>\n",
       "      <td>Решите уравнение: \\(sin9x=2sin3x\\)</td>\n",
       "      <td>1</td>\n",
       "      <td>решите уравнение sin9x 2sin3x</td>\n",
       "      <td>решить уравнение sin9x 2sin3x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject  \\\n",
       "21057      Физика   \n",
       "33061  Математика   \n",
       "12138  Математика   \n",
       "19025  Математика   \n",
       "19351  Математика   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                     task  \\\n",
       "21057  Мягкая легкая металлическая пружина висит, погрузившись нижним концом в соленую воду на небольшую глубину (рисунок ниже). Что произойдет после замыкания ключа?<br> <img src='https://hot_data_kuzovkin_info_private.hb.bizmrg.com/picture_to_tasks/physics/gendenshtein_8/magnit_optika/105_gendenshteyn_96.png'>   \n",
       "33061           На  рисунке ниже стрелочками отмечены параллельные прямые. На  рисунке изображён параллелограмм. Найдите на рисунках ниже длину отрезка, обозначенного буквой \\(х\\).<br> <img src='https://hot_data_kuzovkin_info_private.hb.ru-msk.vkcs.cloud/picture_to_tasks/math/Volchkevich_mat_vertical_9/245.png'>   \n",
       "12138                                                                                                                                                                                                                          Через данную точку внутри окружности проведите хорду, которая делится этой точкой пополам.   \n",
       "19025                                                                                                                                                                                                                                                                            Решите уравнение: \\(cos^{2}x-3cosx+a=0\\)   \n",
       "19351                                                                                                                                                                                                                                                                                  Решите уравнение: \\(sin9x=2sin3x\\)   \n",
       "\n",
       "       target  \\\n",
       "21057       0   \n",
       "33061       1   \n",
       "12138       1   \n",
       "19025       1   \n",
       "19351       1   \n",
       "\n",
       "                                                                                                                                              clean_text  \\\n",
       "21057        мягкая легкая металлическая пружина висит погрузившись нижним концом соленую воду небольшую глубину рисунок ниже произойдет замыкания ключа   \n",
       "33061  рисунке ниже стрелочками отмечены параллельные прямые рисунке изображён параллелограмм найдите рисунках ниже длину отрезка обозначенного буквой х   \n",
       "12138                                                                      данную точку внутри окружности проведите хорду которая делится точкой пополам   \n",
       "19025                                                                                                            решите уравнение cos two x 3cosx a zero   \n",
       "19351                                                                                                                      решите уравнение sin9x 2sin3x   \n",
       "\n",
       "                                                                                                                                           lemm_text  \n",
       "21057      мягкий лёгкий металлический пружина висеть погрузившись нижний конец солёный вода небольшой глубина рисунок ниже произойти замыкание ключ  \n",
       "33061  рисунке низкий стрелочка отметить параллельный прямой рисунке изображён параллелограмм найти рисунок ниже длина отрезка обозначенного буква х  \n",
       "12138                                                                  данную точка внутри окружность проведите хорду которая делиться точка пополам  \n",
       "19025                                                                                                        решить уравнение cos two x 3cosx a zero  \n",
       "19351                                                                                                                  решить уравнение sin9x 2sin3x  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(5) #посмотрим что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a87c56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['lemm_text'].str.len().hist()\n",
    "plt.title('Распределение длин лемматизированных текстов')\n",
    "plt.xlabel('Колличество')\n",
    "plt.ylabel('Длинна')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85b07d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# уберем все строки с нулевой длинной\n",
    "df_train = df_train[~(df_train['lemm_text'].str.len() == 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3256dc",
   "metadata": {},
   "source": [
    "#### Разделим выборку на тренировочную и валидационную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cbc2345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем лишние колонки\n",
    "df_train_net = df_train.drop(['subject', 'task', 'clean_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "684a94cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456\n"
     ]
    }
   ],
   "source": [
    "# избавляемся от дубликатов\n",
    "print(df_train_net.duplicated().sum())\n",
    "df_train_net.drop_duplicates(inplace=True)\n",
    "\n",
    "df_train_net.reset_index(drop=True, inplace=True) # перезапишем индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fd4254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39431, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_net.shape # посмотрим размерность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13351e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим выборки на тренировочную, валидационную и тестовую\n",
    "train, valid = train_test_split(df_train_net, \n",
    "                                test_size=0.25, \n",
    "                                random_state=SEED,\n",
    "                                stratify=df_train['target'])\n",
    "\n",
    "valid, test = train_test_split(valid, \n",
    "                                test_size=0.5, \n",
    "                                random_state=SEED,\n",
    "                                stratify=valid['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2988b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# перезапишем индексы\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a5146e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29573, 2)\n",
      "(4929, 2)\n",
      "(4929, 2)\n"
     ]
    }
   ],
   "source": [
    "# проверим размерность полученых переменых\n",
    "print(train.shape)\n",
    "print(valid.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df07850",
   "metadata": {},
   "source": [
    "## Подготовим необходимые классы и функции для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a1802ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подберем веса классов\n",
    "class_counts = train['target'].value_counts().to_list()\n",
    "num_samples = sum(class_counts)\n",
    "labels = train['target'].values - 1\n",
    "\n",
    "class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
    "weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f734434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# определие специальных символы и индексы\n",
    "PAD_IDX, UNK_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "\n",
    "# токены должны быть расположены в порядке следования их индексов, чтобы правильно вставить их в словарь\n",
    "special_symbols = [\"<pad>\", \"<unk>\", \"<bos>\", \"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2d80fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем класс для текстовых данных\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, max_len=64):\n",
    "        self.data = data\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        row = self.data.iloc[ix].squeeze()\n",
    "        text = row['lemm_text']\n",
    "        label = row['target']\n",
    "        \n",
    "        return text, label\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        texts, labels = list(zip(*batch))       \n",
    "        text_batch = torch.zeros((len(texts), self.max_len)).fill_(PAD_IDX).long() # постоянная длинна\n",
    "              \n",
    "        for i in range(len(texts)):\n",
    "            sample = text_transform(texts[i])[:self.max_len]\n",
    "            text_batch[i, :len(sample)] = sample\n",
    "        \n",
    "        labels = torch.cat([torch.tensor(label).unsqueeze(0) for label in labels]).to(device)\n",
    "        return text_batch.to(device), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0164d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform = get_tokenizer('spacy', language='ru_core_news_sm') # токенизация текста\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    \n",
    "    '''\n",
    "    Функция для преобразовать данные, содержащиеся в data_iter,\n",
    "   с помощью функции token_transform.\n",
    "   На вход получает итерируемый объект.\n",
    "   На выходе возвращает преобразованные данные преобразованные данные.\n",
    "    '''\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform(data_sample[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa72b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим объект Vocab для \n",
    "data_iter = TextDataset(df_train)\n",
    "\n",
    "vocabulary = build_vocab_from_iterator(yield_tokens(data_iter),  # определяем набор данных\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "# Зададим `UNK_IDX` в качестве индекса по умолчанию. Этот индекс возвращается, когда токен не найден.\n",
    "vocabulary.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c56afe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_transforms(*transforms):\n",
    "    \n",
    "    '''\n",
    "    функция для объединения последовательных операций\n",
    "    '''\n",
    "    \n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "def tensor_transform(token_ids, drop_specials=True):\n",
    "    \n",
    "    '''\n",
    "    Функция для добавления BOS/EOS и создания тензора для индексов входной последовательности\n",
    "    '''\n",
    "    \n",
    "    if drop_specials:\n",
    "        return torch.tensor(token_ids)\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# трансформируем текст\n",
    "text_transform = sequential_transforms(token_transform,  # токенизация\n",
    "                                       vocabulary,       # нумиризация\n",
    "                                       tensor_transform) # добавляем BOS/EOS и создаем тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6654ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим загрузчики данных для тренировочной, валидационной и тестовой\n",
    "train_ds = TextDataset(train)\n",
    "valid_ds = TextDataset(valid)\n",
    "test_ds = TextDataset(test)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=train_ds.collate_fn)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=128, collate_fn=valid_ds.collate_fn)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=64, collate_fn=test_ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28cb4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим класс ранней остановки\n",
    "\n",
    "class EarlyStopping:\n",
    "    \n",
    "    # patience - количество эпох ожидания, прежде чем остановиться, если улучшения не будет\n",
    "    # min_delta - Минимальное изменение контролируемого количества, которое можно квалифицировать как улучшение\n",
    "    # counter - счетчик\n",
    "    # best_loss - лучшее значение фуекции потерь\n",
    "    # early_stop - ранняя остновка\n",
    "    \n",
    "    def __init__(self, patience=5, min_delta=0, path='model.pth'):\n",
    "        self.path = path\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss, model=None):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:\n",
    "            if model is not None:\n",
    "                checkpoint = {\n",
    "                    'model': model,\n",
    "                }\n",
    "                torch.save(checkpoint, self.path)\n",
    "                print(f'Model saved to: {self.path}')\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta:\n",
    "            self.counter += 1\n",
    "            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                print('INFO: Early stopping')\n",
    "                self.early_stop = True\n",
    "\n",
    "                \n",
    "def calc_accuracy(y_pred, y_true):\n",
    "    \n",
    "    '''\n",
    "    Функция расчета аccuracy. На вход получает предсказания модели и настоящие значения таргета\n",
    "    На выходе значения метрики аccuracy \n",
    "    '''\n",
    "    \n",
    "    return (y_true == torch.max(y_pred, 1)[1]).float().mean()\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \n",
    "    ''' \n",
    "    https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/focal_loss.py\n",
    "    \n",
    "    Класс для устранения дисбаланса классов. Позволяет избежать потери энтропии и\n",
    "    полезно для задач классификации при большом дисбалансе классов.\n",
    "    Ожидается, что x будет содержать необработанные, ненормализованные оценки для каждого класса.\n",
    "    Ожидается, что y будет содержать метки классов.\n",
    "    \n",
    "    Размерность:\n",
    "        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n",
    "        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, *args, \n",
    "                 alpha: torch.Tensor = None, \n",
    "                 gamma: float = 2.0, \n",
    "                 reduction: str = 'mean',\n",
    "                 ignore_index: int = -100,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        \n",
    "        '''        \n",
    "            alpha (Tensor, optional): Веса каждого класса, по умолчанию None.\n",
    "            gamma (float, optional): Константа, по умолчанию 2.0.                \n",
    "            reduction (str, optional): 'mean', 'sum' or 'none'. Но умолчанию 'mean'.\n",
    "            ignore_index (int, optional): Метка класса, которую следует ингнорировать. Но умолчанию -100.\n",
    "        '''\n",
    "        \n",
    "        if reduction not in ('mean', 'sum', 'none'):\n",
    "            raise ValueError(\n",
    "                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n",
    "\n",
    "        super(FocalLoss, self).__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reduction = reduction\n",
    "\n",
    "        self.nll_loss = nn.NLLLoss(\n",
    "            weight=alpha, reduction='none', ignore_index=ignore_index)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
    "        if x.ndim > 2:\n",
    "            c = x.shape[1]  \n",
    "            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n",
    "            y = y.view(-1)  \n",
    "        \n",
    "        y = y.long()\n",
    "        unignored_mask = y != self.ignore_index\n",
    "        y = y[unignored_mask]\n",
    "        if len(y) == 0:\n",
    "            return torch.tensor(0.)\n",
    "        x = x[unignored_mask]\n",
    "\n",
    "        # вычислить взвешенный коэффициент перекрестной энтропии:\n",
    "        # -alpha * log(pt) (alpha is already part of self.nll_loss)\n",
    "        log_p = F.log_softmax(x, dim=-1)\n",
    "        ce = self.nll_loss(log_p, y)\n",
    "\n",
    "        # получить столбец истинного класса из каждой строки\n",
    "        all_rows = torch.arange(len(x))\n",
    "        log_pt = log_p[all_rows, y]\n",
    "\n",
    "        # вычесляем focal term: (1 - pt)^gamma\n",
    "        pt = log_pt.exp()\n",
    "        focal_term = (1 - pt)**self.gamma\n",
    "\n",
    "        # полная loss: -alpha * ((1 - pt)^gamma) * log(pt)\n",
    "        loss = focal_term * ce\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fb58dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(data, model, criterion, optimizer):\n",
    "    \n",
    "    '''\n",
    "    Функция для тренироваки одного batch.\n",
    "    На вход принимет данные, модель для обучения, функцию потерь и оптимизатор.\n",
    "    На выходе значения функции потерь и accuracy.\n",
    "    '''\n",
    "    \n",
    "    model.train()\n",
    "    texts, labels = data\n",
    "    optimizer.zero_grad()\n",
    "    output = model(texts)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    accuracy = calc_accuracy(output, labels)\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_batch(data, model, criterion):\n",
    "    \n",
    "    '''\n",
    "    Функция для валидации одного batch.\n",
    "    На вход принимет данные, модель для обучения, функцию потерь и оптимизатор.\n",
    "    На выходе значения функции потерь и accuracy.\n",
    "    '''\n",
    "    \n",
    "    model.eval()\n",
    "    texts, labels = data\n",
    "    \n",
    "    out = model(texts)\n",
    "    loss = criterion(out, labels)\n",
    "    \n",
    "    accuracy = calc_accuracy(out, labels)\n",
    "    \n",
    "    return loss.item(), accuracy.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a378355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, epochs=40, print_freq=50):\n",
    "    \n",
    "    '''\n",
    "    Функция для обучения модели.\n",
    "    На вход принимает содель для обучения, количество эпох, частоту вывачи информации о прогрессе обучения.\n",
    "    На выходе значения функции потерь и accuracy для тренировочной, валидационной и тестовой выборках.\n",
    "    '''\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        train_loss, train_accs = [], []\n",
    "        for step, batch in enumerate(train_dataloader, 1):\n",
    "            time_1 = time.time()\n",
    "\n",
    "            loss, accuracy = train_one_batch(batch, model, criterion, optimizer)\n",
    "\n",
    "            train_loss.append(loss)\n",
    "            train_accs.append(accuracy)\n",
    "\n",
    "            if step % print_freq == 0:\n",
    "                print('epoch:', epoch, \n",
    "                      '\\tstep:', step, '/', len(train_dataloader),\n",
    "                      '\\ttrain loss:', '{:.4f}'.format(loss),\n",
    "                      '\\ttrain accuracy:','{:.4f}'.format(accuracy),\n",
    "                      '\\ttime:', '{:.4f}'.format((time.time()-time_1)*print_freq), 's')\n",
    "\n",
    "        valid_loss, valid_accs = [], []\n",
    "        for step, batch in enumerate(tqdm(valid_dataloader)):\n",
    "            loss, accuracy = validate_one_batch(batch, model, criterion)\n",
    "\n",
    "            valid_loss.append(loss)\n",
    "            valid_accs.append(accuracy)\n",
    "\n",
    "        print('epoch:', epoch, '/', epochs,\n",
    "              '\\ttrain loss:', '{:.4f}'.format(np.mean(train_loss)),\n",
    "              '\\tvalid loss:', '{:.4f}'.format(np.mean(valid_loss)),\n",
    "              '\\ttrain accuracy', '{:.4f}'.format(np.mean(train_accs)),\n",
    "              '\\tvalid accuracy', '{:.4f}'.format(np.mean(valid_accs)))\n",
    "\n",
    "        stopper(np.mean(valid_loss), model)\n",
    "        if stopper.early_stop:\n",
    "            checkpoint = torch.load(\"model.pth\", map_location=device)\n",
    "            model = checkpoint['model']\n",
    "            break\n",
    "        scheduler.step(np.mean(valid_loss))\n",
    "\n",
    "    test_loss, test_accs = [], []\n",
    "    for step, batch in enumerate(tqdm(test_dataloader)):\n",
    "        loss, accuracy = validate_one_batch(batch, model, criterion)\n",
    "\n",
    "        test_loss.append(loss)\n",
    "        test_accs.append(accuracy)\n",
    "\n",
    "    print('\\ttest loss:', '{:.4f}'.format(np.mean(test_loss)),\n",
    "          '\\ttest accuracy', '{:.4f}'.format(np.mean(test_accs)),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5863fc1",
   "metadata": {},
   "source": [
    "__Models:__\n",
    "\n",
    " - CNN\n",
    " - LSTM\n",
    " - LSTM-CNN\n",
    " - Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4d7aaa",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e742a",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42e31ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    Задаем класс модели для обучения.\n",
    "    На вход получает число скрытых слоев, размер словаря, коэффициент исключения нейронов, количество классов.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, hidden_dim, vocab_size, num_classes=2, dropout=0.1, **kwargs):\n",
    "        super(CNNModel ,self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)  #, padding_idx=PAD_IDX)  # default = 0\n",
    "        self.conv1 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=1)\n",
    "        \n",
    "        self.cconv1 = nn.Conv1d(hidden_dim, hidden_dim//4, kernel_size=1, padding=0)\n",
    "        self.cconv2 = nn.Conv1d(hidden_dim, hidden_dim//4, kernel_size=2, padding=1)\n",
    "        self.cconv3 = nn.Conv1d(hidden_dim, hidden_dim//4, kernel_size=3, padding=1)\n",
    "        self.cconv4 = nn.Conv1d(hidden_dim, hidden_dim//4, kernel_size=5, padding=2)\n",
    "        self.cbatch = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim*2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(hidden_dim*2, hidden_dim*2, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(hidden_dim*2, hidden_dim*4, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv1d(hidden_dim*4, hidden_dim*4, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.reducer = nn.Linear(hidden_dim*4, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.contiguous().permute(0,2,1)  # [B, SEQ_LEN, hidden] -> [B, hidden, SEQ_LEN] \n",
    "                                           # to slide over sequence for n-gramms        \n",
    "        \n",
    "        in_x1 = self.cconv1(x)\n",
    "        in_x2 = self.cconv1(x)\n",
    "        in_x3 = self.cconv1(x)\n",
    "        in_x4 = self.cconv1(x)\n",
    "        in_x = torch.cat([in_x1, in_x2, in_x3, in_x4], dim=1)\n",
    "        # in_x = self.cbatch(x)\n",
    "        in_x = F.relu(in_x)\n",
    "        \n",
    "        x = self.conv2(in_x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        # x = self.pool(x)\n",
    "        x = torch.max(x, dim=2)[0]  # obtain max n-gramm info\n",
    "        # x = x.contiguous().view(x.size(0), -1)\n",
    "        x = self.reducer(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e431666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel(hidden_dim=64, vocab_size=len(vocabulary), dropout=0.3, num_classes=2).to(device) # модель\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # функция потерь\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0005) # оптимизатор\n",
    "\n",
    "# автоматическое регулирование скорости обучения \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.1)\n",
    "\n",
    "stopper = EarlyStopping(patience=4) # ранняя остановка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8966b219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 232 \ttrain loss: 0.2739 \ttrain accuracy: 0.8906 \ttime: 8.3851 s\n",
      "epoch: 1 \tstep: 100 / 232 \ttrain loss: 0.1867 \ttrain accuracy: 0.9141 \ttime: 10.0127 s\n",
      "epoch: 1 \tstep: 150 / 232 \ttrain loss: 0.1199 \ttrain accuracy: 0.9766 \ttime: 8.0907 s\n",
      "epoch: 1 \tstep: 200 / 232 \ttrain loss: 0.0409 \ttrain accuracy: 0.9922 \ttime: 8.5253 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee5db2894694d079040ea64680763fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 0.2273 \tvalid loss: 0.1470 \ttrain accuracy 0.8960 \tvalid accuracy 0.9381\n",
      "epoch: 2 \tstep: 50 / 232 \ttrain loss: 0.0965 \ttrain accuracy: 0.9609 \ttime: 8.1114 s\n",
      "epoch: 2 \tstep: 100 / 232 \ttrain loss: 0.0415 \ttrain accuracy: 0.9844 \ttime: 8.0544 s\n",
      "epoch: 2 \tstep: 150 / 232 \ttrain loss: 0.0861 \ttrain accuracy: 0.9688 \ttime: 8.1000 s\n",
      "epoch: 2 \tstep: 200 / 232 \ttrain loss: 0.0269 \ttrain accuracy: 0.9922 \ttime: 8.4602 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674f84e57b5f474ab238b57f8841c72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.0720 \tvalid loss: 0.0609 \ttrain accuracy 0.9752 \tvalid accuracy 0.9778\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 232 \ttrain loss: 0.0845 \ttrain accuracy: 0.9844 \ttime: 8.0164 s\n",
      "epoch: 3 \tstep: 100 / 232 \ttrain loss: 0.0434 \ttrain accuracy: 0.9844 \ttime: 8.1047 s\n",
      "epoch: 3 \tstep: 150 / 232 \ttrain loss: 0.0427 \ttrain accuracy: 0.9844 \ttime: 13.4734 s\n",
      "epoch: 3 \tstep: 200 / 232 \ttrain loss: 0.0443 \ttrain accuracy: 0.9922 \ttime: 8.0641 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1723c5a2da93439f8d9765a7bf90865d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.0474 \tvalid loss: 0.0608 \ttrain accuracy 0.9847 \tvalid accuracy 0.9788\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 232 \ttrain loss: 0.0034 \ttrain accuracy: 1.0000 \ttime: 8.0220 s\n",
      "epoch: 4 \tstep: 100 / 232 \ttrain loss: 0.0062 \ttrain accuracy: 1.0000 \ttime: 8.1576 s\n",
      "epoch: 4 \tstep: 150 / 232 \ttrain loss: 0.0165 \ttrain accuracy: 1.0000 \ttime: 8.3100 s\n",
      "epoch: 4 \tstep: 200 / 232 \ttrain loss: 0.0307 \ttrain accuracy: 0.9844 \ttime: 8.0845 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba89b8eedd2d4797815eff5f85e9f578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.0293 \tvalid loss: 0.0520 \ttrain accuracy 0.9905 \tvalid accuracy 0.9842\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 232 \ttrain loss: 0.0086 \ttrain accuracy: 1.0000 \ttime: 8.2265 s\n",
      "epoch: 5 \tstep: 100 / 232 \ttrain loss: 0.0271 \ttrain accuracy: 0.9922 \ttime: 8.1987 s\n",
      "epoch: 5 \tstep: 150 / 232 \ttrain loss: 0.0061 \ttrain accuracy: 1.0000 \ttime: 7.9541 s\n",
      "epoch: 5 \tstep: 200 / 232 \ttrain loss: 0.0219 \ttrain accuracy: 0.9922 \ttime: 8.1095 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4322843e37924ab7bd670adf0bdbe30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.0208 \tvalid loss: 0.0576 \ttrain accuracy 0.9932 \tvalid accuracy 0.9806\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 6 \tstep: 50 / 232 \ttrain loss: 0.0083 \ttrain accuracy: 0.9922 \ttime: 8.0800 s\n",
      "epoch: 6 \tstep: 100 / 232 \ttrain loss: 0.0030 \ttrain accuracy: 1.0000 \ttime: 8.3175 s\n",
      "epoch: 6 \tstep: 150 / 232 \ttrain loss: 0.0252 \ttrain accuracy: 0.9922 \ttime: 8.1200 s\n",
      "epoch: 6 \tstep: 200 / 232 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 8.3788 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc727477af174741939f10b35580a8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.0128 \tvalid loss: 0.0529 \ttrain accuracy 0.9961 \tvalid accuracy 0.9846\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 7 \tstep: 50 / 232 \ttrain loss: 0.0393 \ttrain accuracy: 0.9844 \ttime: 8.6201 s\n",
      "epoch: 7 \tstep: 100 / 232 \ttrain loss: 0.0152 \ttrain accuracy: 0.9922 \ttime: 8.0534 s\n",
      "epoch: 7 \tstep: 150 / 232 \ttrain loss: 0.0174 \ttrain accuracy: 0.9922 \ttime: 8.4396 s\n",
      "epoch: 7 \tstep: 200 / 232 \ttrain loss: 0.0170 \ttrain accuracy: 0.9922 \ttime: 9.0165 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6047947c5604d51b06674560955c9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.0124 \tvalid loss: 0.0685 \ttrain accuracy 0.9961 \tvalid accuracy 0.9820\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 8 \tstep: 50 / 232 \ttrain loss: 0.0030 \ttrain accuracy: 1.0000 \ttime: 9.4079 s\n",
      "epoch: 8 \tstep: 100 / 232 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 9.3728 s\n",
      "epoch: 8 \tstep: 150 / 232 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 9.4807 s\n",
      "epoch: 8 \tstep: 200 / 232 \ttrain loss: 0.0186 \ttrain accuracy: 0.9922 \ttime: 9.5103 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0522672e4e24b7a9c80024ac39d0f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.0034 \tvalid loss: 0.0653 \ttrain accuracy 0.9991 \tvalid accuracy 0.9848\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5b27ee25c74aa5ac54619ac17e752a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.0569 \ttest accuracy 0.9824\n"
     ]
    }
   ],
   "source": [
    "# запускаем модель \n",
    "run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9ed6bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_accuracy = 0.9824"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d967dcc",
   "metadata": {},
   "source": [
    "__Вывод:__ Модель с использованием свёрточной нейронной сети, показала метрику accuracy = 0.9824 на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a97e48c",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2683dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    '''\n",
    "    Задаем класс модели для обучения.\n",
    "    На вход получает число скрытых слоев, размер словаря, количество классов,\n",
    "    коэффициент исключения нейронов, количество слоев LSTM.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, hidden_dim, vocab_size, num_classes=2, dropout=0.1, num_layers=2, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc_mid = nn.Linear(hidden_dim*4, hidden_dim*2)\n",
    "        self.fc_out = nn.Linear(hidden_dim*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # содержит выходные обкекты (h_t) из последнего слоя LSTM, для каждого t: [B, SEQ, hidden * bidirect]\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        avg_pool = torch.mean(x, dim=1)\n",
    "        max_pool = torch.max(x, dim=1)[0]\n",
    "        \n",
    "        x = torch.cat((avg_pool, max_pool), dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc_mid(self.dropout(x)))\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9dd1048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(hidden_dim=64, vocab_size=len(vocabulary), dropout=0.3, num_layers=1).to(device) # модель\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # функция потерь\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.00005) # оптимизатор\n",
    "\n",
    "# автоматическое регулирование скорости обучения\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5) \n",
    "\n",
    "stopper = EarlyStopping(patience=4) # ранняя остановка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da026279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 232 \ttrain loss: 0.6481 \ttrain accuracy: 0.6016 \ttime: 6.1293 s\n",
      "epoch: 1 \tstep: 100 / 232 \ttrain loss: 0.5699 \ttrain accuracy: 0.6875 \ttime: 6.5230 s\n",
      "epoch: 1 \tstep: 150 / 232 \ttrain loss: 0.5840 \ttrain accuracy: 0.6953 \ttime: 10.6645 s\n",
      "epoch: 1 \tstep: 200 / 232 \ttrain loss: 0.4407 \ttrain accuracy: 0.8047 \ttime: 8.6779 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9556950a4d7f40dba6f34fbad3271dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 0.5603 \tvalid loss: 0.3800 \ttrain accuracy 0.7084 \tvalid accuracy 0.8536\n",
      "epoch: 2 \tstep: 50 / 232 \ttrain loss: 0.2845 \ttrain accuracy: 0.8984 \ttime: 9.7362 s\n",
      "epoch: 2 \tstep: 100 / 232 \ttrain loss: 0.2995 \ttrain accuracy: 0.8906 \ttime: 7.3025 s\n",
      "epoch: 2 \tstep: 150 / 232 \ttrain loss: 0.2514 \ttrain accuracy: 0.9062 \ttime: 10.0863 s\n",
      "epoch: 2 \tstep: 200 / 232 \ttrain loss: 0.2149 \ttrain accuracy: 0.8906 \ttime: 6.3716 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728460ccaddd4abdb4855b395c95aebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.2573 \tvalid loss: 0.1719 \ttrain accuracy 0.8970 \tvalid accuracy 0.9293\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 232 \ttrain loss: 0.1225 \ttrain accuracy: 0.9609 \ttime: 6.2846 s\n",
      "epoch: 3 \tstep: 100 / 232 \ttrain loss: 0.1408 \ttrain accuracy: 0.9141 \ttime: 6.2048 s\n",
      "epoch: 3 \tstep: 150 / 232 \ttrain loss: 0.1131 \ttrain accuracy: 0.9688 \ttime: 6.2351 s\n",
      "epoch: 3 \tstep: 200 / 232 \ttrain loss: 0.1274 \ttrain accuracy: 0.9609 \ttime: 6.2526 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbef94a0d0548d0a380b732872f848a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.1518 \tvalid loss: 0.1339 \ttrain accuracy 0.9396 \tvalid accuracy 0.9485\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 232 \ttrain loss: 0.1135 \ttrain accuracy: 0.9453 \ttime: 6.7062 s\n",
      "epoch: 4 \tstep: 100 / 232 \ttrain loss: 0.1351 \ttrain accuracy: 0.9609 \ttime: 6.3079 s\n",
      "epoch: 4 \tstep: 150 / 232 \ttrain loss: 0.0967 \ttrain accuracy: 0.9766 \ttime: 7.6738 s\n",
      "epoch: 4 \tstep: 200 / 232 \ttrain loss: 0.0875 \ttrain accuracy: 0.9609 \ttime: 6.3294 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55db6b9176f941679b2e9078fff74416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.1158 \tvalid loss: 0.1089 \ttrain accuracy 0.9548 \tvalid accuracy 0.9601\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 232 \ttrain loss: 0.1179 \ttrain accuracy: 0.9531 \ttime: 6.7875 s\n",
      "epoch: 5 \tstep: 100 / 232 \ttrain loss: 0.0642 \ttrain accuracy: 0.9766 \ttime: 6.3470 s\n",
      "epoch: 5 \tstep: 150 / 232 \ttrain loss: 0.1051 \ttrain accuracy: 0.9609 \ttime: 6.5678 s\n",
      "epoch: 5 \tstep: 200 / 232 \ttrain loss: 0.0233 \ttrain accuracy: 1.0000 \ttime: 7.4911 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5113347a3f445e996af696eddb6dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.0969 \tvalid loss: 0.0944 \ttrain accuracy 0.9635 \tvalid accuracy 0.9651\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 232 \ttrain loss: 0.0755 \ttrain accuracy: 0.9688 \ttime: 6.4243 s\n",
      "epoch: 6 \tstep: 100 / 232 \ttrain loss: 0.0905 \ttrain accuracy: 0.9688 \ttime: 6.7248 s\n",
      "epoch: 6 \tstep: 150 / 232 \ttrain loss: 0.0600 \ttrain accuracy: 0.9766 \ttime: 6.4685 s\n",
      "epoch: 6 \tstep: 200 / 232 \ttrain loss: 0.0504 \ttrain accuracy: 0.9922 \ttime: 6.2386 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f10465a94bf4176afd89a19ca87fdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.0827 \tvalid loss: 0.0896 \ttrain accuracy 0.9690 \tvalid accuracy 0.9674\n",
      "Model saved to: model.pth\n",
      "epoch: 7 \tstep: 50 / 232 \ttrain loss: 0.0359 \ttrain accuracy: 0.9844 \ttime: 7.7824 s\n",
      "epoch: 7 \tstep: 100 / 232 \ttrain loss: 0.0397 \ttrain accuracy: 0.9922 \ttime: 7.3106 s\n",
      "epoch: 7 \tstep: 150 / 232 \ttrain loss: 0.0811 \ttrain accuracy: 0.9922 \ttime: 6.0833 s\n",
      "epoch: 7 \tstep: 200 / 232 \ttrain loss: 0.0561 \ttrain accuracy: 0.9766 \ttime: 6.2173 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5346b0319e54fdabb635ccbeed1534b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.0725 \tvalid loss: 0.0805 \ttrain accuracy 0.9745 \tvalid accuracy 0.9730\n",
      "Model saved to: model.pth\n",
      "epoch: 8 \tstep: 50 / 232 \ttrain loss: 0.0984 \ttrain accuracy: 0.9688 \ttime: 8.6918 s\n",
      "epoch: 8 \tstep: 100 / 232 \ttrain loss: 0.0394 \ttrain accuracy: 0.9766 \ttime: 8.5710 s\n",
      "epoch: 8 \tstep: 150 / 232 \ttrain loss: 0.1424 \ttrain accuracy: 0.9531 \ttime: 6.2357 s\n",
      "epoch: 8 \tstep: 200 / 232 \ttrain loss: 0.0600 \ttrain accuracy: 0.9766 \ttime: 21.7574 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae2bf7623504e6aa9d53c9d1e930c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.0654 \tvalid loss: 0.0742 \ttrain accuracy 0.9774 \tvalid accuracy 0.9730\n",
      "Model saved to: model.pth\n",
      "epoch: 9 \tstep: 50 / 232 \ttrain loss: 0.0933 \ttrain accuracy: 0.9844 \ttime: 6.2842 s\n",
      "epoch: 9 \tstep: 100 / 232 \ttrain loss: 0.0636 \ttrain accuracy: 0.9766 \ttime: 6.1904 s\n",
      "epoch: 9 \tstep: 150 / 232 \ttrain loss: 0.1429 \ttrain accuracy: 0.9609 \ttime: 6.5261 s\n",
      "epoch: 9 \tstep: 200 / 232 \ttrain loss: 0.0988 \ttrain accuracy: 0.9531 \ttime: 9.7865 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a16484d4e64939a74f81308f02e0ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.0589 \tvalid loss: 0.0725 \ttrain accuracy 0.9794 \tvalid accuracy 0.9746\n",
      "Model saved to: model.pth\n",
      "epoch: 10 \tstep: 50 / 232 \ttrain loss: 0.0256 \ttrain accuracy: 0.9922 \ttime: 6.2988 s\n",
      "epoch: 10 \tstep: 100 / 232 \ttrain loss: 0.0117 \ttrain accuracy: 1.0000 \ttime: 6.3697 s\n",
      "epoch: 10 \tstep: 150 / 232 \ttrain loss: 0.0172 \ttrain accuracy: 1.0000 \ttime: 6.4518 s\n",
      "epoch: 10 \tstep: 200 / 232 \ttrain loss: 0.1027 \ttrain accuracy: 0.9766 \ttime: 6.4612 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebc0b911ea6430e9ffe8b9b8007cd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.0538 \tvalid loss: 0.0675 \ttrain accuracy 0.9815 \tvalid accuracy 0.9764\n",
      "Model saved to: model.pth\n",
      "epoch: 11 \tstep: 50 / 232 \ttrain loss: 0.0754 \ttrain accuracy: 0.9688 \ttime: 6.2541 s\n",
      "epoch: 11 \tstep: 100 / 232 \ttrain loss: 0.0915 \ttrain accuracy: 0.9531 \ttime: 6.5722 s\n",
      "epoch: 11 \tstep: 150 / 232 \ttrain loss: 0.0463 \ttrain accuracy: 0.9844 \ttime: 8.3983 s\n",
      "epoch: 11 \tstep: 200 / 232 \ttrain loss: 0.0631 \ttrain accuracy: 0.9844 \ttime: 6.0719 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9257b408504bed8ab0f6f472633227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 40 \ttrain loss: 0.0485 \tvalid loss: 0.0660 \ttrain accuracy 0.9839 \tvalid accuracy 0.9764\n",
      "Model saved to: model.pth\n",
      "epoch: 12 \tstep: 50 / 232 \ttrain loss: 0.0143 \ttrain accuracy: 1.0000 \ttime: 6.2025 s\n",
      "epoch: 12 \tstep: 100 / 232 \ttrain loss: 0.0965 \ttrain accuracy: 0.9688 \ttime: 6.1921 s\n",
      "epoch: 12 \tstep: 150 / 232 \ttrain loss: 0.0830 \ttrain accuracy: 0.9766 \ttime: 8.6211 s\n",
      "epoch: 12 \tstep: 200 / 232 \ttrain loss: 0.0286 \ttrain accuracy: 0.9922 \ttime: 6.1767 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc2ebf007ff4b4ba68d2fc38d7bcb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 40 \ttrain loss: 0.0437 \tvalid loss: 0.0654 \ttrain accuracy 0.9852 \tvalid accuracy 0.9780\n",
      "Model saved to: model.pth\n",
      "epoch: 13 \tstep: 50 / 232 \ttrain loss: 0.0172 \ttrain accuracy: 0.9922 \ttime: 8.9077 s\n",
      "epoch: 13 \tstep: 100 / 232 \ttrain loss: 0.0105 \ttrain accuracy: 1.0000 \ttime: 6.1552 s\n",
      "epoch: 13 \tstep: 150 / 232 \ttrain loss: 0.0946 \ttrain accuracy: 0.9688 \ttime: 6.2613 s\n",
      "epoch: 13 \tstep: 200 / 232 \ttrain loss: 0.0134 \ttrain accuracy: 1.0000 \ttime: 6.2364 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d4ec0d54ff40abbc9f71b3e5a6d084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 / 40 \ttrain loss: 0.0397 \tvalid loss: 0.0682 \ttrain accuracy 0.9864 \tvalid accuracy 0.9766\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 14 \tstep: 50 / 232 \ttrain loss: 0.0522 \ttrain accuracy: 0.9844 \ttime: 23.2903 s\n",
      "epoch: 14 \tstep: 100 / 232 \ttrain loss: 0.0194 \ttrain accuracy: 0.9922 \ttime: 8.7159 s\n",
      "epoch: 14 \tstep: 150 / 232 \ttrain loss: 0.0062 \ttrain accuracy: 1.0000 \ttime: 8.7650 s\n",
      "epoch: 14 \tstep: 200 / 232 \ttrain loss: 0.0787 \ttrain accuracy: 0.9766 \ttime: 8.3992 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0c5fafc2404cc8a65d24f88ddda578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 / 40 \ttrain loss: 0.0372 \tvalid loss: 0.0638 \ttrain accuracy 0.9875 \tvalid accuracy 0.9786\n",
      "Model saved to: model.pth\n",
      "epoch: 15 \tstep: 50 / 232 \ttrain loss: 0.0698 \ttrain accuracy: 0.9766 \ttime: 9.2408 s\n",
      "epoch: 15 \tstep: 100 / 232 \ttrain loss: 0.0133 \ttrain accuracy: 1.0000 \ttime: 6.2243 s\n",
      "epoch: 15 \tstep: 150 / 232 \ttrain loss: 0.0281 \ttrain accuracy: 0.9844 \ttime: 6.3308 s\n",
      "epoch: 15 \tstep: 200 / 232 \ttrain loss: 0.0239 \ttrain accuracy: 0.9922 \ttime: 11.7388 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf8ec07c4524c4d89d2db7051c05658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 / 40 \ttrain loss: 0.0335 \tvalid loss: 0.0617 \ttrain accuracy 0.9895 \tvalid accuracy 0.9800\n",
      "Model saved to: model.pth\n",
      "epoch: 16 \tstep: 50 / 232 \ttrain loss: 0.0685 \ttrain accuracy: 0.9844 \ttime: 11.3682 s\n",
      "epoch: 16 \tstep: 100 / 232 \ttrain loss: 0.0546 \ttrain accuracy: 0.9844 \ttime: 13.0072 s\n",
      "epoch: 16 \tstep: 150 / 232 \ttrain loss: 0.0111 \ttrain accuracy: 1.0000 \ttime: 8.2636 s\n",
      "epoch: 16 \tstep: 200 / 232 \ttrain loss: 0.0456 \ttrain accuracy: 0.9766 \ttime: 6.2478 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdca579f3c3e4c30a39c031dd8d9e8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 / 40 \ttrain loss: 0.0320 \tvalid loss: 0.0609 \ttrain accuracy 0.9901 \tvalid accuracy 0.9798\n",
      "Model saved to: model.pth\n",
      "epoch: 17 \tstep: 50 / 232 \ttrain loss: 0.0165 \ttrain accuracy: 0.9922 \ttime: 17.7868 s\n",
      "epoch: 17 \tstep: 100 / 232 \ttrain loss: 0.0220 \ttrain accuracy: 0.9844 \ttime: 8.4938 s\n",
      "epoch: 17 \tstep: 150 / 232 \ttrain loss: 0.0377 \ttrain accuracy: 0.9922 \ttime: 10.4985 s\n",
      "epoch: 17 \tstep: 200 / 232 \ttrain loss: 0.0503 \ttrain accuracy: 0.9766 \ttime: 8.7845 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a3f87524b44860b60a5a1e207d8244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 / 40 \ttrain loss: 0.0291 \tvalid loss: 0.0659 \ttrain accuracy 0.9911 \tvalid accuracy 0.9802\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 18 \tstep: 50 / 232 \ttrain loss: 0.0962 \ttrain accuracy: 0.9688 \ttime: 6.2183 s\n",
      "epoch: 18 \tstep: 100 / 232 \ttrain loss: 0.0571 \ttrain accuracy: 0.9844 \ttime: 8.5198 s\n",
      "epoch: 18 \tstep: 150 / 232 \ttrain loss: 0.0313 \ttrain accuracy: 0.9844 \ttime: 6.0515 s\n",
      "epoch: 18 \tstep: 200 / 232 \ttrain loss: 0.0185 \ttrain accuracy: 0.9922 \ttime: 10.2016 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78a4ada856841ac93afc4fdb7620ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 / 40 \ttrain loss: 0.0274 \tvalid loss: 0.0690 \ttrain accuracy 0.9913 \tvalid accuracy 0.9792\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 19 \tstep: 50 / 232 \ttrain loss: 0.0034 \ttrain accuracy: 1.0000 \ttime: 8.5130 s\n",
      "epoch: 19 \tstep: 100 / 232 \ttrain loss: 0.0292 \ttrain accuracy: 0.9844 \ttime: 8.5511 s\n",
      "epoch: 19 \tstep: 150 / 232 \ttrain loss: 0.0142 \ttrain accuracy: 1.0000 \ttime: 8.5452 s\n",
      "epoch: 19 \tstep: 200 / 232 \ttrain loss: 0.0119 \ttrain accuracy: 1.0000 \ttime: 6.1522 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b665f44441834207adea7895aeffd503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 / 40 \ttrain loss: 0.0249 \tvalid loss: 0.0615 \ttrain accuracy 0.9922 \tvalid accuracy 0.9802\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 20 \tstep: 50 / 232 \ttrain loss: 0.0073 \ttrain accuracy: 1.0000 \ttime: 8.7509 s\n",
      "epoch: 20 \tstep: 100 / 232 \ttrain loss: 0.0196 \ttrain accuracy: 0.9922 \ttime: 6.9399 s\n",
      "epoch: 20 \tstep: 150 / 232 \ttrain loss: 0.0156 \ttrain accuracy: 0.9922 \ttime: 6.2767 s\n",
      "epoch: 20 \tstep: 200 / 232 \ttrain loss: 0.0239 \ttrain accuracy: 0.9922 \ttime: 7.6914 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878fde1d936c4c88b2c08f778dd016f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20 / 40 \ttrain loss: 0.0206 \tvalid loss: 0.0618 \ttrain accuracy 0.9942 \tvalid accuracy 0.9816\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2544776ec2f542c5b130b5d3a3b13693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.0658 \ttest accuracy 0.9774\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "71a63e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_accuracy = 0.9774"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ed2db",
   "metadata": {},
   "source": [
    "__Вывод:__ Модель с использованием двунаправленной рекурентной нейронной сети, показала метрику accuracy = 0.9774 на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a047fcb",
   "metadata": {},
   "source": [
    "### LSTM + PackedSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "370d2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, vocab_size, num_classes=2, dropout=0.1, bilstm=True, num_layers=2, **kwargs):\n",
    "        super(BiLSTM, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=bilstm,\n",
    "                            dropout=dropout,\n",
    "                            bidirectional=True)\n",
    "        scale = 2 if bilstm else 1\n",
    "        self.pool = nn.AdaptiveAvgPool1d(5)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.fc_mid = nn.Linear(hidden_dim*10, hidden_dim*scale)\n",
    "        self.fc_out = nn.Linear(hidden_dim*scale, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        text_lengths = torch.sum((x != PAD_IDX).type(torch.int32), dim=1)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        # ignore padding\n",
    "        packed_embedded = pack_padded_sequence(x, text_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        packed_output, (hidden_state, cell_state) = self.lstm(packed_embedded)\n",
    "        \n",
    "        output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        output = output.contiguous().transpose(1,2)\n",
    "        output = self.pool(output)\n",
    "\n",
    "        output = output.contiguous().view(batch_size, -1)\n",
    "\n",
    "        x = F.relu(self.fc_mid(self.dropout(output)))\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "337fa3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(hidden_dim=64, vocab_size=len(vocabulary), dropout=0.3, num_layers=1).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.00005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2ba5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 232 \ttrain loss: 0.6665 \ttrain accuracy: 0.7031 \ttime: 15.0484 s\n",
      "epoch: 1 \tstep: 100 / 232 \ttrain loss: 0.6179 \ttrain accuracy: 0.6250 \ttime: 14.6574 s\n",
      "epoch: 1 \tstep: 150 / 232 \ttrain loss: 0.4497 \ttrain accuracy: 0.8047 \ttime: 16.2791 s\n",
      "epoch: 1 \tstep: 200 / 232 \ttrain loss: 0.3202 \ttrain accuracy: 0.8828 \ttime: 14.5737 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1937c663dba94b1c908d9a8fac41740d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 0.5140 \tvalid loss: 0.2809 \ttrain accuracy 0.7565 \tvalid accuracy 0.8838\n",
      "epoch: 2 \tstep: 50 / 232 \ttrain loss: 0.2819 \ttrain accuracy: 0.9062 \ttime: 19.7574 s\n",
      "epoch: 2 \tstep: 100 / 232 \ttrain loss: 0.1381 \ttrain accuracy: 0.9609 \ttime: 12.8736 s\n",
      "epoch: 2 \tstep: 150 / 232 \ttrain loss: 0.1673 \ttrain accuracy: 0.9453 \ttime: 13.6267 s\n",
      "epoch: 2 \tstep: 200 / 232 \ttrain loss: 0.2616 \ttrain accuracy: 0.8984 \ttime: 14.1056 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb23e9dbf4d44c2a721b0a68ce8a99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.2224 \tvalid loss: 0.1929 \ttrain accuracy 0.9134 \tvalid accuracy 0.9255\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 232 \ttrain loss: 0.1895 \ttrain accuracy: 0.9297 \ttime: 17.1399 s\n",
      "epoch: 3 \tstep: 100 / 232 \ttrain loss: 0.1719 \ttrain accuracy: 0.9141 \ttime: 14.4132 s\n",
      "epoch: 3 \tstep: 150 / 232 \ttrain loss: 0.1788 \ttrain accuracy: 0.9141 \ttime: 17.7602 s\n",
      "epoch: 3 \tstep: 200 / 232 \ttrain loss: 0.0968 \ttrain accuracy: 0.9609 \ttime: 20.7580 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819a1426709e4359909f880076d7165b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.1609 \tvalid loss: 0.1491 \ttrain accuracy 0.9388 \tvalid accuracy 0.9443\n",
      "Model saved to: model.pth\n",
      "epoch: 4 \tstep: 50 / 232 \ttrain loss: 0.1362 \ttrain accuracy: 0.9531 \ttime: 21.3799 s\n",
      "epoch: 4 \tstep: 100 / 232 \ttrain loss: 0.1787 \ttrain accuracy: 0.8906 \ttime: 19.5928 s\n",
      "epoch: 4 \tstep: 150 / 232 \ttrain loss: 0.1378 \ttrain accuracy: 0.9297 \ttime: 16.3783 s\n",
      "epoch: 4 \tstep: 200 / 232 \ttrain loss: 0.1508 \ttrain accuracy: 0.9297 \ttime: 25.7973 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dad2471b8fe4699be6e475b0ad3dfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.1276 \tvalid loss: 0.1244 \ttrain accuracy 0.9538 \tvalid accuracy 0.9545\n",
      "Model saved to: model.pth\n",
      "epoch: 5 \tstep: 50 / 232 \ttrain loss: 0.1169 \ttrain accuracy: 0.9531 \ttime: 23.6229 s\n",
      "epoch: 5 \tstep: 100 / 232 \ttrain loss: 0.0954 \ttrain accuracy: 0.9688 \ttime: 17.5159 s\n",
      "epoch: 5 \tstep: 150 / 232 \ttrain loss: 0.1175 \ttrain accuracy: 0.9531 \ttime: 29.0768 s\n",
      "epoch: 5 \tstep: 200 / 232 \ttrain loss: 0.0975 \ttrain accuracy: 0.9688 \ttime: 17.5642 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a1ce94e0504c2497b0f0fd1b4aac5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.1021 \tvalid loss: 0.1098 \ttrain accuracy 0.9641 \tvalid accuracy 0.9627\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 232 \ttrain loss: 0.1199 \ttrain accuracy: 0.9531 \ttime: 18.3940 s\n",
      "epoch: 6 \tstep: 100 / 232 \ttrain loss: 0.0369 \ttrain accuracy: 0.9922 \ttime: 17.9407 s\n",
      "epoch: 6 \tstep: 150 / 232 \ttrain loss: 0.0559 \ttrain accuracy: 0.9766 \ttime: 19.0594 s\n",
      "epoch: 6 \tstep: 200 / 232 \ttrain loss: 0.0953 \ttrain accuracy: 0.9688 \ttime: 17.3719 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99d7dd335674f59a5ebb4157ec86c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.0855 \tvalid loss: 0.0969 \ttrain accuracy 0.9705 \tvalid accuracy 0.9685\n",
      "Model saved to: model.pth\n",
      "epoch: 7 \tstep: 50 / 232 \ttrain loss: 0.0793 \ttrain accuracy: 0.9844 \ttime: 17.5274 s\n",
      "epoch: 7 \tstep: 100 / 232 \ttrain loss: 0.0690 \ttrain accuracy: 0.9688 \ttime: 21.9645 s\n",
      "epoch: 7 \tstep: 150 / 232 \ttrain loss: 0.0993 \ttrain accuracy: 0.9609 \ttime: 38.2360 s\n",
      "epoch: 7 \tstep: 200 / 232 \ttrain loss: 0.0282 \ttrain accuracy: 0.9922 \ttime: 21.0257 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33470770dd8e4f4a8416b453dc6b0d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.0727 \tvalid loss: 0.0878 \ttrain accuracy 0.9761 \tvalid accuracy 0.9710\n",
      "Model saved to: model.pth\n",
      "epoch: 8 \tstep: 50 / 232 \ttrain loss: 0.0463 \ttrain accuracy: 0.9766 \ttime: 23.3405 s\n",
      "epoch: 8 \tstep: 100 / 232 \ttrain loss: 0.0232 \ttrain accuracy: 0.9922 \ttime: 23.2326 s\n",
      "epoch: 8 \tstep: 150 / 232 \ttrain loss: 0.0439 \ttrain accuracy: 0.9844 \ttime: 23.8996 s\n",
      "epoch: 8 \tstep: 200 / 232 \ttrain loss: 0.0895 \ttrain accuracy: 0.9688 \ttime: 22.1955 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f92b021345845a681fa612e0820481c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.0642 \tvalid loss: 0.0798 \ttrain accuracy 0.9790 \tvalid accuracy 0.9734\n",
      "Model saved to: model.pth\n",
      "epoch: 9 \tstep: 50 / 232 \ttrain loss: 0.0248 \ttrain accuracy: 1.0000 \ttime: 24.2041 s\n",
      "epoch: 9 \tstep: 100 / 232 \ttrain loss: 0.0293 \ttrain accuracy: 0.9922 \ttime: 50.5798 s\n",
      "epoch: 9 \tstep: 150 / 232 \ttrain loss: 0.0249 \ttrain accuracy: 1.0000 \ttime: 20.9955 s\n",
      "epoch: 9 \tstep: 200 / 232 \ttrain loss: 0.0207 \ttrain accuracy: 1.0000 \ttime: 18.8041 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1da44cfa30c475ba6019bdf7106ed1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.0559 \tvalid loss: 0.0761 \ttrain accuracy 0.9817 \tvalid accuracy 0.9762\n",
      "Model saved to: model.pth\n",
      "epoch: 10 \tstep: 50 / 232 \ttrain loss: 0.0751 \ttrain accuracy: 0.9531 \ttime: 18.8670 s\n",
      "epoch: 10 \tstep: 100 / 232 \ttrain loss: 0.0198 \ttrain accuracy: 1.0000 \ttime: 21.4892 s\n",
      "epoch: 10 \tstep: 150 / 232 \ttrain loss: 0.0195 \ttrain accuracy: 1.0000 \ttime: 18.6502 s\n",
      "epoch: 10 \tstep: 200 / 232 \ttrain loss: 0.0471 \ttrain accuracy: 0.9844 \ttime: 20.3025 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3083a0dae9094caeaf6f55be84528e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.0498 \tvalid loss: 0.0754 \ttrain accuracy 0.9840 \tvalid accuracy 0.9776\n",
      "Model saved to: model.pth\n",
      "epoch: 11 \tstep: 50 / 232 \ttrain loss: 0.0240 \ttrain accuracy: 1.0000 \ttime: 32.5109 s\n",
      "epoch: 11 \tstep: 100 / 232 \ttrain loss: 0.0626 \ttrain accuracy: 0.9844 \ttime: 20.4621 s\n",
      "epoch: 11 \tstep: 150 / 232 \ttrain loss: 0.0665 \ttrain accuracy: 0.9844 \ttime: 17.5531 s\n",
      "epoch: 11 \tstep: 200 / 232 \ttrain loss: 0.0507 \ttrain accuracy: 0.9766 \ttime: 17.9953 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5e6e49c04d435db6044572c5691ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 40 \ttrain loss: 0.0455 \tvalid loss: 0.0704 \ttrain accuracy 0.9859 \tvalid accuracy 0.9782\n",
      "Model saved to: model.pth\n",
      "epoch: 12 \tstep: 50 / 232 \ttrain loss: 0.0296 \ttrain accuracy: 1.0000 \ttime: 16.1950 s\n",
      "epoch: 12 \tstep: 100 / 232 \ttrain loss: 0.0368 \ttrain accuracy: 0.9922 \ttime: 17.2180 s\n",
      "epoch: 12 \tstep: 150 / 232 \ttrain loss: 0.1133 \ttrain accuracy: 0.9453 \ttime: 17.5093 s\n",
      "epoch: 12 \tstep: 200 / 232 \ttrain loss: 0.0598 \ttrain accuracy: 0.9688 \ttime: 17.8107 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0c05c2db2b4663bfdc74302d62f4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 40 \ttrain loss: 0.0397 \tvalid loss: 0.0701 \ttrain accuracy 0.9879 \tvalid accuracy 0.9792\n",
      "Model saved to: model.pth\n",
      "epoch: 13 \tstep: 50 / 232 \ttrain loss: 0.0515 \ttrain accuracy: 0.9766 \ttime: 18.7880 s\n",
      "epoch: 13 \tstep: 100 / 232 \ttrain loss: 0.0209 \ttrain accuracy: 0.9922 \ttime: 13.8149 s\n",
      "epoch: 13 \tstep: 150 / 232 \ttrain loss: 0.0180 \ttrain accuracy: 1.0000 \ttime: 20.9275 s\n",
      "epoch: 13 \tstep: 200 / 232 \ttrain loss: 0.0494 \ttrain accuracy: 0.9922 \ttime: 17.4911 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68512009a1404f42b1b53f0d6dbd048b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 / 40 \ttrain loss: 0.0355 \tvalid loss: 0.0675 \ttrain accuracy 0.9898 \tvalid accuracy 0.9806\n",
      "Model saved to: model.pth\n",
      "epoch: 14 \tstep: 50 / 232 \ttrain loss: 0.0933 \ttrain accuracy: 0.9688 \ttime: 28.0987 s\n",
      "epoch: 14 \tstep: 100 / 232 \ttrain loss: 0.0183 \ttrain accuracy: 1.0000 \ttime: 17.1890 s\n",
      "epoch: 14 \tstep: 150 / 232 \ttrain loss: 0.0988 \ttrain accuracy: 0.9844 \ttime: 23.5433 s\n",
      "epoch: 14 \tstep: 200 / 232 \ttrain loss: 0.0228 \ttrain accuracy: 0.9922 \ttime: 23.9568 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13ec8b280004cfbaabb42943002bea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 / 40 \ttrain loss: 0.0326 \tvalid loss: 0.0675 \ttrain accuracy 0.9904 \tvalid accuracy 0.9804\n",
      "Model saved to: model.pth\n",
      "epoch: 15 \tstep: 50 / 232 \ttrain loss: 0.0342 \ttrain accuracy: 0.9922 \ttime: 36.9303 s\n",
      "epoch: 15 \tstep: 100 / 232 \ttrain loss: 0.0300 \ttrain accuracy: 0.9844 \ttime: 48.5300 s\n",
      "epoch: 15 \tstep: 150 / 232 \ttrain loss: 0.0103 \ttrain accuracy: 1.0000 \ttime: 15.9204 s\n",
      "epoch: 15 \tstep: 200 / 232 \ttrain loss: 0.0330 \ttrain accuracy: 0.9766 \ttime: 17.3209 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57eaf1d3fe2d4943862b470f6d2166b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 / 40 \ttrain loss: 0.0290 \tvalid loss: 0.0667 \ttrain accuracy 0.9914 \tvalid accuracy 0.9822\n",
      "Model saved to: model.pth\n",
      "epoch: 16 \tstep: 50 / 232 \ttrain loss: 0.0464 \ttrain accuracy: 0.9922 \ttime: 18.0700 s\n",
      "epoch: 16 \tstep: 100 / 232 \ttrain loss: 0.0130 \ttrain accuracy: 1.0000 \ttime: 13.1500 s\n",
      "epoch: 16 \tstep: 150 / 232 \ttrain loss: 0.0256 \ttrain accuracy: 0.9922 \ttime: 13.8625 s\n",
      "epoch: 16 \tstep: 200 / 232 \ttrain loss: 0.0733 \ttrain accuracy: 0.9766 \ttime: 14.9368 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd643bea998c4b4cbb66692078fd01a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 / 40 \ttrain loss: 0.0267 \tvalid loss: 0.0715 \ttrain accuracy 0.9925 \tvalid accuracy 0.9814\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 17 \tstep: 50 / 232 \ttrain loss: 0.0449 \ttrain accuracy: 0.9922 \ttime: 13.2858 s\n",
      "epoch: 17 \tstep: 100 / 232 \ttrain loss: 0.0108 \ttrain accuracy: 1.0000 \ttime: 17.7096 s\n",
      "epoch: 17 \tstep: 150 / 232 \ttrain loss: 0.0706 \ttrain accuracy: 0.9922 \ttime: 14.1973 s\n",
      "epoch: 17 \tstep: 200 / 232 \ttrain loss: 0.0083 \ttrain accuracy: 1.0000 \ttime: 13.2331 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371bd21d414745a288ccc8880423e684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 / 40 \ttrain loss: 0.0248 \tvalid loss: 0.0676 \ttrain accuracy 0.9928 \tvalid accuracy 0.9828\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 18 \tstep: 50 / 232 \ttrain loss: 0.0088 \ttrain accuracy: 1.0000 \ttime: 14.3880 s\n",
      "epoch: 18 \tstep: 100 / 232 \ttrain loss: 0.0870 \ttrain accuracy: 0.9844 \ttime: 13.1519 s\n",
      "epoch: 18 \tstep: 150 / 232 \ttrain loss: 0.0159 \ttrain accuracy: 0.9922 \ttime: 12.4656 s\n",
      "epoch: 18 \tstep: 200 / 232 \ttrain loss: 0.0076 \ttrain accuracy: 1.0000 \ttime: 13.9992 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6d1c3c733642578caef5dceb542fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 / 40 \ttrain loss: 0.0215 \tvalid loss: 0.0691 \ttrain accuracy 0.9939 \tvalid accuracy 0.9830\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 19 \tstep: 50 / 232 \ttrain loss: 0.0103 \ttrain accuracy: 1.0000 \ttime: 13.5434 s\n",
      "epoch: 19 \tstep: 100 / 232 \ttrain loss: 0.0091 \ttrain accuracy: 1.0000 \ttime: 13.8860 s\n",
      "epoch: 19 \tstep: 150 / 232 \ttrain loss: 0.0188 \ttrain accuracy: 0.9922 \ttime: 14.1890 s\n",
      "epoch: 19 \tstep: 200 / 232 \ttrain loss: 0.0104 \ttrain accuracy: 1.0000 \ttime: 13.4550 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37c2182a2ff4e058c2b3637c482c7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 / 40 \ttrain loss: 0.0186 \tvalid loss: 0.0724 \ttrain accuracy 0.9953 \tvalid accuracy 0.9832\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf167fff9cf4131be8297e065516490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.0652 \ttest accuracy 0.9826\n"
     ]
    }
   ],
   "source": [
    "run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7c765940",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_packed_accuracy = 0.9826"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4276f1e4",
   "metadata": {},
   "source": [
    "__Вывод:__ Модель с использованием рекурентной нейронной сети и pack_padded_sequence, показала метрику accuracy = 0.9826 на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c70972",
   "metadata": {},
   "source": [
    "## Transformers + Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d931dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "masked = AutoModelForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c69aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_for_roberta(text):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for sent in tqdm(text):\n",
    "        encoded_sent = tokenizer(sent, padding='max_length', truncation=True, max_length=64)\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80086001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bert = df_train.drop(['subject', 'task', 'lemm_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9b079543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_bert.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fd824a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>равносильны уравнения cosx zero sin 2x one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>равносильны уравнения frac log x x one log x2 one log two x one one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>равносильны уравнения frac x three x three one frac x two three x two three one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>равносильны уравнения log x two x two one log xx one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>какое двух уравнений является следствием другого x two twenty five x two frac one x five twenty five frac one x five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39882</th>\n",
       "      <td>1</td>\n",
       "      <td>найдите минимальный объем выборки котором доверительной вероятностью alpha точность оценки математического ожидания длины детали генеральной совокупности выборочной средней равна beta zero twenty five генеральное среднее квадратическое отклонение sigma zero five мм длина детали х нормально распределенная случайная величина alpha zero ninety nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39883</th>\n",
       "      <td>1</td>\n",
       "      <td>найдите минимальный объем выборки котором доверительной вероятностью alpha точность оценки математического ожидания длины детали генеральной совокупности выборочной средней равна beta zero twenty five генеральное среднее квадратическое отклонение sigma zero five мм длина детали х нормально распределенная случайная величина alpha zero nine hundred and ninety nine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39884</th>\n",
       "      <td>1</td>\n",
       "      <td>лабораторная работа three задание проведите измерения толщины n спичек выбранных простым случайным бесповторным отбором three hundred four hundred спичек изготовленных одной фабрике измерения выполните микрометром ценой деления zero one мм примечание использовать данные собранные выполнении лабораторной работы two цель работы oвладение методом составления доверительных интервалов оценки математического ожидания нормального распределения неизвестном sigma оценки среднего квадратического отклонения sigma нормального распределения порядок выполнения лабораторной работы one составьте исходную таблицу n проведенных измерений выбрав следующих вариантов решения задачи таблице ниже two составьте статистическое распределение частот результатов полученных измерений three вычислите среднее арифметическое overline х b рассматриваемого признака х four вычислите исправленную среднюю квадратическую погрешность n измерений формуле s sqrt frac sum n i x i overline x b two n one five определите коэффициент стьюдента t alpha заданной доверительной вероятности alpha числа проведенных измерений таблицы six найдите границы доверительного интервала оценки математического ожидания заданной доверительной вероятности alpha используя условие sixty six seven данным alpha n найдите значение q см приложение ниже eight найдите границы доверительного интервала оценки среднего квадратического отклонения sigma заданной доверительной вероятности используя условие sixty seven примечание величина точности оценки beta t alpha frac s sqrt n должна величины погрешности прибора найдите значения коэффициента t условия phi t frac alpha two alpha zero ninety five zero ninety nine zero nine hundred and ninety nine сравните значениями коэффициента стьюдента t alpha соответствующих значениях alpha различных значениях n вывод сравнения сделать two сравните точность оценки t alpha frac s sqrt n различных значений n alpha каких условиях точность оценки увеличивается</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39885</th>\n",
       "      <td>1</td>\n",
       "      <td>большой партии изготовленных деталей выборке объема n найдена средняя арифметическая длины детали равная x b считая длина детали х нормально распределенная случайная величина найдите доверительный интервал который доверительной вероятностью alpha покрывает неизвестное математическое ожидание a длины детали генеральное среднее квадратическое отклонение sigma zero five мм overline x b fifty мм n sixty four alpha zero ninety five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39886</th>\n",
       "      <td>1</td>\n",
       "      <td>лабораторная работа four задание основании результатов экзаменационной сессии соберите данные успеваемости одному предмету признак х другому предмету признак y помощью статистических методов изучите зависимость этими величинами цель работы oвладение методами установления связи двумя случайными величинами х y большом числе наблюдений методами определения параметров выборочного уравнения прямой линии регрессии сгруппированным данным варианты лабораторной работы one соберите данные значениях признака х успеваемость математике признака y успеваемость физике студентов одной групп n twenty two соберите данные значениях признаков х y рассмотренных варианте one студентов одного курсов n forty five seventy one hundred three соберите данные значениях признака х успеваемость марксистско ленинской философии признака y успеваемость педагогике студентов одной групп four соберите данные значениях признаков х y рассмотренных варианте three студентов одного курсов примечание данные значениях признаков х y выборочно взять экзаменационных ведомостей порядок выполнения лабораторной работы one полученные данные внесите корреляционную таблицу ниже порядок заполнения клеток внутри таблицы поясним примером группе five студентов получили удовлетворительно three математике four физике уголке клетки пересечении третьей строки четвертого столбца записывается значение ху равное twelve заполнения соответствующих клеток внутри таблицы подсчитайте n x каждого x i n y каждого y i должно иметь место равенство n sum n x sum n y виду корреляционной таблицы установите форму корреляционной связи признаков х y two корреляционную таблицу дополните расчетной таблицы произведите необходимые вычисления three вычислите overline x frac sum n x x n overline y frac sum n y y n overline x two frac sum n x x two n overline y two frac sum n y y two n four найдите sigma x sigma y формулам sigma x sqrt overline x two overline x two sigma y sqrt overline y two overline y two five формуле seventy вычислите выборочный коэффициент корреляции r b установите величине степень тесноты связи six подставьте найденные величины уравнение seventy one прямой линии регрессии y х</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39887 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  \\\n",
       "0           1   \n",
       "1           1   \n",
       "2           1   \n",
       "3           1   \n",
       "4           1   \n",
       "...       ...   \n",
       "39882       1   \n",
       "39883       1   \n",
       "39884       1   \n",
       "39885       1   \n",
       "39886       1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   clean_text  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  равносильны уравнения cosx zero sin 2x one  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         равносильны уравнения frac log x x one log x2 one log two x one one  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             равносильны уравнения frac x three x three one frac x two three x two three one  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        равносильны уравнения log x two x two one log xx one  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        какое двух уравнений является следствием другого x two twenty five x two frac one x five twenty five frac one x five  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ...  \n",
       "39882                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             найдите минимальный объем выборки котором доверительной вероятностью alpha точность оценки математического ожидания длины детали генеральной совокупности выборочной средней равна beta zero twenty five генеральное среднее квадратическое отклонение sigma zero five мм длина детали х нормально распределенная случайная величина alpha zero ninety nine  \n",
       "39883                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            найдите минимальный объем выборки котором доверительной вероятностью alpha точность оценки математического ожидания длины детали генеральной совокупности выборочной средней равна beta zero twenty five генеральное среднее квадратическое отклонение sigma zero five мм длина детали х нормально распределенная случайная величина alpha zero nine hundred and ninety nine  \n",
       "39884                                                                                                                                                                                                          лабораторная работа three задание проведите измерения толщины n спичек выбранных простым случайным бесповторным отбором three hundred four hundred спичек изготовленных одной фабрике измерения выполните микрометром ценой деления zero one мм примечание использовать данные собранные выполнении лабораторной работы two цель работы oвладение методом составления доверительных интервалов оценки математического ожидания нормального распределения неизвестном sigma оценки среднего квадратического отклонения sigma нормального распределения порядок выполнения лабораторной работы one составьте исходную таблицу n проведенных измерений выбрав следующих вариантов решения задачи таблице ниже two составьте статистическое распределение частот результатов полученных измерений three вычислите среднее арифметическое overline х b рассматриваемого признака х four вычислите исправленную среднюю квадратическую погрешность n измерений формуле s sqrt frac sum n i x i overline x b two n one five определите коэффициент стьюдента t alpha заданной доверительной вероятности alpha числа проведенных измерений таблицы six найдите границы доверительного интервала оценки математического ожидания заданной доверительной вероятности alpha используя условие sixty six seven данным alpha n найдите значение q см приложение ниже eight найдите границы доверительного интервала оценки среднего квадратического отклонения sigma заданной доверительной вероятности используя условие sixty seven примечание величина точности оценки beta t alpha frac s sqrt n должна величины погрешности прибора найдите значения коэффициента t условия phi t frac alpha two alpha zero ninety five zero ninety nine zero nine hundred and ninety nine сравните значениями коэффициента стьюдента t alpha соответствующих значениях alpha различных значениях n вывод сравнения сделать two сравните точность оценки t alpha frac s sqrt n различных значений n alpha каких условиях точность оценки увеличивается  \n",
       "39885                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          большой партии изготовленных деталей выборке объема n найдена средняя арифметическая длины детали равная x b считая длина детали х нормально распределенная случайная величина найдите доверительный интервал который доверительной вероятностью alpha покрывает неизвестное математическое ожидание a длины детали генеральное среднее квадратическое отклонение sigma zero five мм overline x b fifty мм n sixty four alpha zero ninety five  \n",
       "39886  лабораторная работа four задание основании результатов экзаменационной сессии соберите данные успеваемости одному предмету признак х другому предмету признак y помощью статистических методов изучите зависимость этими величинами цель работы oвладение методами установления связи двумя случайными величинами х y большом числе наблюдений методами определения параметров выборочного уравнения прямой линии регрессии сгруппированным данным варианты лабораторной работы one соберите данные значениях признака х успеваемость математике признака y успеваемость физике студентов одной групп n twenty two соберите данные значениях признаков х y рассмотренных варианте one студентов одного курсов n forty five seventy one hundred three соберите данные значениях признака х успеваемость марксистско ленинской философии признака y успеваемость педагогике студентов одной групп four соберите данные значениях признаков х y рассмотренных варианте three студентов одного курсов примечание данные значениях признаков х y выборочно взять экзаменационных ведомостей порядок выполнения лабораторной работы one полученные данные внесите корреляционную таблицу ниже порядок заполнения клеток внутри таблицы поясним примером группе five студентов получили удовлетворительно three математике four физике уголке клетки пересечении третьей строки четвертого столбца записывается значение ху равное twelve заполнения соответствующих клеток внутри таблицы подсчитайте n x каждого x i n y каждого y i должно иметь место равенство n sum n x sum n y виду корреляционной таблицы установите форму корреляционной связи признаков х y two корреляционную таблицу дополните расчетной таблицы произведите необходимые вычисления three вычислите overline x frac sum n x x n overline y frac sum n y y n overline x two frac sum n x x two n overline y two frac sum n y y two n four найдите sigma x sigma y формулам sigma x sqrt overline x two overline x two sigma y sqrt overline y two overline y two five формуле seventy вычислите выборочный коэффициент корреляции r b установите величине степень тесноты связи six подставьте найденные величины уравнение seventy one прямой линии регрессии y х  \n",
       "\n",
       "[39887 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "89123734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим выборки на тренировочную, валидационную и тестовую\n",
    "train_bert, valid_bert = train_test_split(df_train_bert, \n",
    "                                test_size=0.25, \n",
    "                                random_state=SEED,\n",
    "                                stratify=df_train_bert['target'])\n",
    "\n",
    "valid_bert, test_bert = train_test_split(valid_bert, \n",
    "                                test_size=0.5, \n",
    "                                random_state=SEED,\n",
    "                                stratify=valid_bert['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a5419a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34221</th>\n",
       "      <td>1</td>\n",
       "      <td>докажите середины диагоналей любой трапеции лежат средней линии</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>1</td>\n",
       "      <td>цена акцию сначала снизилась ten снизилась ещё ten увеличилась twenty сколько процентов изменилась цена акции сравнению первоначальной</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17460</th>\n",
       "      <td>1</td>\n",
       "      <td>решите уравнение two sin6x sin4xsin2x cos6x cos2x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>1</td>\n",
       "      <td>пиджак стоит five thousand two hundred and fifty рублей магазине проводят распродажу скидкой fifteen сколько стоит пиджак распродаже</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>1</td>\n",
       "      <td>упростить выражение frac one b left abc a c right frac one a frac one b frac one c frac one a frac one b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>1</td>\n",
       "      <td>извлечь корень одночлена sqrt five frac a ten b fifteen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14659</th>\n",
       "      <td>0</td>\n",
       "      <td>мимо наблюдателя равномерно прямолинейно скоростью v two м движется тележка массой м one hundred кг момент тележка поравняется наблюдателем кладет ящик массой m five кг определить энергию которая процессе переходит тепло ответ укажите дж округлите десятых</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38784</th>\n",
       "      <td>1</td>\n",
       "      <td>основания трапеции равны a b середину её боковой стороны точку пересечения диагоналей проведена прямая каком отношении делит другую боковую сторону трапеции</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18619</th>\n",
       "      <td>0</td>\n",
       "      <td>баллона выпустили половину газа изменилось давление газа баллоне объясните почему</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>1</td>\n",
       "      <td>решите уравнение five x zero three x four five x two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4986 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       target  \\\n",
       "34221       1   \n",
       "2551        1   \n",
       "17460       1   \n",
       "2656        1   \n",
       "11996       1   \n",
       "...       ...   \n",
       "4928        1   \n",
       "14659       0   \n",
       "38784       1   \n",
       "18619       0   \n",
       "2122        1   \n",
       "\n",
       "                                                                                                                                                                                                                                                            clean_text  \n",
       "34221                                                                                                                                                                                                  докажите середины диагоналей любой трапеции лежат средней линии  \n",
       "2551                                                                                                                            цена акцию сначала снизилась ten снизилась ещё ten увеличилась twenty сколько процентов изменилась цена акции сравнению первоначальной  \n",
       "17460                                                                                                                                                                                                                решите уравнение two sin6x sin4xsin2x cos6x cos2x  \n",
       "2656                                                                                                                              пиджак стоит five thousand two hundred and fifty рублей магазине проводят распродажу скидкой fifteen сколько стоит пиджак распродаже  \n",
       "11996                                                                                                                                                         упростить выражение frac one b left abc a c right frac one a frac one b frac one c frac one a frac one b  \n",
       "...                                                                                                                                                                                                                                                                ...  \n",
       "4928                                                                                                                                                                                                           извлечь корень одночлена sqrt five frac a ten b fifteen  \n",
       "14659  мимо наблюдателя равномерно прямолинейно скоростью v two м движется тележка массой м one hundred кг момент тележка поравняется наблюдателем кладет ящик массой m five кг определить энергию которая процессе переходит тепло ответ укажите дж округлите десятых  \n",
       "38784                                                                                                     основания трапеции равны a b середину её боковой стороны точку пересечения диагоналей проведена прямая каком отношении делит другую боковую сторону трапеции  \n",
       "18619                                                                                                                                                                                баллона выпустили половину газа изменилось давление газа баллоне объясните почему  \n",
       "2122                                                                                                                                                                                                              решите уравнение five x zero three x four five x two  \n",
       "\n",
       "[4986 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "06bb2e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f65c3c578534ed4bfcea3f3ef293f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd3c94cbe8b642729711b48f62137b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a5a0715b5d40a4b57c09169ebed698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4986 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ids, train_masks = tokenize_for_roberta(train_bert['clean_text'].values)\n",
    "train_labels = torch.LongTensor(train_bert['target'].values)\n",
    "\n",
    "valid_ids, valid_masks = tokenize_for_roberta(valid_bert['clean_text'].values)\n",
    "valid_labels = torch.LongTensor(valid_bert['target'].values)\n",
    "\n",
    "test_ids, test_masks = tokenize_for_roberta(test_bert['clean_text'].values)\n",
    "test_labels = torch.LongTensor(test_bert['target'].values)\n",
    "\n",
    "train_ds = TensorDataset(train_ids, train_masks, train_labels)\n",
    "valid_ds = TensorDataset(valid_ids, valid_masks, valid_labels)\n",
    "test_ds = TensorDataset(test_ids, test_masks, test_labels)\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_ds, batch_size=8, shuffle=False)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eaba0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanPooling(nn.Module):\n",
    "    \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, dim=1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "\n",
    "\n",
    "class MaxPooling(nn.Module):\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        last_hidden_state[input_mask_expanded == 0] = -1e9\n",
    "        max_embeddings = torch.max(last_hidden_state, dim=1)[0]\n",
    "        return max_embeddings           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d1d1bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(nn.Module):\n",
    "    def __init__(self, extractor=None, num_classes=2, dropout=0.1, pool_type=\"max\", pool=\"feat\", **kwargs):\n",
    "        super(BertModel, self).__init__(**kwargs)\n",
    "        assert pool in [\"feat\", \"cls\"], \"set 'pool' or 'cls'\"\n",
    "        assert pool_type in [\"max\", \"mean\"], \"set pool type 'mean' or 'max'\"\n",
    "        self.pool = pool\n",
    "        \n",
    "        if extractor is None:\n",
    "            self.extractor = masked.to(device)\n",
    "        for p in self.extractor.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "        self.pooler = MaxPooling() if pool_type == \"max\" else MeanPooling()\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        \n",
    "    def forward(self, ids, mask):        \n",
    "        out = self.extractor(input_ids=ids, attention_mask=mask, output_hidden_states=True)\n",
    "        # pooler = [B, 1024] Last layer hidden-state of the first token of the sequence (classification token)\n",
    "        # maybe ruRoberta doesn't have CLS token - pooled_output in original RoBerta\n",
    "        # ruRoBerta trained to predict missing tokens in sequences of text, output: logits [B, seq, vocab]\n",
    "        if self.pool == \"cls\":\n",
    "            out = torch.cat(out.hidden_states, dim=1)[:, 0]   \n",
    "        else:\n",
    "            out = self.pooler(out.hidden_states[-1], mask)  # last layer hidden state [B, seq, hidden] - [8, 64, 1024]\n",
    "            out = self.drop(out)\n",
    "        outputs = self.fc(out)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f7a25530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(data, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    data = [d.to(device) for d in data]\n",
    "    texts, masks, labels = data\n",
    "    optimizer.zero_grad()\n",
    "    output = model(texts, masks)\n",
    "    loss = criterion(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    accuracy = calc_accuracy(output, labels)\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_batch(data, model, criterion):\n",
    "    model.eval()\n",
    "    data = [d.to(device) for d in data]\n",
    "    texts, masks, labels = data\n",
    "    \n",
    "    out = model(texts, masks)\n",
    "    loss = criterion(out, labels)\n",
    "    \n",
    "    accuracy = calc_accuracy(out, labels)\n",
    "    \n",
    "    return loss.item(), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "863cd83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = BertModel(pool_type=\"mean\", pool=\"feat\").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(roberta.fc.parameters(), lr=0.001, weight_decay=0.0005)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, min_lr=1e-7, factor=0.5)\n",
    "stopper = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9b57395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \tstep: 50 / 3740 \ttrain loss: 0.4138 \ttrain accuracy: 0.8750 \ttime: 72.5776 s\n",
      "epoch: 1 \tstep: 100 / 3740 \ttrain loss: 0.0842 \ttrain accuracy: 1.0000 \ttime: 77.6549 s\n",
      "epoch: 1 \tstep: 150 / 3740 \ttrain loss: 0.3887 \ttrain accuracy: 0.8750 \ttime: 79.9705 s\n",
      "epoch: 1 \tstep: 200 / 3740 \ttrain loss: 0.1548 \ttrain accuracy: 0.8750 \ttime: 125.1843 s\n",
      "epoch: 1 \tstep: 250 / 3740 \ttrain loss: 0.1307 \ttrain accuracy: 1.0000 \ttime: 82.2915 s\n",
      "epoch: 1 \tstep: 300 / 3740 \ttrain loss: 0.2026 \ttrain accuracy: 0.8750 \ttime: 139.9424 s\n",
      "epoch: 1 \tstep: 350 / 3740 \ttrain loss: 0.0366 \ttrain accuracy: 1.0000 \ttime: 83.9703 s\n",
      "epoch: 1 \tstep: 400 / 3740 \ttrain loss: 0.1033 \ttrain accuracy: 1.0000 \ttime: 81.0718 s\n",
      "epoch: 1 \tstep: 450 / 3740 \ttrain loss: 0.1110 \ttrain accuracy: 1.0000 \ttime: 82.0228 s\n",
      "epoch: 1 \tstep: 500 / 3740 \ttrain loss: 0.0861 \ttrain accuracy: 1.0000 \ttime: 82.5621 s\n",
      "epoch: 1 \tstep: 550 / 3740 \ttrain loss: 0.0052 \ttrain accuracy: 1.0000 \ttime: 81.3547 s\n",
      "epoch: 1 \tstep: 600 / 3740 \ttrain loss: 0.0339 \ttrain accuracy: 1.0000 \ttime: 81.2605 s\n",
      "epoch: 1 \tstep: 650 / 3740 \ttrain loss: 0.1057 \ttrain accuracy: 1.0000 \ttime: 84.9569 s\n",
      "epoch: 1 \tstep: 700 / 3740 \ttrain loss: 0.0736 \ttrain accuracy: 1.0000 \ttime: 82.1548 s\n",
      "epoch: 1 \tstep: 750 / 3740 \ttrain loss: 0.0253 \ttrain accuracy: 1.0000 \ttime: 82.5967 s\n",
      "epoch: 1 \tstep: 800 / 3740 \ttrain loss: 0.0045 \ttrain accuracy: 1.0000 \ttime: 85.1524 s\n",
      "epoch: 1 \tstep: 850 / 3740 \ttrain loss: 0.0062 \ttrain accuracy: 1.0000 \ttime: 83.0670 s\n",
      "epoch: 1 \tstep: 900 / 3740 \ttrain loss: 0.0112 \ttrain accuracy: 1.0000 \ttime: 82.7952 s\n",
      "epoch: 1 \tstep: 950 / 3740 \ttrain loss: 0.0964 \ttrain accuracy: 1.0000 \ttime: 101.1846 s\n",
      "epoch: 1 \tstep: 1000 / 3740 \ttrain loss: 0.0126 \ttrain accuracy: 1.0000 \ttime: 82.0375 s\n",
      "epoch: 1 \tstep: 1050 / 3740 \ttrain loss: 0.0036 \ttrain accuracy: 1.0000 \ttime: 104.4746 s\n",
      "epoch: 1 \tstep: 1100 / 3740 \ttrain loss: 0.0119 \ttrain accuracy: 1.0000 \ttime: 92.7534 s\n",
      "epoch: 1 \tstep: 1150 / 3740 \ttrain loss: 0.0467 \ttrain accuracy: 1.0000 \ttime: 84.1039 s\n",
      "epoch: 1 \tstep: 1200 / 3740 \ttrain loss: 0.0479 \ttrain accuracy: 1.0000 \ttime: 83.2864 s\n",
      "epoch: 1 \tstep: 1250 / 3740 \ttrain loss: 0.1040 \ttrain accuracy: 0.8750 \ttime: 81.4159 s\n",
      "epoch: 1 \tstep: 1300 / 3740 \ttrain loss: 0.2067 \ttrain accuracy: 0.8750 \ttime: 93.4566 s\n",
      "epoch: 1 \tstep: 1350 / 3740 \ttrain loss: 0.2726 \ttrain accuracy: 0.8750 \ttime: 82.8099 s\n",
      "epoch: 1 \tstep: 1400 / 3740 \ttrain loss: 0.2967 \ttrain accuracy: 0.8750 \ttime: 84.0448 s\n",
      "epoch: 1 \tstep: 1450 / 3740 \ttrain loss: 0.0529 \ttrain accuracy: 1.0000 \ttime: 81.1561 s\n",
      "epoch: 1 \tstep: 1500 / 3740 \ttrain loss: 0.0638 \ttrain accuracy: 1.0000 \ttime: 81.7022 s\n",
      "epoch: 1 \tstep: 1550 / 3740 \ttrain loss: 0.0774 \ttrain accuracy: 1.0000 \ttime: 82.2088 s\n",
      "epoch: 1 \tstep: 1600 / 3740 \ttrain loss: 0.0152 \ttrain accuracy: 1.0000 \ttime: 81.4684 s\n",
      "epoch: 1 \tstep: 1650 / 3740 \ttrain loss: 0.1865 \ttrain accuracy: 0.8750 \ttime: 80.6404 s\n",
      "epoch: 1 \tstep: 1700 / 3740 \ttrain loss: 0.0015 \ttrain accuracy: 1.0000 \ttime: 81.6599 s\n",
      "epoch: 1 \tstep: 1750 / 3740 \ttrain loss: 0.1212 \ttrain accuracy: 0.8750 \ttime: 82.0506 s\n",
      "epoch: 1 \tstep: 1800 / 3740 \ttrain loss: 0.0638 \ttrain accuracy: 1.0000 \ttime: 83.5317 s\n",
      "epoch: 1 \tstep: 1850 / 3740 \ttrain loss: 0.0490 \ttrain accuracy: 1.0000 \ttime: 87.4231 s\n",
      "epoch: 1 \tstep: 1900 / 3740 \ttrain loss: 0.0352 \ttrain accuracy: 1.0000 \ttime: 83.5310 s\n",
      "epoch: 1 \tstep: 1950 / 3740 \ttrain loss: 0.0342 \ttrain accuracy: 1.0000 \ttime: 80.8929 s\n",
      "epoch: 1 \tstep: 2000 / 3740 \ttrain loss: 0.0138 \ttrain accuracy: 1.0000 \ttime: 84.1326 s\n",
      "epoch: 1 \tstep: 2050 / 3740 \ttrain loss: 0.0265 \ttrain accuracy: 1.0000 \ttime: 82.3954 s\n",
      "epoch: 1 \tstep: 2100 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 84.0206 s\n",
      "epoch: 1 \tstep: 2150 / 3740 \ttrain loss: 0.2906 \ttrain accuracy: 0.8750 \ttime: 83.7048 s\n",
      "epoch: 1 \tstep: 2200 / 3740 \ttrain loss: 0.0172 \ttrain accuracy: 1.0000 \ttime: 81.9761 s\n",
      "epoch: 1 \tstep: 2250 / 3740 \ttrain loss: 0.0730 \ttrain accuracy: 1.0000 \ttime: 82.3054 s\n",
      "epoch: 1 \tstep: 2300 / 3740 \ttrain loss: 0.0335 \ttrain accuracy: 1.0000 \ttime: 82.3144 s\n",
      "epoch: 1 \tstep: 2350 / 3740 \ttrain loss: 0.0138 \ttrain accuracy: 1.0000 \ttime: 84.3612 s\n",
      "epoch: 1 \tstep: 2400 / 3740 \ttrain loss: 0.0092 \ttrain accuracy: 1.0000 \ttime: 80.9522 s\n",
      "epoch: 1 \tstep: 2450 / 3740 \ttrain loss: 0.0056 \ttrain accuracy: 1.0000 \ttime: 82.7071 s\n",
      "epoch: 1 \tstep: 2500 / 3740 \ttrain loss: 0.0535 \ttrain accuracy: 1.0000 \ttime: 80.0011 s\n",
      "epoch: 1 \tstep: 2550 / 3740 \ttrain loss: 0.0474 \ttrain accuracy: 1.0000 \ttime: 80.2441 s\n",
      "epoch: 1 \tstep: 2600 / 3740 \ttrain loss: 0.0033 \ttrain accuracy: 1.0000 \ttime: 117.5893 s\n",
      "epoch: 1 \tstep: 2650 / 3740 \ttrain loss: 0.4151 \ttrain accuracy: 0.8750 \ttime: 172.6687 s\n",
      "epoch: 1 \tstep: 2700 / 3740 \ttrain loss: 0.4346 \ttrain accuracy: 0.8750 \ttime: 78.2216 s\n",
      "epoch: 1 \tstep: 2750 / 3740 \ttrain loss: 0.0249 \ttrain accuracy: 1.0000 \ttime: 119.5580 s\n",
      "epoch: 1 \tstep: 2800 / 3740 \ttrain loss: 0.0063 \ttrain accuracy: 1.0000 \ttime: 199.9320 s\n",
      "epoch: 1 \tstep: 2850 / 3740 \ttrain loss: 0.0043 \ttrain accuracy: 1.0000 \ttime: 139.7260 s\n",
      "epoch: 1 \tstep: 2900 / 3740 \ttrain loss: 0.0023 \ttrain accuracy: 1.0000 \ttime: 126.6371 s\n",
      "epoch: 1 \tstep: 2950 / 3740 \ttrain loss: 0.0064 \ttrain accuracy: 1.0000 \ttime: 164.9805 s\n",
      "epoch: 1 \tstep: 3000 / 3740 \ttrain loss: 0.5600 \ttrain accuracy: 0.8750 \ttime: 142.2264 s\n",
      "epoch: 1 \tstep: 3050 / 3740 \ttrain loss: 0.2690 \ttrain accuracy: 0.8750 \ttime: 152.6057 s\n",
      "epoch: 1 \tstep: 3100 / 3740 \ttrain loss: 0.2169 \ttrain accuracy: 0.8750 \ttime: 138.5348 s\n",
      "epoch: 1 \tstep: 3150 / 3740 \ttrain loss: 0.0016 \ttrain accuracy: 1.0000 \ttime: 150.0437 s\n",
      "epoch: 1 \tstep: 3200 / 3740 \ttrain loss: 0.3803 \ttrain accuracy: 0.7500 \ttime: 146.0675 s\n",
      "epoch: 1 \tstep: 3250 / 3740 \ttrain loss: 0.0300 \ttrain accuracy: 1.0000 \ttime: 151.2671 s\n",
      "epoch: 1 \tstep: 3300 / 3740 \ttrain loss: 0.7470 \ttrain accuracy: 0.8750 \ttime: 165.2590 s\n",
      "epoch: 1 \tstep: 3350 / 3740 \ttrain loss: 0.0167 \ttrain accuracy: 1.0000 \ttime: 150.0921 s\n",
      "epoch: 1 \tstep: 3400 / 3740 \ttrain loss: 0.0399 \ttrain accuracy: 1.0000 \ttime: 148.9120 s\n",
      "epoch: 1 \tstep: 3450 / 3740 \ttrain loss: 0.1919 \ttrain accuracy: 0.8750 \ttime: 150.7213 s\n",
      "epoch: 1 \tstep: 3500 / 3740 \ttrain loss: 0.0261 \ttrain accuracy: 1.0000 \ttime: 159.0056 s\n",
      "epoch: 1 \tstep: 3550 / 3740 \ttrain loss: 0.0093 \ttrain accuracy: 1.0000 \ttime: 152.6892 s\n",
      "epoch: 1 \tstep: 3600 / 3740 \ttrain loss: 0.0921 \ttrain accuracy: 1.0000 \ttime: 149.8858 s\n",
      "epoch: 1 \tstep: 3650 / 3740 \ttrain loss: 0.0630 \ttrain accuracy: 1.0000 \ttime: 290.4721 s\n",
      "epoch: 1 \tstep: 3700 / 3740 \ttrain loss: 0.0386 \ttrain accuracy: 1.0000 \ttime: 150.3843 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e991856251d4eb8ac7fc6ed5bb7f927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 40 \ttrain loss: 0.1023 \tvalid loss: 0.0768 \ttrain accuracy 0.9641 \tvalid accuracy 0.9728\n",
      "epoch: 2 \tstep: 50 / 3740 \ttrain loss: 0.0044 \ttrain accuracy: 1.0000 \ttime: 135.2728 s\n",
      "epoch: 2 \tstep: 100 / 3740 \ttrain loss: 0.0246 \ttrain accuracy: 1.0000 \ttime: 149.0404 s\n",
      "epoch: 2 \tstep: 150 / 3740 \ttrain loss: 0.0055 \ttrain accuracy: 1.0000 \ttime: 146.1756 s\n",
      "epoch: 2 \tstep: 200 / 3740 \ttrain loss: 0.0054 \ttrain accuracy: 1.0000 \ttime: 164.0048 s\n",
      "epoch: 2 \tstep: 250 / 3740 \ttrain loss: 0.0502 \ttrain accuracy: 1.0000 \ttime: 149.1613 s\n",
      "epoch: 2 \tstep: 300 / 3740 \ttrain loss: 0.0091 \ttrain accuracy: 1.0000 \ttime: 135.7992 s\n",
      "epoch: 2 \tstep: 350 / 3740 \ttrain loss: 0.1438 \ttrain accuracy: 1.0000 \ttime: 134.2756 s\n",
      "epoch: 2 \tstep: 400 / 3740 \ttrain loss: 0.0806 \ttrain accuracy: 1.0000 \ttime: 162.3789 s\n",
      "epoch: 2 \tstep: 450 / 3740 \ttrain loss: 0.1151 \ttrain accuracy: 1.0000 \ttime: 135.0085 s\n",
      "epoch: 2 \tstep: 500 / 3740 \ttrain loss: 0.1964 \ttrain accuracy: 0.8750 \ttime: 153.5403 s\n",
      "epoch: 2 \tstep: 550 / 3740 \ttrain loss: 0.0078 \ttrain accuracy: 1.0000 \ttime: 136.8354 s\n",
      "epoch: 2 \tstep: 600 / 3740 \ttrain loss: 0.0406 \ttrain accuracy: 1.0000 \ttime: 136.1574 s\n",
      "epoch: 2 \tstep: 650 / 3740 \ttrain loss: 0.0186 \ttrain accuracy: 1.0000 \ttime: 148.4837 s\n",
      "epoch: 2 \tstep: 700 / 3740 \ttrain loss: 0.0558 \ttrain accuracy: 1.0000 \ttime: 135.3492 s\n",
      "epoch: 2 \tstep: 750 / 3740 \ttrain loss: 0.0039 \ttrain accuracy: 1.0000 \ttime: 135.4823 s\n",
      "epoch: 2 \tstep: 800 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 149.9074 s\n",
      "epoch: 2 \tstep: 850 / 3740 \ttrain loss: 0.0505 \ttrain accuracy: 1.0000 \ttime: 145.3267 s\n",
      "epoch: 2 \tstep: 900 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 137.9423 s\n",
      "epoch: 2 \tstep: 950 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 134.7600 s\n",
      "epoch: 2 \tstep: 1000 / 3740 \ttrain loss: 0.0110 \ttrain accuracy: 1.0000 \ttime: 148.5787 s\n",
      "epoch: 2 \tstep: 1050 / 3740 \ttrain loss: 0.0867 \ttrain accuracy: 1.0000 \ttime: 135.1544 s\n",
      "epoch: 2 \tstep: 1100 / 3740 \ttrain loss: 0.3251 \ttrain accuracy: 0.8750 \ttime: 147.5325 s\n",
      "epoch: 2 \tstep: 1150 / 3740 \ttrain loss: 0.0204 \ttrain accuracy: 1.0000 \ttime: 171.3101 s\n",
      "epoch: 2 \tstep: 1200 / 3740 \ttrain loss: 0.0513 \ttrain accuracy: 1.0000 \ttime: 137.7133 s\n",
      "epoch: 2 \tstep: 1250 / 3740 \ttrain loss: 0.0144 \ttrain accuracy: 1.0000 \ttime: 135.5517 s\n",
      "epoch: 2 \tstep: 1300 / 3740 \ttrain loss: 0.0010 \ttrain accuracy: 1.0000 \ttime: 148.6403 s\n",
      "epoch: 2 \tstep: 1350 / 3740 \ttrain loss: 0.0014 \ttrain accuracy: 1.0000 \ttime: 136.2455 s\n",
      "epoch: 2 \tstep: 1400 / 3740 \ttrain loss: 0.0085 \ttrain accuracy: 1.0000 \ttime: 136.3302 s\n",
      "epoch: 2 \tstep: 1450 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 136.4424 s\n",
      "epoch: 2 \tstep: 1500 / 3740 \ttrain loss: 0.0115 \ttrain accuracy: 1.0000 \ttime: 133.0124 s\n",
      "epoch: 2 \tstep: 1550 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 138.5279 s\n",
      "epoch: 2 \tstep: 1600 / 3740 \ttrain loss: 0.0030 \ttrain accuracy: 1.0000 \ttime: 135.0893 s\n",
      "epoch: 2 \tstep: 1650 / 3740 \ttrain loss: 0.0060 \ttrain accuracy: 1.0000 \ttime: 137.3296 s\n",
      "epoch: 2 \tstep: 1700 / 3740 \ttrain loss: 0.0550 \ttrain accuracy: 1.0000 \ttime: 137.2414 s\n",
      "epoch: 2 \tstep: 1750 / 3740 \ttrain loss: 0.0311 \ttrain accuracy: 1.0000 \ttime: 134.6662 s\n",
      "epoch: 2 \tstep: 1800 / 3740 \ttrain loss: 0.3362 \ttrain accuracy: 0.8750 \ttime: 148.6012 s\n",
      "epoch: 2 \tstep: 1850 / 3740 \ttrain loss: 0.0125 \ttrain accuracy: 1.0000 \ttime: 127.3328 s\n",
      "epoch: 2 \tstep: 1900 / 3740 \ttrain loss: 0.0855 \ttrain accuracy: 1.0000 \ttime: 138.8025 s\n",
      "epoch: 2 \tstep: 1950 / 3740 \ttrain loss: 0.3330 \ttrain accuracy: 0.8750 \ttime: 136.0795 s\n",
      "epoch: 2 \tstep: 2000 / 3740 \ttrain loss: 0.0329 \ttrain accuracy: 1.0000 \ttime: 148.7346 s\n",
      "epoch: 2 \tstep: 2050 / 3740 \ttrain loss: 0.0977 \ttrain accuracy: 1.0000 \ttime: 138.7370 s\n",
      "epoch: 2 \tstep: 2100 / 3740 \ttrain loss: 0.0942 \ttrain accuracy: 1.0000 \ttime: 136.2038 s\n",
      "epoch: 2 \tstep: 2150 / 3740 \ttrain loss: 0.0042 \ttrain accuracy: 1.0000 \ttime: 133.6619 s\n",
      "epoch: 2 \tstep: 2200 / 3740 \ttrain loss: 0.0347 \ttrain accuracy: 1.0000 \ttime: 136.6920 s\n",
      "epoch: 2 \tstep: 2250 / 3740 \ttrain loss: 0.0153 \ttrain accuracy: 1.0000 \ttime: 134.8698 s\n",
      "epoch: 2 \tstep: 2300 / 3740 \ttrain loss: 0.0165 \ttrain accuracy: 1.0000 \ttime: 146.6040 s\n",
      "epoch: 2 \tstep: 2350 / 3740 \ttrain loss: 0.3441 \ttrain accuracy: 0.7500 \ttime: 134.7041 s\n",
      "epoch: 2 \tstep: 2400 / 3740 \ttrain loss: 0.0153 \ttrain accuracy: 1.0000 \ttime: 135.3571 s\n",
      "epoch: 2 \tstep: 2450 / 3740 \ttrain loss: 0.2254 \ttrain accuracy: 0.8750 \ttime: 129.7899 s\n",
      "epoch: 2 \tstep: 2500 / 3740 \ttrain loss: 0.0035 \ttrain accuracy: 1.0000 \ttime: 136.7817 s\n",
      "epoch: 2 \tstep: 2550 / 3740 \ttrain loss: 0.1838 \ttrain accuracy: 0.8750 \ttime: 124.1434 s\n",
      "epoch: 2 \tstep: 2600 / 3740 \ttrain loss: 0.0046 \ttrain accuracy: 1.0000 \ttime: 125.0152 s\n",
      "epoch: 2 \tstep: 2650 / 3740 \ttrain loss: 0.0114 \ttrain accuracy: 1.0000 \ttime: 136.9388 s\n",
      "epoch: 2 \tstep: 2700 / 3740 \ttrain loss: 0.0220 \ttrain accuracy: 1.0000 \ttime: 137.5500 s\n",
      "epoch: 2 \tstep: 2750 / 3740 \ttrain loss: 0.0178 \ttrain accuracy: 1.0000 \ttime: 134.8819 s\n",
      "epoch: 2 \tstep: 2800 / 3740 \ttrain loss: 0.0115 \ttrain accuracy: 1.0000 \ttime: 147.4642 s\n",
      "epoch: 2 \tstep: 2850 / 3740 \ttrain loss: 0.0036 \ttrain accuracy: 1.0000 \ttime: 134.7072 s\n",
      "epoch: 2 \tstep: 2900 / 3740 \ttrain loss: 0.0205 \ttrain accuracy: 1.0000 \ttime: 134.1182 s\n",
      "epoch: 2 \tstep: 2950 / 3740 \ttrain loss: 0.0041 \ttrain accuracy: 1.0000 \ttime: 148.7298 s\n",
      "epoch: 2 \tstep: 3000 / 3740 \ttrain loss: 0.0068 \ttrain accuracy: 1.0000 \ttime: 135.8179 s\n",
      "epoch: 2 \tstep: 3050 / 3740 \ttrain loss: 0.0008 \ttrain accuracy: 1.0000 \ttime: 149.8795 s\n",
      "epoch: 2 \tstep: 3100 / 3740 \ttrain loss: 0.0731 \ttrain accuracy: 1.0000 \ttime: 147.4908 s\n",
      "epoch: 2 \tstep: 3150 / 3740 \ttrain loss: 0.0930 \ttrain accuracy: 0.8750 \ttime: 147.8569 s\n",
      "epoch: 2 \tstep: 3200 / 3740 \ttrain loss: 0.0486 \ttrain accuracy: 1.0000 \ttime: 147.7264 s\n",
      "epoch: 2 \tstep: 3250 / 3740 \ttrain loss: 0.0012 \ttrain accuracy: 1.0000 \ttime: 147.4877 s\n",
      "epoch: 2 \tstep: 3300 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 136.0520 s\n",
      "epoch: 2 \tstep: 3350 / 3740 \ttrain loss: 0.0008 \ttrain accuracy: 1.0000 \ttime: 147.4869 s\n",
      "epoch: 2 \tstep: 3400 / 3740 \ttrain loss: 0.0095 \ttrain accuracy: 1.0000 \ttime: 148.4411 s\n",
      "epoch: 2 \tstep: 3450 / 3740 \ttrain loss: 0.0022 \ttrain accuracy: 1.0000 \ttime: 136.0791 s\n",
      "epoch: 2 \tstep: 3500 / 3740 \ttrain loss: 0.0149 \ttrain accuracy: 1.0000 \ttime: 147.4746 s\n",
      "epoch: 2 \tstep: 3550 / 3740 \ttrain loss: 0.7645 \ttrain accuracy: 0.8750 \ttime: 147.8856 s\n",
      "epoch: 2 \tstep: 3600 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 146.1994 s\n",
      "epoch: 2 \tstep: 3650 / 3740 \ttrain loss: 0.0633 \ttrain accuracy: 1.0000 \ttime: 140.6262 s\n",
      "epoch: 2 \tstep: 3700 / 3740 \ttrain loss: 0.0195 \ttrain accuracy: 1.0000 \ttime: 123.5470 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e79e40fb3b246f38e46ba2bc2de4ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 40 \ttrain loss: 0.0843 \tvalid loss: 0.0600 \ttrain accuracy 0.9728 \tvalid accuracy 0.9794\n",
      "Model saved to: model.pth\n",
      "epoch: 3 \tstep: 50 / 3740 \ttrain loss: 0.1512 \ttrain accuracy: 0.8750 \ttime: 136.1553 s\n",
      "epoch: 3 \tstep: 100 / 3740 \ttrain loss: 0.0200 \ttrain accuracy: 1.0000 \ttime: 135.0173 s\n",
      "epoch: 3 \tstep: 150 / 3740 \ttrain loss: 0.1318 \ttrain accuracy: 1.0000 \ttime: 134.9188 s\n",
      "epoch: 3 \tstep: 200 / 3740 \ttrain loss: 0.0045 \ttrain accuracy: 1.0000 \ttime: 134.0786 s\n",
      "epoch: 3 \tstep: 250 / 3740 \ttrain loss: 0.0053 \ttrain accuracy: 1.0000 \ttime: 137.4536 s\n",
      "epoch: 3 \tstep: 300 / 3740 \ttrain loss: 0.0034 \ttrain accuracy: 1.0000 \ttime: 131.2471 s\n",
      "epoch: 3 \tstep: 350 / 3740 \ttrain loss: 0.0017 \ttrain accuracy: 1.0000 \ttime: 124.3075 s\n",
      "epoch: 3 \tstep: 400 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 143.8555 s\n",
      "epoch: 3 \tstep: 450 / 3740 \ttrain loss: 0.0097 \ttrain accuracy: 1.0000 \ttime: 134.8982 s\n",
      "epoch: 3 \tstep: 500 / 3740 \ttrain loss: 0.0025 \ttrain accuracy: 1.0000 \ttime: 135.0779 s\n",
      "epoch: 3 \tstep: 550 / 3740 \ttrain loss: 0.2991 \ttrain accuracy: 0.8750 \ttime: 135.4918 s\n",
      "epoch: 3 \tstep: 600 / 3740 \ttrain loss: 0.0032 \ttrain accuracy: 1.0000 \ttime: 124.0423 s\n",
      "epoch: 3 \tstep: 650 / 3740 \ttrain loss: 0.0955 \ttrain accuracy: 0.8750 \ttime: 137.1228 s\n",
      "epoch: 3 \tstep: 700 / 3740 \ttrain loss: 0.0171 \ttrain accuracy: 1.0000 \ttime: 135.2823 s\n",
      "epoch: 3 \tstep: 750 / 3740 \ttrain loss: 0.0089 \ttrain accuracy: 1.0000 \ttime: 138.1660 s\n",
      "epoch: 3 \tstep: 800 / 3740 \ttrain loss: 0.0022 \ttrain accuracy: 1.0000 \ttime: 133.1319 s\n",
      "epoch: 3 \tstep: 850 / 3740 \ttrain loss: 0.0152 \ttrain accuracy: 1.0000 \ttime: 137.3345 s\n",
      "epoch: 3 \tstep: 900 / 3740 \ttrain loss: 0.0897 \ttrain accuracy: 1.0000 \ttime: 135.2990 s\n",
      "epoch: 3 \tstep: 950 / 3740 \ttrain loss: 0.2134 \ttrain accuracy: 0.8750 \ttime: 135.6959 s\n",
      "epoch: 3 \tstep: 1000 / 3740 \ttrain loss: 0.0161 \ttrain accuracy: 1.0000 \ttime: 125.7187 s\n",
      "epoch: 3 \tstep: 1050 / 3740 \ttrain loss: 0.0167 \ttrain accuracy: 1.0000 \ttime: 138.4507 s\n",
      "epoch: 3 \tstep: 1100 / 3740 \ttrain loss: 0.0380 \ttrain accuracy: 1.0000 \ttime: 136.3348 s\n",
      "epoch: 3 \tstep: 1150 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 147.3080 s\n",
      "epoch: 3 \tstep: 1200 / 3740 \ttrain loss: 0.0125 \ttrain accuracy: 1.0000 \ttime: 135.2896 s\n",
      "epoch: 3 \tstep: 1250 / 3740 \ttrain loss: 0.0026 \ttrain accuracy: 1.0000 \ttime: 139.3962 s\n",
      "epoch: 3 \tstep: 1300 / 3740 \ttrain loss: 0.0573 \ttrain accuracy: 1.0000 \ttime: 134.0090 s\n",
      "epoch: 3 \tstep: 1350 / 3740 \ttrain loss: 0.0025 \ttrain accuracy: 1.0000 \ttime: 136.2494 s\n",
      "epoch: 3 \tstep: 1400 / 3740 \ttrain loss: 0.0173 \ttrain accuracy: 1.0000 \ttime: 124.9632 s\n",
      "epoch: 3 \tstep: 1450 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 124.5834 s\n",
      "epoch: 3 \tstep: 1500 / 3740 \ttrain loss: 0.0014 \ttrain accuracy: 1.0000 \ttime: 135.8806 s\n",
      "epoch: 3 \tstep: 1550 / 3740 \ttrain loss: 0.2642 \ttrain accuracy: 0.7500 \ttime: 134.7716 s\n",
      "epoch: 3 \tstep: 1600 / 3740 \ttrain loss: 0.0038 \ttrain accuracy: 1.0000 \ttime: 135.3752 s\n",
      "epoch: 3 \tstep: 1650 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 133.9204 s\n",
      "epoch: 3 \tstep: 1700 / 3740 \ttrain loss: 0.3848 \ttrain accuracy: 0.7500 \ttime: 133.5780 s\n",
      "epoch: 3 \tstep: 1750 / 3740 \ttrain loss: 0.0317 \ttrain accuracy: 1.0000 \ttime: 129.6237 s\n",
      "epoch: 3 \tstep: 1800 / 3740 \ttrain loss: 0.0016 \ttrain accuracy: 1.0000 \ttime: 136.0586 s\n",
      "epoch: 3 \tstep: 1850 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 135.9104 s\n",
      "epoch: 3 \tstep: 1900 / 3740 \ttrain loss: 0.0162 \ttrain accuracy: 1.0000 \ttime: 140.8915 s\n",
      "epoch: 3 \tstep: 1950 / 3740 \ttrain loss: 0.0062 \ttrain accuracy: 1.0000 \ttime: 100.9902 s\n",
      "epoch: 3 \tstep: 2000 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 95.2112 s\n",
      "epoch: 3 \tstep: 2050 / 3740 \ttrain loss: 0.0014 \ttrain accuracy: 1.0000 \ttime: 109.7044 s\n",
      "epoch: 3 \tstep: 2100 / 3740 \ttrain loss: 0.0174 \ttrain accuracy: 1.0000 \ttime: 75.8319 s\n",
      "epoch: 3 \tstep: 2150 / 3740 \ttrain loss: 0.0025 \ttrain accuracy: 1.0000 \ttime: 75.1106 s\n",
      "epoch: 3 \tstep: 2200 / 3740 \ttrain loss: 0.0073 \ttrain accuracy: 1.0000 \ttime: 83.3752 s\n",
      "epoch: 3 \tstep: 2250 / 3740 \ttrain loss: 0.0029 \ttrain accuracy: 1.0000 \ttime: 86.2668 s\n",
      "epoch: 3 \tstep: 2300 / 3740 \ttrain loss: 0.0136 \ttrain accuracy: 1.0000 \ttime: 90.6611 s\n",
      "epoch: 3 \tstep: 2350 / 3740 \ttrain loss: 0.0084 \ttrain accuracy: 1.0000 \ttime: 89.2791 s\n",
      "epoch: 3 \tstep: 2400 / 3740 \ttrain loss: 0.2509 \ttrain accuracy: 0.7500 \ttime: 89.7525 s\n",
      "epoch: 3 \tstep: 2450 / 3740 \ttrain loss: 0.0008 \ttrain accuracy: 1.0000 \ttime: 86.5687 s\n",
      "epoch: 3 \tstep: 2500 / 3740 \ttrain loss: 0.0351 \ttrain accuracy: 1.0000 \ttime: 105.4611 s\n",
      "epoch: 3 \tstep: 2550 / 3740 \ttrain loss: 0.0763 \ttrain accuracy: 1.0000 \ttime: 93.6388 s\n",
      "epoch: 3 \tstep: 2600 / 3740 \ttrain loss: 0.0599 \ttrain accuracy: 1.0000 \ttime: 122.5670 s\n",
      "epoch: 3 \tstep: 2650 / 3740 \ttrain loss: 0.0063 \ttrain accuracy: 1.0000 \ttime: 113.9514 s\n",
      "epoch: 3 \tstep: 2700 / 3740 \ttrain loss: 0.0023 \ttrain accuracy: 1.0000 \ttime: 124.9970 s\n",
      "epoch: 3 \tstep: 2750 / 3740 \ttrain loss: 0.0207 \ttrain accuracy: 1.0000 \ttime: 116.9521 s\n",
      "epoch: 3 \tstep: 2800 / 3740 \ttrain loss: 0.2344 \ttrain accuracy: 0.8750 \ttime: 120.9214 s\n",
      "epoch: 3 \tstep: 2850 / 3740 \ttrain loss: 0.0143 \ttrain accuracy: 1.0000 \ttime: 117.1873 s\n",
      "epoch: 3 \tstep: 2900 / 3740 \ttrain loss: 0.0137 \ttrain accuracy: 1.0000 \ttime: 146.5420 s\n",
      "epoch: 3 \tstep: 2950 / 3740 \ttrain loss: 0.1258 \ttrain accuracy: 0.8750 \ttime: 76.2112 s\n",
      "epoch: 3 \tstep: 3000 / 3740 \ttrain loss: 0.0486 \ttrain accuracy: 1.0000 \ttime: 76.5866 s\n",
      "epoch: 3 \tstep: 3050 / 3740 \ttrain loss: 0.0030 \ttrain accuracy: 1.0000 \ttime: 76.1566 s\n",
      "epoch: 3 \tstep: 3100 / 3740 \ttrain loss: 0.0027 \ttrain accuracy: 1.0000 \ttime: 77.1469 s\n",
      "epoch: 3 \tstep: 3150 / 3740 \ttrain loss: 0.0305 \ttrain accuracy: 1.0000 \ttime: 77.4763 s\n",
      "epoch: 3 \tstep: 3200 / 3740 \ttrain loss: 0.6526 \ttrain accuracy: 0.8750 \ttime: 76.0522 s\n",
      "epoch: 3 \tstep: 3250 / 3740 \ttrain loss: 0.0104 \ttrain accuracy: 1.0000 \ttime: 79.2090 s\n",
      "epoch: 3 \tstep: 3300 / 3740 \ttrain loss: 0.0153 \ttrain accuracy: 1.0000 \ttime: 76.4484 s\n",
      "epoch: 3 \tstep: 3350 / 3740 \ttrain loss: 0.0031 \ttrain accuracy: 1.0000 \ttime: 81.9719 s\n",
      "epoch: 3 \tstep: 3400 / 3740 \ttrain loss: 0.0084 \ttrain accuracy: 1.0000 \ttime: 80.8897 s\n",
      "epoch: 3 \tstep: 3450 / 3740 \ttrain loss: 0.0065 \ttrain accuracy: 1.0000 \ttime: 82.9595 s\n",
      "epoch: 3 \tstep: 3500 / 3740 \ttrain loss: 0.0008 \ttrain accuracy: 1.0000 \ttime: 80.1830 s\n",
      "epoch: 3 \tstep: 3550 / 3740 \ttrain loss: 0.0554 \ttrain accuracy: 1.0000 \ttime: 80.4433 s\n",
      "epoch: 3 \tstep: 3600 / 3740 \ttrain loss: 0.0657 \ttrain accuracy: 1.0000 \ttime: 82.9596 s\n",
      "epoch: 3 \tstep: 3650 / 3740 \ttrain loss: 0.0056 \ttrain accuracy: 1.0000 \ttime: 81.0447 s\n",
      "epoch: 3 \tstep: 3700 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 81.5071 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3c164cb53c489f895875a7a251277b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 40 \ttrain loss: 0.0819 \tvalid loss: 0.0619 \ttrain accuracy 0.9732 \tvalid accuracy 0.9780\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 4 \tstep: 50 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 120.3312 s\n",
      "epoch: 4 \tstep: 100 / 3740 \ttrain loss: 0.0020 \ttrain accuracy: 1.0000 \ttime: 104.8136 s\n",
      "epoch: 4 \tstep: 150 / 3740 \ttrain loss: 0.0772 \ttrain accuracy: 1.0000 \ttime: 81.7598 s\n",
      "epoch: 4 \tstep: 200 / 3740 \ttrain loss: 0.0081 \ttrain accuracy: 1.0000 \ttime: 89.6838 s\n",
      "epoch: 4 \tstep: 250 / 3740 \ttrain loss: 0.0037 \ttrain accuracy: 1.0000 \ttime: 80.6741 s\n",
      "epoch: 4 \tstep: 300 / 3740 \ttrain loss: 0.0041 \ttrain accuracy: 1.0000 \ttime: 93.6310 s\n",
      "epoch: 4 \tstep: 350 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 88.4189 s\n",
      "epoch: 4 \tstep: 400 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 98.8517 s\n",
      "epoch: 4 \tstep: 450 / 3740 \ttrain loss: 0.0066 \ttrain accuracy: 1.0000 \ttime: 109.6465 s\n",
      "epoch: 4 \tstep: 500 / 3740 \ttrain loss: 0.0197 \ttrain accuracy: 1.0000 \ttime: 102.8231 s\n",
      "epoch: 4 \tstep: 550 / 3740 \ttrain loss: 0.0192 \ttrain accuracy: 1.0000 \ttime: 70.9142 s\n",
      "epoch: 4 \tstep: 600 / 3740 \ttrain loss: 0.0025 \ttrain accuracy: 1.0000 \ttime: 69.4791 s\n",
      "epoch: 4 \tstep: 650 / 3740 \ttrain loss: 0.0105 \ttrain accuracy: 1.0000 \ttime: 70.8194 s\n",
      "epoch: 4 \tstep: 700 / 3740 \ttrain loss: 0.1995 \ttrain accuracy: 0.8750 \ttime: 69.6770 s\n",
      "epoch: 4 \tstep: 750 / 3740 \ttrain loss: 0.0041 \ttrain accuracy: 1.0000 \ttime: 73.5164 s\n",
      "epoch: 4 \tstep: 800 / 3740 \ttrain loss: 0.0589 \ttrain accuracy: 1.0000 \ttime: 76.1737 s\n",
      "epoch: 4 \tstep: 850 / 3740 \ttrain loss: 0.0717 \ttrain accuracy: 1.0000 \ttime: 76.9422 s\n",
      "epoch: 4 \tstep: 900 / 3740 \ttrain loss: 0.0133 \ttrain accuracy: 1.0000 \ttime: 81.6623 s\n",
      "epoch: 4 \tstep: 950 / 3740 \ttrain loss: 0.0818 \ttrain accuracy: 1.0000 \ttime: 81.0103 s\n",
      "epoch: 4 \tstep: 1000 / 3740 \ttrain loss: 0.0497 \ttrain accuracy: 1.0000 \ttime: 77.4346 s\n",
      "epoch: 4 \tstep: 1050 / 3740 \ttrain loss: 0.0066 \ttrain accuracy: 1.0000 \ttime: 86.4678 s\n",
      "epoch: 4 \tstep: 1100 / 3740 \ttrain loss: 0.2181 \ttrain accuracy: 0.8750 \ttime: 81.3218 s\n",
      "epoch: 4 \tstep: 1150 / 3740 \ttrain loss: 0.1751 \ttrain accuracy: 0.8750 \ttime: 87.3995 s\n",
      "epoch: 4 \tstep: 1200 / 3740 \ttrain loss: 0.0795 \ttrain accuracy: 1.0000 \ttime: 81.3937 s\n",
      "epoch: 4 \tstep: 1250 / 3740 \ttrain loss: 0.9539 \ttrain accuracy: 0.8750 \ttime: 81.8851 s\n",
      "epoch: 4 \tstep: 1300 / 3740 \ttrain loss: 0.0228 \ttrain accuracy: 1.0000 \ttime: 81.6036 s\n",
      "epoch: 4 \tstep: 1350 / 3740 \ttrain loss: 0.0604 \ttrain accuracy: 1.0000 \ttime: 81.1653 s\n",
      "epoch: 4 \tstep: 1400 / 3740 \ttrain loss: 0.6312 \ttrain accuracy: 0.8750 \ttime: 80.8164 s\n",
      "epoch: 4 \tstep: 1450 / 3740 \ttrain loss: 0.0025 \ttrain accuracy: 1.0000 \ttime: 81.9561 s\n",
      "epoch: 4 \tstep: 1500 / 3740 \ttrain loss: 0.0473 \ttrain accuracy: 1.0000 \ttime: 87.1573 s\n",
      "epoch: 4 \tstep: 1550 / 3740 \ttrain loss: 0.0002 \ttrain accuracy: 1.0000 \ttime: 83.8949 s\n",
      "epoch: 4 \tstep: 1600 / 3740 \ttrain loss: 1.2646 \ttrain accuracy: 0.8750 \ttime: 81.7531 s\n",
      "epoch: 4 \tstep: 1650 / 3740 \ttrain loss: 0.0008 \ttrain accuracy: 1.0000 \ttime: 81.7158 s\n",
      "epoch: 4 \tstep: 1700 / 3740 \ttrain loss: 0.0189 \ttrain accuracy: 1.0000 \ttime: 80.9525 s\n",
      "epoch: 4 \tstep: 1750 / 3740 \ttrain loss: 0.2437 \ttrain accuracy: 0.8750 \ttime: 80.8854 s\n",
      "epoch: 4 \tstep: 1800 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 133.6680 s\n",
      "epoch: 4 \tstep: 1850 / 3740 \ttrain loss: 0.0154 \ttrain accuracy: 1.0000 \ttime: 67.8638 s\n",
      "epoch: 4 \tstep: 1900 / 3740 \ttrain loss: 0.0306 \ttrain accuracy: 1.0000 \ttime: 81.3358 s\n",
      "epoch: 4 \tstep: 1950 / 3740 \ttrain loss: 0.0110 \ttrain accuracy: 1.0000 \ttime: 135.5280 s\n",
      "epoch: 4 \tstep: 2000 / 3740 \ttrain loss: 0.0400 \ttrain accuracy: 1.0000 \ttime: 68.4881 s\n",
      "epoch: 4 \tstep: 2050 / 3740 \ttrain loss: 0.0008 \ttrain accuracy: 1.0000 \ttime: 78.4990 s\n",
      "epoch: 4 \tstep: 2100 / 3740 \ttrain loss: 0.0166 \ttrain accuracy: 1.0000 \ttime: 153.3935 s\n",
      "epoch: 4 \tstep: 2150 / 3740 \ttrain loss: 0.0046 \ttrain accuracy: 1.0000 \ttime: 84.3966 s\n",
      "epoch: 4 \tstep: 2200 / 3740 \ttrain loss: 0.1420 \ttrain accuracy: 0.8750 \ttime: 75.2378 s\n",
      "epoch: 4 \tstep: 2250 / 3740 \ttrain loss: 0.0102 \ttrain accuracy: 1.0000 \ttime: 81.8994 s\n",
      "epoch: 4 \tstep: 2300 / 3740 \ttrain loss: 0.0068 \ttrain accuracy: 1.0000 \ttime: 83.3287 s\n",
      "epoch: 4 \tstep: 2350 / 3740 \ttrain loss: 0.0899 \ttrain accuracy: 0.8750 \ttime: 81.8771 s\n",
      "epoch: 4 \tstep: 2400 / 3740 \ttrain loss: 0.0752 \ttrain accuracy: 1.0000 \ttime: 83.3404 s\n",
      "epoch: 4 \tstep: 2450 / 3740 \ttrain loss: 0.2336 \ttrain accuracy: 0.8750 \ttime: 81.0392 s\n",
      "epoch: 4 \tstep: 2500 / 3740 \ttrain loss: 0.0041 \ttrain accuracy: 1.0000 \ttime: 81.9896 s\n",
      "epoch: 4 \tstep: 2550 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 82.3333 s\n",
      "epoch: 4 \tstep: 2600 / 3740 \ttrain loss: 0.2429 \ttrain accuracy: 0.7500 \ttime: 83.3533 s\n",
      "epoch: 4 \tstep: 2650 / 3740 \ttrain loss: 0.0064 \ttrain accuracy: 1.0000 \ttime: 118.0181 s\n",
      "epoch: 4 \tstep: 2700 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 117.1749 s\n",
      "epoch: 4 \tstep: 2750 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 109.2201 s\n",
      "epoch: 4 \tstep: 2800 / 3740 \ttrain loss: 0.8688 \ttrain accuracy: 0.8750 \ttime: 80.8277 s\n",
      "epoch: 4 \tstep: 2850 / 3740 \ttrain loss: 0.0241 \ttrain accuracy: 1.0000 \ttime: 116.7290 s\n",
      "epoch: 4 \tstep: 2900 / 3740 \ttrain loss: 0.0073 \ttrain accuracy: 1.0000 \ttime: 81.0169 s\n",
      "epoch: 4 \tstep: 2950 / 3740 \ttrain loss: 0.1986 \ttrain accuracy: 0.8750 \ttime: 115.3210 s\n",
      "epoch: 4 \tstep: 3000 / 3740 \ttrain loss: 0.0016 \ttrain accuracy: 1.0000 \ttime: 80.7158 s\n",
      "epoch: 4 \tstep: 3050 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 80.9270 s\n",
      "epoch: 4 \tstep: 3100 / 3740 \ttrain loss: 0.0439 \ttrain accuracy: 1.0000 \ttime: 82.7962 s\n",
      "epoch: 4 \tstep: 3150 / 3740 \ttrain loss: 0.0044 \ttrain accuracy: 1.0000 \ttime: 113.7429 s\n",
      "epoch: 4 \tstep: 3200 / 3740 \ttrain loss: 0.0282 \ttrain accuracy: 1.0000 \ttime: 116.8177 s\n",
      "epoch: 4 \tstep: 3250 / 3740 \ttrain loss: 0.3859 \ttrain accuracy: 0.8750 \ttime: 106.9527 s\n",
      "epoch: 4 \tstep: 3300 / 3740 \ttrain loss: 0.2555 \ttrain accuracy: 0.8750 \ttime: 115.5842 s\n",
      "epoch: 4 \tstep: 3350 / 3740 \ttrain loss: 0.0254 \ttrain accuracy: 1.0000 \ttime: 101.1390 s\n",
      "epoch: 4 \tstep: 3400 / 3740 \ttrain loss: 0.0037 \ttrain accuracy: 1.0000 \ttime: 113.9627 s\n",
      "epoch: 4 \tstep: 3450 / 3740 \ttrain loss: 0.5306 \ttrain accuracy: 0.8750 \ttime: 117.4554 s\n",
      "epoch: 4 \tstep: 3500 / 3740 \ttrain loss: 0.0055 \ttrain accuracy: 1.0000 \ttime: 85.9938 s\n",
      "epoch: 4 \tstep: 3550 / 3740 \ttrain loss: 0.0597 \ttrain accuracy: 1.0000 \ttime: 113.6804 s\n",
      "epoch: 4 \tstep: 3600 / 3740 \ttrain loss: 0.0017 \ttrain accuracy: 1.0000 \ttime: 95.5022 s\n",
      "epoch: 4 \tstep: 3650 / 3740 \ttrain loss: 0.0017 \ttrain accuracy: 1.0000 \ttime: 90.5671 s\n",
      "epoch: 4 \tstep: 3700 / 3740 \ttrain loss: 0.0224 \ttrain accuracy: 1.0000 \ttime: 113.1786 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbce49086d64f3e83f34cbfe8047ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 40 \ttrain loss: 0.0810 \tvalid loss: 0.0647 \ttrain accuracy 0.9735 \tvalid accuracy 0.9778\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 5 \tstep: 50 / 3740 \ttrain loss: 0.0164 \ttrain accuracy: 1.0000 \ttime: 112.4904 s\n",
      "epoch: 5 \tstep: 100 / 3740 \ttrain loss: 0.0099 \ttrain accuracy: 1.0000 \ttime: 81.1943 s\n",
      "epoch: 5 \tstep: 150 / 3740 \ttrain loss: 0.0988 \ttrain accuracy: 1.0000 \ttime: 116.2501 s\n",
      "epoch: 5 \tstep: 200 / 3740 \ttrain loss: 0.7764 \ttrain accuracy: 0.8750 \ttime: 80.6792 s\n",
      "epoch: 5 \tstep: 250 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 112.3763 s\n",
      "epoch: 5 \tstep: 300 / 3740 \ttrain loss: 0.0016 \ttrain accuracy: 1.0000 \ttime: 79.8241 s\n",
      "epoch: 5 \tstep: 350 / 3740 \ttrain loss: 0.2687 \ttrain accuracy: 0.8750 \ttime: 111.3317 s\n",
      "epoch: 5 \tstep: 400 / 3740 \ttrain loss: 0.0115 \ttrain accuracy: 1.0000 \ttime: 113.4060 s\n",
      "epoch: 5 \tstep: 450 / 3740 \ttrain loss: 0.0146 \ttrain accuracy: 1.0000 \ttime: 81.3117 s\n",
      "epoch: 5 \tstep: 500 / 3740 \ttrain loss: 0.0193 \ttrain accuracy: 1.0000 \ttime: 79.9398 s\n",
      "epoch: 5 \tstep: 550 / 3740 \ttrain loss: 0.0049 \ttrain accuracy: 1.0000 \ttime: 82.1689 s\n",
      "epoch: 5 \tstep: 600 / 3740 \ttrain loss: 0.4282 \ttrain accuracy: 0.8750 \ttime: 111.8773 s\n",
      "epoch: 5 \tstep: 650 / 3740 \ttrain loss: 0.0136 \ttrain accuracy: 1.0000 \ttime: 80.4133 s\n",
      "epoch: 5 \tstep: 700 / 3740 \ttrain loss: 0.0866 \ttrain accuracy: 1.0000 \ttime: 114.9437 s\n",
      "epoch: 5 \tstep: 750 / 3740 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 79.8938 s\n",
      "epoch: 5 \tstep: 800 / 3740 \ttrain loss: 0.0120 \ttrain accuracy: 1.0000 \ttime: 112.4041 s\n",
      "epoch: 5 \tstep: 850 / 3740 \ttrain loss: 0.0527 \ttrain accuracy: 1.0000 \ttime: 81.6343 s\n",
      "epoch: 5 \tstep: 900 / 3740 \ttrain loss: 0.0150 \ttrain accuracy: 1.0000 \ttime: 111.8566 s\n",
      "epoch: 5 \tstep: 950 / 3740 \ttrain loss: 0.1901 \ttrain accuracy: 0.8750 \ttime: 112.3180 s\n",
      "epoch: 5 \tstep: 1000 / 3740 \ttrain loss: 0.2626 \ttrain accuracy: 0.7500 \ttime: 113.1428 s\n",
      "epoch: 5 \tstep: 1050 / 3740 \ttrain loss: 0.0623 \ttrain accuracy: 1.0000 \ttime: 80.9570 s\n",
      "epoch: 5 \tstep: 1100 / 3740 \ttrain loss: 0.0091 \ttrain accuracy: 1.0000 \ttime: 94.6302 s\n",
      "epoch: 5 \tstep: 1150 / 3740 \ttrain loss: 0.0581 \ttrain accuracy: 1.0000 \ttime: 80.4667 s\n",
      "epoch: 5 \tstep: 1200 / 3740 \ttrain loss: 0.1131 \ttrain accuracy: 1.0000 \ttime: 89.2808 s\n",
      "epoch: 5 \tstep: 1250 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 80.2236 s\n",
      "epoch: 5 \tstep: 1300 / 3740 \ttrain loss: 0.1523 \ttrain accuracy: 0.8750 \ttime: 80.2144 s\n",
      "epoch: 5 \tstep: 1350 / 3740 \ttrain loss: 0.0368 \ttrain accuracy: 1.0000 \ttime: 80.9044 s\n",
      "epoch: 5 \tstep: 1400 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 82.0358 s\n",
      "epoch: 5 \tstep: 1450 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 80.6916 s\n",
      "epoch: 5 \tstep: 1500 / 3740 \ttrain loss: 0.0603 \ttrain accuracy: 1.0000 \ttime: 80.2191 s\n",
      "epoch: 5 \tstep: 1550 / 3740 \ttrain loss: 0.0205 \ttrain accuracy: 1.0000 \ttime: 89.6547 s\n",
      "epoch: 5 \tstep: 1600 / 3740 \ttrain loss: 0.0229 \ttrain accuracy: 1.0000 \ttime: 79.4548 s\n",
      "epoch: 5 \tstep: 1650 / 3740 \ttrain loss: 0.0295 \ttrain accuracy: 1.0000 \ttime: 82.5841 s\n",
      "epoch: 5 \tstep: 1700 / 3740 \ttrain loss: 0.2015 \ttrain accuracy: 0.8750 \ttime: 81.1387 s\n",
      "epoch: 5 \tstep: 1750 / 3740 \ttrain loss: 0.1764 \ttrain accuracy: 0.8750 \ttime: 82.6710 s\n",
      "epoch: 5 \tstep: 1800 / 3740 \ttrain loss: 0.0141 \ttrain accuracy: 1.0000 \ttime: 80.6429 s\n",
      "epoch: 5 \tstep: 1850 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 81.8056 s\n",
      "epoch: 5 \tstep: 1900 / 3740 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 79.7387 s\n",
      "epoch: 5 \tstep: 1950 / 3740 \ttrain loss: 0.0873 \ttrain accuracy: 0.8750 \ttime: 80.6695 s\n",
      "epoch: 5 \tstep: 2000 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 80.5346 s\n",
      "epoch: 5 \tstep: 2050 / 3740 \ttrain loss: 0.0018 \ttrain accuracy: 1.0000 \ttime: 81.8524 s\n",
      "epoch: 5 \tstep: 2100 / 3740 \ttrain loss: 0.0075 \ttrain accuracy: 1.0000 \ttime: 80.5236 s\n",
      "epoch: 5 \tstep: 2150 / 3740 \ttrain loss: 0.3879 \ttrain accuracy: 0.8750 \ttime: 80.5714 s\n",
      "epoch: 5 \tstep: 2200 / 3740 \ttrain loss: 0.0020 \ttrain accuracy: 1.0000 \ttime: 81.1060 s\n",
      "epoch: 5 \tstep: 2250 / 3740 \ttrain loss: 0.0864 \ttrain accuracy: 1.0000 \ttime: 80.4058 s\n",
      "epoch: 5 \tstep: 2300 / 3740 \ttrain loss: 0.3334 \ttrain accuracy: 0.8750 \ttime: 79.8339 s\n",
      "epoch: 5 \tstep: 2350 / 3740 \ttrain loss: 0.1596 \ttrain accuracy: 0.8750 \ttime: 80.9704 s\n",
      "epoch: 5 \tstep: 2400 / 3740 \ttrain loss: 0.0913 \ttrain accuracy: 0.8750 \ttime: 80.0558 s\n",
      "epoch: 5 \tstep: 2450 / 3740 \ttrain loss: 0.0065 \ttrain accuracy: 1.0000 \ttime: 79.8099 s\n",
      "epoch: 5 \tstep: 2500 / 3740 \ttrain loss: 0.0035 \ttrain accuracy: 1.0000 \ttime: 80.4060 s\n",
      "epoch: 5 \tstep: 2550 / 3740 \ttrain loss: 0.0213 \ttrain accuracy: 1.0000 \ttime: 68.9733 s\n",
      "epoch: 5 \tstep: 2600 / 3740 \ttrain loss: 0.3422 \ttrain accuracy: 0.8750 \ttime: 129.9619 s\n",
      "epoch: 5 \tstep: 2650 / 3740 \ttrain loss: 0.0339 \ttrain accuracy: 1.0000 \ttime: 109.2988 s\n",
      "epoch: 5 \tstep: 2700 / 3740 \ttrain loss: 0.0395 \ttrain accuracy: 1.0000 \ttime: 105.5280 s\n",
      "epoch: 5 \tstep: 2750 / 3740 \ttrain loss: 0.0010 \ttrain accuracy: 1.0000 \ttime: 99.7170 s\n",
      "epoch: 5 \tstep: 2800 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 76.3648 s\n",
      "epoch: 5 \tstep: 2850 / 3740 \ttrain loss: 0.0251 \ttrain accuracy: 1.0000 \ttime: 89.0252 s\n",
      "epoch: 5 \tstep: 2900 / 3740 \ttrain loss: 0.0022 \ttrain accuracy: 1.0000 \ttime: 103.3244 s\n",
      "epoch: 5 \tstep: 2950 / 3740 \ttrain loss: 0.0078 \ttrain accuracy: 1.0000 \ttime: 92.6359 s\n",
      "epoch: 5 \tstep: 3000 / 3740 \ttrain loss: 0.0051 \ttrain accuracy: 1.0000 \ttime: 90.5979 s\n",
      "epoch: 5 \tstep: 3050 / 3740 \ttrain loss: 0.0103 \ttrain accuracy: 1.0000 \ttime: 88.7082 s\n",
      "epoch: 5 \tstep: 3100 / 3740 \ttrain loss: 0.3045 \ttrain accuracy: 0.8750 \ttime: 95.3734 s\n",
      "epoch: 5 \tstep: 3150 / 3740 \ttrain loss: 0.1400 \ttrain accuracy: 0.8750 \ttime: 90.0864 s\n",
      "epoch: 5 \tstep: 3200 / 3740 \ttrain loss: 0.0823 \ttrain accuracy: 1.0000 \ttime: 92.8717 s\n",
      "epoch: 5 \tstep: 3250 / 3740 \ttrain loss: 0.0060 \ttrain accuracy: 1.0000 \ttime: 115.3142 s\n",
      "epoch: 5 \tstep: 3300 / 3740 \ttrain loss: 0.0503 \ttrain accuracy: 1.0000 \ttime: 98.0155 s\n",
      "epoch: 5 \tstep: 3350 / 3740 \ttrain loss: 0.1479 \ttrain accuracy: 0.8750 \ttime: 192.3134 s\n",
      "epoch: 5 \tstep: 3400 / 3740 \ttrain loss: 0.0155 \ttrain accuracy: 1.0000 \ttime: 221.8383 s\n",
      "epoch: 5 \tstep: 3450 / 3740 \ttrain loss: 0.0099 \ttrain accuracy: 1.0000 \ttime: 85.9585 s\n",
      "epoch: 5 \tstep: 3500 / 3740 \ttrain loss: 0.0014 \ttrain accuracy: 1.0000 \ttime: 151.7400 s\n",
      "epoch: 5 \tstep: 3550 / 3740 \ttrain loss: 0.0106 \ttrain accuracy: 1.0000 \ttime: 87.6599 s\n",
      "epoch: 5 \tstep: 3600 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 97.0440 s\n",
      "epoch: 5 \tstep: 3650 / 3740 \ttrain loss: 0.0170 \ttrain accuracy: 1.0000 \ttime: 89.0169 s\n",
      "epoch: 5 \tstep: 3700 / 3740 \ttrain loss: 0.0202 \ttrain accuracy: 1.0000 \ttime: 155.1997 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0e506812574af4bde1c40846edcf58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 40 \ttrain loss: 0.0806 \tvalid loss: 0.0585 \ttrain accuracy 0.9726 \tvalid accuracy 0.9814\n",
      "Model saved to: model.pth\n",
      "epoch: 6 \tstep: 50 / 3740 \ttrain loss: 0.0030 \ttrain accuracy: 1.0000 \ttime: 210.0144 s\n",
      "epoch: 6 \tstep: 100 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 196.3102 s\n",
      "epoch: 6 \tstep: 150 / 3740 \ttrain loss: 0.0340 \ttrain accuracy: 1.0000 \ttime: 83.0294 s\n",
      "epoch: 6 \tstep: 200 / 3740 \ttrain loss: 0.0116 \ttrain accuracy: 1.0000 \ttime: 84.8568 s\n",
      "epoch: 6 \tstep: 250 / 3740 \ttrain loss: 0.9918 \ttrain accuracy: 0.8750 \ttime: 82.8423 s\n",
      "epoch: 6 \tstep: 300 / 3740 \ttrain loss: 0.6886 \ttrain accuracy: 0.8750 \ttime: 83.3102 s\n",
      "epoch: 6 \tstep: 350 / 3740 \ttrain loss: 0.0035 \ttrain accuracy: 1.0000 \ttime: 84.9637 s\n",
      "epoch: 6 \tstep: 400 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 87.0612 s\n",
      "epoch: 6 \tstep: 450 / 3740 \ttrain loss: 0.1564 \ttrain accuracy: 0.8750 \ttime: 83.2925 s\n",
      "epoch: 6 \tstep: 500 / 3740 \ttrain loss: 0.0034 \ttrain accuracy: 1.0000 \ttime: 113.7351 s\n",
      "epoch: 6 \tstep: 550 / 3740 \ttrain loss: 0.4779 \ttrain accuracy: 0.8750 \ttime: 82.5097 s\n",
      "epoch: 6 \tstep: 600 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 85.2064 s\n",
      "epoch: 6 \tstep: 650 / 3740 \ttrain loss: 0.1622 \ttrain accuracy: 1.0000 \ttime: 96.5992 s\n",
      "epoch: 6 \tstep: 700 / 3740 \ttrain loss: 0.0010 \ttrain accuracy: 1.0000 \ttime: 84.1665 s\n",
      "epoch: 6 \tstep: 750 / 3740 \ttrain loss: 0.2243 \ttrain accuracy: 0.8750 \ttime: 82.4857 s\n",
      "epoch: 6 \tstep: 800 / 3740 \ttrain loss: 0.3342 \ttrain accuracy: 0.8750 \ttime: 82.1820 s\n",
      "epoch: 6 \tstep: 850 / 3740 \ttrain loss: 0.0067 \ttrain accuracy: 1.0000 \ttime: 84.8540 s\n",
      "epoch: 6 \tstep: 900 / 3740 \ttrain loss: 0.1807 \ttrain accuracy: 0.8750 \ttime: 113.2871 s\n",
      "epoch: 6 \tstep: 950 / 3740 \ttrain loss: 0.0304 \ttrain accuracy: 1.0000 \ttime: 83.8037 s\n",
      "epoch: 6 \tstep: 1000 / 3740 \ttrain loss: 0.0204 \ttrain accuracy: 1.0000 \ttime: 84.6077 s\n",
      "epoch: 6 \tstep: 1050 / 3740 \ttrain loss: 0.0070 \ttrain accuracy: 1.0000 \ttime: 105.2917 s\n",
      "epoch: 6 \tstep: 1100 / 3740 \ttrain loss: 0.1234 \ttrain accuracy: 0.8750 \ttime: 83.0997 s\n",
      "epoch: 6 \tstep: 1150 / 3740 \ttrain loss: 0.2825 \ttrain accuracy: 0.8750 \ttime: 81.9348 s\n",
      "epoch: 6 \tstep: 1200 / 3740 \ttrain loss: 0.9644 \ttrain accuracy: 0.7500 \ttime: 94.8620 s\n",
      "epoch: 6 \tstep: 1250 / 3740 \ttrain loss: 0.5248 \ttrain accuracy: 0.8750 \ttime: 101.3332 s\n",
      "epoch: 6 \tstep: 1300 / 3740 \ttrain loss: 0.0339 \ttrain accuracy: 1.0000 \ttime: 81.7673 s\n",
      "epoch: 6 \tstep: 1350 / 3740 \ttrain loss: 0.0670 \ttrain accuracy: 1.0000 \ttime: 111.9806 s\n",
      "epoch: 6 \tstep: 1400 / 3740 \ttrain loss: 0.0123 \ttrain accuracy: 1.0000 \ttime: 112.4783 s\n",
      "epoch: 6 \tstep: 1450 / 3740 \ttrain loss: 0.2210 \ttrain accuracy: 0.8750 \ttime: 82.5800 s\n",
      "epoch: 6 \tstep: 1500 / 3740 \ttrain loss: 0.0824 \ttrain accuracy: 1.0000 \ttime: 185.2530 s\n",
      "epoch: 6 \tstep: 1550 / 3740 \ttrain loss: 0.0001 \ttrain accuracy: 1.0000 \ttime: 134.6742 s\n",
      "epoch: 6 \tstep: 1600 / 3740 \ttrain loss: 0.0066 \ttrain accuracy: 1.0000 \ttime: 74.2683 s\n",
      "epoch: 6 \tstep: 1650 / 3740 \ttrain loss: 0.0183 \ttrain accuracy: 1.0000 \ttime: 113.2330 s\n",
      "epoch: 6 \tstep: 1700 / 3740 \ttrain loss: 0.0001 \ttrain accuracy: 1.0000 \ttime: 127.7890 s\n",
      "epoch: 6 \tstep: 1750 / 3740 \ttrain loss: 0.0612 \ttrain accuracy: 1.0000 \ttime: 164.9910 s\n",
      "epoch: 6 \tstep: 1800 / 3740 \ttrain loss: 0.0033 \ttrain accuracy: 1.0000 \ttime: 205.1306 s\n",
      "epoch: 6 \tstep: 1850 / 3740 \ttrain loss: 0.2205 \ttrain accuracy: 0.8750 \ttime: 176.1000 s\n",
      "epoch: 6 \tstep: 1900 / 3740 \ttrain loss: 0.0047 \ttrain accuracy: 1.0000 \ttime: 204.9674 s\n",
      "epoch: 6 \tstep: 1950 / 3740 \ttrain loss: 0.0612 \ttrain accuracy: 1.0000 \ttime: 269.8929 s\n",
      "epoch: 6 \tstep: 2000 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 252.4558 s\n",
      "epoch: 6 \tstep: 2050 / 3740 \ttrain loss: 0.3364 \ttrain accuracy: 0.8750 \ttime: 205.1474 s\n",
      "epoch: 6 \tstep: 2100 / 3740 \ttrain loss: 0.0923 \ttrain accuracy: 1.0000 \ttime: 243.7876 s\n",
      "epoch: 6 \tstep: 2150 / 3740 \ttrain loss: 0.3197 \ttrain accuracy: 0.8750 \ttime: 232.7652 s\n",
      "epoch: 6 \tstep: 2200 / 3740 \ttrain loss: 0.0149 \ttrain accuracy: 1.0000 \ttime: 206.2771 s\n",
      "epoch: 6 \tstep: 2250 / 3740 \ttrain loss: 0.0136 \ttrain accuracy: 1.0000 \ttime: 219.8648 s\n",
      "epoch: 6 \tstep: 2300 / 3740 \ttrain loss: 0.0363 \ttrain accuracy: 1.0000 \ttime: 247.3480 s\n",
      "epoch: 6 \tstep: 2350 / 3740 \ttrain loss: 0.1346 \ttrain accuracy: 0.8750 \ttime: 209.7677 s\n",
      "epoch: 6 \tstep: 2400 / 3740 \ttrain loss: 0.0070 \ttrain accuracy: 1.0000 \ttime: 206.1925 s\n",
      "epoch: 6 \tstep: 2450 / 3740 \ttrain loss: 0.0037 \ttrain accuracy: 1.0000 \ttime: 206.2193 s\n",
      "epoch: 6 \tstep: 2500 / 3740 \ttrain loss: 0.0117 \ttrain accuracy: 1.0000 \ttime: 245.2346 s\n",
      "epoch: 6 \tstep: 2550 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 232.4536 s\n",
      "epoch: 6 \tstep: 2600 / 3740 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 252.4763 s\n",
      "epoch: 6 \tstep: 2650 / 3740 \ttrain loss: 0.1601 \ttrain accuracy: 0.8750 \ttime: 77.3073 s\n",
      "epoch: 6 \tstep: 2700 / 3740 \ttrain loss: 0.1686 \ttrain accuracy: 0.8750 \ttime: 93.0597 s\n",
      "epoch: 6 \tstep: 2750 / 3740 \ttrain loss: 0.0054 \ttrain accuracy: 1.0000 \ttime: 145.5870 s\n",
      "epoch: 6 \tstep: 2800 / 3740 \ttrain loss: 0.0001 \ttrain accuracy: 1.0000 \ttime: 173.4587 s\n",
      "epoch: 6 \tstep: 2850 / 3740 \ttrain loss: 0.0015 \ttrain accuracy: 1.0000 \ttime: 190.0724 s\n",
      "epoch: 6 \tstep: 2900 / 3740 \ttrain loss: 0.0101 \ttrain accuracy: 1.0000 \ttime: 199.9998 s\n",
      "epoch: 6 \tstep: 2950 / 3740 \ttrain loss: 0.2950 \ttrain accuracy: 0.8750 \ttime: 250.0633 s\n",
      "epoch: 6 \tstep: 3000 / 3740 \ttrain loss: 0.0106 \ttrain accuracy: 1.0000 \ttime: 254.9733 s\n",
      "epoch: 6 \tstep: 3050 / 3740 \ttrain loss: 0.0045 \ttrain accuracy: 1.0000 \ttime: 198.5027 s\n",
      "epoch: 6 \tstep: 3100 / 3740 \ttrain loss: 0.1204 \ttrain accuracy: 1.0000 \ttime: 201.2710 s\n",
      "epoch: 6 \tstep: 3150 / 3740 \ttrain loss: 0.0207 \ttrain accuracy: 1.0000 \ttime: 203.5878 s\n",
      "epoch: 6 \tstep: 3200 / 3740 \ttrain loss: 0.0058 \ttrain accuracy: 1.0000 \ttime: 198.7213 s\n",
      "epoch: 6 \tstep: 3250 / 3740 \ttrain loss: 0.1013 \ttrain accuracy: 1.0000 \ttime: 218.7136 s\n",
      "epoch: 6 \tstep: 3300 / 3740 \ttrain loss: 0.0012 \ttrain accuracy: 1.0000 \ttime: 221.1265 s\n",
      "epoch: 6 \tstep: 3350 / 3740 \ttrain loss: 0.0052 \ttrain accuracy: 1.0000 \ttime: 218.6201 s\n",
      "epoch: 6 \tstep: 3400 / 3740 \ttrain loss: 0.0798 \ttrain accuracy: 1.0000 \ttime: 269.9583 s\n",
      "epoch: 6 \tstep: 3450 / 3740 \ttrain loss: 0.0002 \ttrain accuracy: 1.0000 \ttime: 247.6340 s\n",
      "epoch: 6 \tstep: 3500 / 3740 \ttrain loss: 0.0056 \ttrain accuracy: 1.0000 \ttime: 246.3845 s\n",
      "epoch: 6 \tstep: 3550 / 3740 \ttrain loss: 0.1261 \ttrain accuracy: 0.8750 \ttime: 205.0082 s\n",
      "epoch: 6 \tstep: 3600 / 3740 \ttrain loss: 0.0888 \ttrain accuracy: 1.0000 \ttime: 201.1842 s\n",
      "epoch: 6 \tstep: 3650 / 3740 \ttrain loss: 0.0374 \ttrain accuracy: 1.0000 \ttime: 211.1093 s\n",
      "epoch: 6 \tstep: 3700 / 3740 \ttrain loss: 0.0204 \ttrain accuracy: 1.0000 \ttime: 201.1559 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0eacc8e24a54e74b587fb58b58ac831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 40 \ttrain loss: 0.0806 \tvalid loss: 0.0633 \ttrain accuracy 0.9734 \tvalid accuracy 0.9772\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 7 \tstep: 50 / 3740 \ttrain loss: 0.0551 \ttrain accuracy: 1.0000 \ttime: 167.7420 s\n",
      "epoch: 7 \tstep: 100 / 3740 \ttrain loss: 0.0113 \ttrain accuracy: 1.0000 \ttime: 202.6963 s\n",
      "epoch: 7 \tstep: 150 / 3740 \ttrain loss: 0.0044 \ttrain accuracy: 1.0000 \ttime: 201.2300 s\n",
      "epoch: 7 \tstep: 200 / 3740 \ttrain loss: 0.0016 \ttrain accuracy: 1.0000 \ttime: 201.6401 s\n",
      "epoch: 7 \tstep: 250 / 3740 \ttrain loss: 0.0390 \ttrain accuracy: 1.0000 \ttime: 197.7270 s\n",
      "epoch: 7 \tstep: 300 / 3740 \ttrain loss: 0.0047 \ttrain accuracy: 1.0000 \ttime: 205.0071 s\n",
      "epoch: 7 \tstep: 350 / 3740 \ttrain loss: 0.1882 \ttrain accuracy: 0.8750 \ttime: 222.2010 s\n",
      "epoch: 7 \tstep: 400 / 3740 \ttrain loss: 0.0204 \ttrain accuracy: 1.0000 \ttime: 202.0394 s\n",
      "epoch: 7 \tstep: 450 / 3740 \ttrain loss: 0.0026 \ttrain accuracy: 1.0000 \ttime: 204.9242 s\n",
      "epoch: 7 \tstep: 500 / 3740 \ttrain loss: 0.0016 \ttrain accuracy: 1.0000 \ttime: 204.9867 s\n",
      "epoch: 7 \tstep: 550 / 3740 \ttrain loss: 0.0535 \ttrain accuracy: 1.0000 \ttime: 257.6753 s\n",
      "epoch: 7 \tstep: 600 / 3740 \ttrain loss: 0.1610 \ttrain accuracy: 0.8750 \ttime: 202.2963 s\n",
      "epoch: 7 \tstep: 650 / 3740 \ttrain loss: 0.0023 \ttrain accuracy: 1.0000 \ttime: 206.2573 s\n",
      "epoch: 7 \tstep: 700 / 3740 \ttrain loss: 0.0021 \ttrain accuracy: 1.0000 \ttime: 271.2295 s\n",
      "epoch: 7 \tstep: 750 / 3740 \ttrain loss: 0.1893 \ttrain accuracy: 0.8750 \ttime: 297.6816 s\n",
      "epoch: 7 \tstep: 800 / 3740 \ttrain loss: 0.0146 \ttrain accuracy: 1.0000 \ttime: 207.4590 s\n",
      "epoch: 7 \tstep: 850 / 3740 \ttrain loss: 0.0018 \ttrain accuracy: 1.0000 \ttime: 200.0124 s\n",
      "epoch: 7 \tstep: 900 / 3740 \ttrain loss: 0.0041 \ttrain accuracy: 1.0000 \ttime: 200.3065 s\n",
      "epoch: 7 \tstep: 950 / 3740 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 195.0564 s\n",
      "epoch: 7 \tstep: 1000 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 201.2245 s\n",
      "epoch: 7 \tstep: 1050 / 3740 \ttrain loss: 0.0643 \ttrain accuracy: 1.0000 \ttime: 200.0504 s\n",
      "epoch: 7 \tstep: 1100 / 3740 \ttrain loss: 0.0030 \ttrain accuracy: 1.0000 \ttime: 179.8058 s\n",
      "epoch: 7 \tstep: 1150 / 3740 \ttrain loss: 0.0155 \ttrain accuracy: 1.0000 \ttime: 196.0534 s\n",
      "epoch: 7 \tstep: 1200 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 193.6162 s\n",
      "epoch: 7 \tstep: 1250 / 3740 \ttrain loss: 0.0002 \ttrain accuracy: 1.0000 \ttime: 197.6178 s\n",
      "epoch: 7 \tstep: 1300 / 3740 \ttrain loss: 0.1953 \ttrain accuracy: 0.8750 \ttime: 217.6389 s\n",
      "epoch: 7 \tstep: 1350 / 3740 \ttrain loss: 0.0026 \ttrain accuracy: 1.0000 \ttime: 203.7351 s\n",
      "epoch: 7 \tstep: 1400 / 3740 \ttrain loss: 0.0219 \ttrain accuracy: 1.0000 \ttime: 216.2270 s\n",
      "epoch: 7 \tstep: 1450 / 3740 \ttrain loss: 0.0040 \ttrain accuracy: 1.0000 \ttime: 214.5419 s\n",
      "epoch: 7 \tstep: 1500 / 3740 \ttrain loss: 0.1061 \ttrain accuracy: 0.8750 \ttime: 216.2017 s\n",
      "epoch: 7 \tstep: 1550 / 3740 \ttrain loss: 0.0268 \ttrain accuracy: 1.0000 \ttime: 220.0173 s\n",
      "epoch: 7 \tstep: 1600 / 3740 \ttrain loss: 0.0867 \ttrain accuracy: 1.0000 \ttime: 212.6348 s\n",
      "epoch: 7 \tstep: 1650 / 3740 \ttrain loss: 0.0413 \ttrain accuracy: 1.0000 \ttime: 212.4941 s\n",
      "epoch: 7 \tstep: 1700 / 3740 \ttrain loss: 0.0992 \ttrain accuracy: 0.8750 \ttime: 231.2100 s\n",
      "epoch: 7 \tstep: 1750 / 3740 \ttrain loss: 0.0282 \ttrain accuracy: 1.0000 \ttime: 91.7009 s\n",
      "epoch: 7 \tstep: 1800 / 3740 \ttrain loss: 0.0146 \ttrain accuracy: 1.0000 \ttime: 88.5527 s\n",
      "epoch: 7 \tstep: 1850 / 3740 \ttrain loss: 0.0026 \ttrain accuracy: 1.0000 \ttime: 81.5147 s\n",
      "epoch: 7 \tstep: 1900 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 82.9580 s\n",
      "epoch: 7 \tstep: 1950 / 3740 \ttrain loss: 0.0058 \ttrain accuracy: 1.0000 \ttime: 84.7535 s\n",
      "epoch: 7 \tstep: 2000 / 3740 \ttrain loss: 0.0085 \ttrain accuracy: 1.0000 \ttime: 85.4995 s\n",
      "epoch: 7 \tstep: 2050 / 3740 \ttrain loss: 0.0693 \ttrain accuracy: 1.0000 \ttime: 88.8339 s\n",
      "epoch: 7 \tstep: 2100 / 3740 \ttrain loss: 0.0164 \ttrain accuracy: 1.0000 \ttime: 113.9991 s\n",
      "epoch: 7 \tstep: 2150 / 3740 \ttrain loss: 0.1338 \ttrain accuracy: 0.8750 \ttime: 104.9186 s\n",
      "epoch: 7 \tstep: 2200 / 3740 \ttrain loss: 0.0051 \ttrain accuracy: 1.0000 \ttime: 83.1538 s\n",
      "epoch: 7 \tstep: 2250 / 3740 \ttrain loss: 0.0022 \ttrain accuracy: 1.0000 \ttime: 114.1932 s\n",
      "epoch: 7 \tstep: 2300 / 3740 \ttrain loss: 0.2706 \ttrain accuracy: 0.8750 \ttime: 82.8485 s\n",
      "epoch: 7 \tstep: 2350 / 3740 \ttrain loss: 0.0010 \ttrain accuracy: 1.0000 \ttime: 114.2262 s\n",
      "epoch: 7 \tstep: 2400 / 3740 \ttrain loss: 0.2450 \ttrain accuracy: 0.8750 \ttime: 114.1188 s\n",
      "epoch: 7 \tstep: 2450 / 3740 \ttrain loss: 0.0228 \ttrain accuracy: 1.0000 \ttime: 121.3212 s\n",
      "epoch: 7 \tstep: 2500 / 3740 \ttrain loss: 0.0057 \ttrain accuracy: 1.0000 \ttime: 110.0057 s\n",
      "epoch: 7 \tstep: 2550 / 3740 \ttrain loss: 1.0991 \ttrain accuracy: 0.7500 \ttime: 81.9251 s\n",
      "epoch: 7 \tstep: 2600 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 113.8304 s\n",
      "epoch: 7 \tstep: 2650 / 3740 \ttrain loss: 0.0668 \ttrain accuracy: 1.0000 \ttime: 81.4486 s\n",
      "epoch: 7 \tstep: 2700 / 3740 \ttrain loss: 0.0085 \ttrain accuracy: 1.0000 \ttime: 86.3354 s\n",
      "epoch: 7 \tstep: 2750 / 3740 \ttrain loss: 0.4064 \ttrain accuracy: 0.8750 \ttime: 115.2342 s\n",
      "epoch: 7 \tstep: 2800 / 3740 \ttrain loss: 0.0048 \ttrain accuracy: 1.0000 \ttime: 96.4521 s\n",
      "epoch: 7 \tstep: 2850 / 3740 \ttrain loss: 0.2932 \ttrain accuracy: 0.8750 \ttime: 116.0316 s\n",
      "epoch: 7 \tstep: 2900 / 3740 \ttrain loss: 0.0035 \ttrain accuracy: 1.0000 \ttime: 103.2932 s\n",
      "epoch: 7 \tstep: 2950 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 111.1240 s\n",
      "epoch: 7 \tstep: 3000 / 3740 \ttrain loss: 0.0039 \ttrain accuracy: 1.0000 \ttime: 113.0712 s\n",
      "epoch: 7 \tstep: 3050 / 3740 \ttrain loss: 0.0086 \ttrain accuracy: 1.0000 \ttime: 113.0751 s\n",
      "epoch: 7 \tstep: 3100 / 3740 \ttrain loss: 0.0261 \ttrain accuracy: 1.0000 \ttime: 112.7603 s\n",
      "epoch: 7 \tstep: 3150 / 3740 \ttrain loss: 0.0796 \ttrain accuracy: 1.0000 \ttime: 88.5213 s\n",
      "epoch: 7 \tstep: 3200 / 3740 \ttrain loss: 0.8355 \ttrain accuracy: 0.7500 \ttime: 81.2634 s\n",
      "epoch: 7 \tstep: 3250 / 3740 \ttrain loss: 0.0156 \ttrain accuracy: 1.0000 \ttime: 127.3138 s\n",
      "epoch: 7 \tstep: 3300 / 3740 \ttrain loss: 0.0140 \ttrain accuracy: 1.0000 \ttime: 68.9013 s\n",
      "epoch: 7 \tstep: 3350 / 3740 \ttrain loss: 0.0076 \ttrain accuracy: 1.0000 \ttime: 74.2674 s\n",
      "epoch: 7 \tstep: 3400 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 73.2229 s\n",
      "epoch: 7 \tstep: 3450 / 3740 \ttrain loss: 0.0130 \ttrain accuracy: 1.0000 \ttime: 73.5213 s\n",
      "epoch: 7 \tstep: 3500 / 3740 \ttrain loss: 0.0033 \ttrain accuracy: 1.0000 \ttime: 28083.4612 s\n",
      "epoch: 7 \tstep: 3550 / 3740 \ttrain loss: 0.0047 \ttrain accuracy: 1.0000 \ttime: 102.3769 s\n",
      "epoch: 7 \tstep: 3600 / 3740 \ttrain loss: 0.1786 \ttrain accuracy: 0.8750 \ttime: 128.2894 s\n",
      "epoch: 7 \tstep: 3650 / 3740 \ttrain loss: 0.0134 \ttrain accuracy: 1.0000 \ttime: 87.8737 s\n",
      "epoch: 7 \tstep: 3700 / 3740 \ttrain loss: 0.1915 \ttrain accuracy: 0.8750 \ttime: 125.0396 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9301fc4ff5a84659974ceeba4fdb9d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 40 \ttrain loss: 0.0814 \tvalid loss: 0.0569 \ttrain accuracy 0.9739 \tvalid accuracy 0.9820\n",
      "Model saved to: model.pth\n",
      "epoch: 8 \tstep: 50 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 84.1827 s\n",
      "epoch: 8 \tstep: 100 / 3740 \ttrain loss: 0.0030 \ttrain accuracy: 1.0000 \ttime: 85.8652 s\n",
      "epoch: 8 \tstep: 150 / 3740 \ttrain loss: 0.0018 \ttrain accuracy: 1.0000 \ttime: 81.1090 s\n",
      "epoch: 8 \tstep: 200 / 3740 \ttrain loss: 0.0103 \ttrain accuracy: 1.0000 \ttime: 81.5429 s\n",
      "epoch: 8 \tstep: 250 / 3740 \ttrain loss: 0.0308 \ttrain accuracy: 1.0000 \ttime: 82.3310 s\n",
      "epoch: 8 \tstep: 300 / 3740 \ttrain loss: 0.0049 \ttrain accuracy: 1.0000 \ttime: 82.3108 s\n",
      "epoch: 8 \tstep: 350 / 3740 \ttrain loss: 0.1728 \ttrain accuracy: 0.8750 \ttime: 81.1867 s\n",
      "epoch: 8 \tstep: 400 / 3740 \ttrain loss: 0.0167 \ttrain accuracy: 1.0000 \ttime: 81.0765 s\n",
      "epoch: 8 \tstep: 450 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 86.7450 s\n",
      "epoch: 8 \tstep: 500 / 3740 \ttrain loss: 0.0072 \ttrain accuracy: 1.0000 \ttime: 83.1053 s\n",
      "epoch: 8 \tstep: 550 / 3740 \ttrain loss: 1.1078 \ttrain accuracy: 0.8750 \ttime: 81.0286 s\n",
      "epoch: 8 \tstep: 600 / 3740 \ttrain loss: 0.0790 \ttrain accuracy: 1.0000 \ttime: 81.7000 s\n",
      "epoch: 8 \tstep: 650 / 3740 \ttrain loss: 0.3357 \ttrain accuracy: 0.7500 \ttime: 82.6230 s\n",
      "epoch: 8 \tstep: 700 / 3740 \ttrain loss: 0.0077 \ttrain accuracy: 1.0000 \ttime: 81.5035 s\n",
      "epoch: 8 \tstep: 750 / 3740 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 81.1917 s\n",
      "epoch: 8 \tstep: 800 / 3740 \ttrain loss: 0.0058 \ttrain accuracy: 1.0000 \ttime: 81.2512 s\n",
      "epoch: 8 \tstep: 850 / 3740 \ttrain loss: 0.0060 \ttrain accuracy: 1.0000 \ttime: 81.5637 s\n",
      "epoch: 8 \tstep: 900 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 81.7946 s\n",
      "epoch: 8 \tstep: 950 / 3740 \ttrain loss: 0.0018 \ttrain accuracy: 1.0000 \ttime: 81.8595 s\n",
      "epoch: 8 \tstep: 1000 / 3740 \ttrain loss: 0.0338 \ttrain accuracy: 1.0000 \ttime: 81.5380 s\n",
      "epoch: 8 \tstep: 1050 / 3740 \ttrain loss: 0.0839 \ttrain accuracy: 1.0000 \ttime: 82.0341 s\n",
      "epoch: 8 \tstep: 1100 / 3740 \ttrain loss: 0.0189 \ttrain accuracy: 1.0000 \ttime: 81.5520 s\n",
      "epoch: 8 \tstep: 1150 / 3740 \ttrain loss: 0.0068 \ttrain accuracy: 1.0000 \ttime: 82.5243 s\n",
      "epoch: 8 \tstep: 1200 / 3740 \ttrain loss: 0.1695 \ttrain accuracy: 0.8750 \ttime: 80.8819 s\n",
      "epoch: 8 \tstep: 1250 / 3740 \ttrain loss: 0.0771 \ttrain accuracy: 1.0000 \ttime: 81.5787 s\n",
      "epoch: 8 \tstep: 1300 / 3740 \ttrain loss: 0.0173 \ttrain accuracy: 1.0000 \ttime: 81.7093 s\n",
      "epoch: 8 \tstep: 1350 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 82.8719 s\n",
      "epoch: 8 \tstep: 1400 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 84.5610 s\n",
      "epoch: 8 \tstep: 1450 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 85.4782 s\n",
      "epoch: 8 \tstep: 1500 / 3740 \ttrain loss: 0.0016 \ttrain accuracy: 1.0000 \ttime: 81.4705 s\n",
      "epoch: 8 \tstep: 1550 / 3740 \ttrain loss: 0.0010 \ttrain accuracy: 1.0000 \ttime: 80.8581 s\n",
      "epoch: 8 \tstep: 1600 / 3740 \ttrain loss: 0.1948 \ttrain accuracy: 0.8750 \ttime: 81.3352 s\n",
      "epoch: 8 \tstep: 1650 / 3740 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 83.3543 s\n",
      "epoch: 8 \tstep: 1700 / 3740 \ttrain loss: 0.0059 \ttrain accuracy: 1.0000 \ttime: 80.8320 s\n",
      "epoch: 8 \tstep: 1750 / 3740 \ttrain loss: 0.0711 \ttrain accuracy: 1.0000 \ttime: 83.6524 s\n",
      "epoch: 8 \tstep: 1800 / 3740 \ttrain loss: 0.4471 \ttrain accuracy: 0.8750 \ttime: 82.2946 s\n",
      "epoch: 8 \tstep: 1850 / 3740 \ttrain loss: 0.0206 \ttrain accuracy: 1.0000 \ttime: 81.2031 s\n",
      "epoch: 8 \tstep: 1900 / 3740 \ttrain loss: 0.1143 \ttrain accuracy: 1.0000 \ttime: 80.9520 s\n",
      "epoch: 8 \tstep: 1950 / 3740 \ttrain loss: 0.0220 \ttrain accuracy: 1.0000 \ttime: 80.6946 s\n",
      "epoch: 8 \tstep: 2000 / 3740 \ttrain loss: 0.0115 \ttrain accuracy: 1.0000 \ttime: 80.8187 s\n",
      "epoch: 8 \tstep: 2050 / 3740 \ttrain loss: 0.0726 \ttrain accuracy: 1.0000 \ttime: 80.8357 s\n",
      "epoch: 8 \tstep: 2100 / 3740 \ttrain loss: 0.0505 \ttrain accuracy: 1.0000 \ttime: 93.5797 s\n",
      "epoch: 8 \tstep: 2150 / 3740 \ttrain loss: 0.0083 \ttrain accuracy: 1.0000 \ttime: 81.6980 s\n",
      "epoch: 8 \tstep: 2200 / 3740 \ttrain loss: 0.0622 \ttrain accuracy: 1.0000 \ttime: 80.8883 s\n",
      "epoch: 8 \tstep: 2250 / 3740 \ttrain loss: 0.1619 \ttrain accuracy: 0.8750 \ttime: 81.7844 s\n",
      "epoch: 8 \tstep: 2300 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 80.5410 s\n",
      "epoch: 8 \tstep: 2350 / 3740 \ttrain loss: 0.2488 \ttrain accuracy: 0.8750 \ttime: 82.8205 s\n",
      "epoch: 8 \tstep: 2400 / 3740 \ttrain loss: 0.0858 \ttrain accuracy: 1.0000 \ttime: 81.3667 s\n",
      "epoch: 8 \tstep: 2450 / 3740 \ttrain loss: 0.1618 \ttrain accuracy: 0.8750 \ttime: 73.7683 s\n",
      "epoch: 8 \tstep: 2500 / 3740 \ttrain loss: 0.0440 \ttrain accuracy: 1.0000 \ttime: 68.9423 s\n",
      "epoch: 8 \tstep: 2550 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 71.2175 s\n",
      "epoch: 8 \tstep: 2600 / 3740 \ttrain loss: 0.2000 \ttrain accuracy: 0.8750 \ttime: 68.6244 s\n",
      "epoch: 8 \tstep: 2650 / 3740 \ttrain loss: 0.0088 \ttrain accuracy: 1.0000 \ttime: 112.0685 s\n",
      "epoch: 8 \tstep: 2700 / 3740 \ttrain loss: 0.0285 \ttrain accuracy: 1.0000 \ttime: 77.3126 s\n",
      "epoch: 8 \tstep: 2750 / 3740 \ttrain loss: 0.0019 \ttrain accuracy: 1.0000 \ttime: 72.1165 s\n",
      "epoch: 8 \tstep: 2800 / 3740 \ttrain loss: 0.0620 \ttrain accuracy: 1.0000 \ttime: 68.9178 s\n",
      "epoch: 8 \tstep: 2850 / 3740 \ttrain loss: 0.2929 \ttrain accuracy: 0.8750 \ttime: 74.8148 s\n",
      "epoch: 8 \tstep: 2900 / 3740 \ttrain loss: 0.1207 \ttrain accuracy: 0.8750 \ttime: 70.1102 s\n",
      "epoch: 8 \tstep: 2950 / 3740 \ttrain loss: 0.8192 \ttrain accuracy: 0.7500 \ttime: 77.0194 s\n",
      "epoch: 8 \tstep: 3000 / 3740 \ttrain loss: 0.0025 \ttrain accuracy: 1.0000 \ttime: 85.0640 s\n",
      "epoch: 8 \tstep: 3050 / 3740 \ttrain loss: 0.0026 \ttrain accuracy: 1.0000 \ttime: 113.8562 s\n",
      "epoch: 8 \tstep: 3100 / 3740 \ttrain loss: 0.0019 \ttrain accuracy: 1.0000 \ttime: 113.0847 s\n",
      "epoch: 8 \tstep: 3150 / 3740 \ttrain loss: 0.0941 \ttrain accuracy: 0.8750 \ttime: 188.5888 s\n",
      "epoch: 8 \tstep: 3200 / 3740 \ttrain loss: 0.0050 \ttrain accuracy: 1.0000 \ttime: 129.5238 s\n",
      "epoch: 8 \tstep: 3250 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 69.0045 s\n",
      "epoch: 8 \tstep: 3300 / 3740 \ttrain loss: 0.0833 \ttrain accuracy: 1.0000 \ttime: 71.6985 s\n",
      "epoch: 8 \tstep: 3350 / 3740 \ttrain loss: 0.0042 \ttrain accuracy: 1.0000 \ttime: 69.6965 s\n",
      "epoch: 8 \tstep: 3400 / 3740 \ttrain loss: 0.0020 \ttrain accuracy: 1.0000 \ttime: 70.3429 s\n",
      "epoch: 8 \tstep: 3450 / 3740 \ttrain loss: 0.0432 \ttrain accuracy: 1.0000 \ttime: 69.9383 s\n",
      "epoch: 8 \tstep: 3500 / 3740 \ttrain loss: 0.0111 \ttrain accuracy: 1.0000 \ttime: 71.5931 s\n",
      "epoch: 8 \tstep: 3550 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 72.9712 s\n",
      "epoch: 8 \tstep: 3600 / 3740 \ttrain loss: 0.0026 \ttrain accuracy: 1.0000 \ttime: 77.2097 s\n",
      "epoch: 8 \tstep: 3650 / 3740 \ttrain loss: 0.7764 \ttrain accuracy: 0.8750 \ttime: 73.8997 s\n",
      "epoch: 8 \tstep: 3700 / 3740 \ttrain loss: 0.0057 \ttrain accuracy: 1.0000 \ttime: 118.6788 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804e2791d17540eb96e9c79fffa75aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 40 \ttrain loss: 0.0804 \tvalid loss: 0.0551 \ttrain accuracy 0.9732 \tvalid accuracy 0.9810\n",
      "Model saved to: model.pth\n",
      "epoch: 9 \tstep: 50 / 3740 \ttrain loss: 0.0367 \ttrain accuracy: 1.0000 \ttime: 81.6040 s\n",
      "epoch: 9 \tstep: 100 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 81.0772 s\n",
      "epoch: 9 \tstep: 150 / 3740 \ttrain loss: 0.1766 \ttrain accuracy: 0.8750 \ttime: 82.0724 s\n",
      "epoch: 9 \tstep: 200 / 3740 \ttrain loss: 0.0065 \ttrain accuracy: 1.0000 \ttime: 81.9813 s\n",
      "epoch: 9 \tstep: 250 / 3740 \ttrain loss: 0.0060 \ttrain accuracy: 1.0000 \ttime: 81.2257 s\n",
      "epoch: 9 \tstep: 300 / 3740 \ttrain loss: 0.0447 \ttrain accuracy: 1.0000 \ttime: 99.6992 s\n",
      "epoch: 9 \tstep: 350 / 3740 \ttrain loss: 0.0091 \ttrain accuracy: 1.0000 \ttime: 98.3002 s\n",
      "epoch: 9 \tstep: 400 / 3740 \ttrain loss: 0.2770 \ttrain accuracy: 0.8750 \ttime: 99.9665 s\n",
      "epoch: 9 \tstep: 450 / 3740 \ttrain loss: 0.3160 \ttrain accuracy: 0.8750 \ttime: 102.8870 s\n",
      "epoch: 9 \tstep: 500 / 3740 \ttrain loss: 0.0113 \ttrain accuracy: 1.0000 \ttime: 100.4773 s\n",
      "epoch: 9 \tstep: 550 / 3740 \ttrain loss: 0.0052 \ttrain accuracy: 1.0000 \ttime: 96.6524 s\n",
      "epoch: 9 \tstep: 600 / 3740 \ttrain loss: 0.0480 \ttrain accuracy: 1.0000 \ttime: 101.2394 s\n",
      "epoch: 9 \tstep: 650 / 3740 \ttrain loss: 0.0010 \ttrain accuracy: 1.0000 \ttime: 99.9775 s\n",
      "epoch: 9 \tstep: 700 / 3740 \ttrain loss: 0.0016 \ttrain accuracy: 1.0000 \ttime: 99.1807 s\n",
      "epoch: 9 \tstep: 750 / 3740 \ttrain loss: 0.0095 \ttrain accuracy: 1.0000 \ttime: 100.9890 s\n",
      "epoch: 9 \tstep: 800 / 3740 \ttrain loss: 0.0049 \ttrain accuracy: 1.0000 \ttime: 97.6887 s\n",
      "epoch: 9 \tstep: 850 / 3740 \ttrain loss: 0.0622 \ttrain accuracy: 1.0000 \ttime: 99.8181 s\n",
      "epoch: 9 \tstep: 900 / 3740 \ttrain loss: 0.1114 \ttrain accuracy: 1.0000 \ttime: 99.3292 s\n",
      "epoch: 9 \tstep: 950 / 3740 \ttrain loss: 0.1167 \ttrain accuracy: 0.8750 \ttime: 99.2715 s\n",
      "epoch: 9 \tstep: 1000 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 99.4542 s\n",
      "epoch: 9 \tstep: 1050 / 3740 \ttrain loss: 0.0036 \ttrain accuracy: 1.0000 \ttime: 102.0724 s\n",
      "epoch: 9 \tstep: 1100 / 3740 \ttrain loss: 0.0252 \ttrain accuracy: 1.0000 \ttime: 97.8260 s\n",
      "epoch: 9 \tstep: 1150 / 3740 \ttrain loss: 0.0071 \ttrain accuracy: 1.0000 \ttime: 105.2699 s\n",
      "epoch: 9 \tstep: 1200 / 3740 \ttrain loss: 0.0284 \ttrain accuracy: 1.0000 \ttime: 97.8927 s\n",
      "epoch: 9 \tstep: 1250 / 3740 \ttrain loss: 0.0653 \ttrain accuracy: 1.0000 \ttime: 99.4334 s\n",
      "epoch: 9 \tstep: 1300 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 100.8960 s\n",
      "epoch: 9 \tstep: 1350 / 3740 \ttrain loss: 0.0390 \ttrain accuracy: 1.0000 \ttime: 102.7048 s\n",
      "epoch: 9 \tstep: 1400 / 3740 \ttrain loss: 0.0032 \ttrain accuracy: 1.0000 \ttime: 117.3487 s\n",
      "epoch: 9 \tstep: 1450 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 98.4433 s\n",
      "epoch: 9 \tstep: 1500 / 3740 \ttrain loss: 0.0039 \ttrain accuracy: 1.0000 \ttime: 106.6222 s\n",
      "epoch: 9 \tstep: 1550 / 3740 \ttrain loss: 0.0054 \ttrain accuracy: 1.0000 \ttime: 92.6711 s\n",
      "epoch: 9 \tstep: 1600 / 3740 \ttrain loss: 0.0032 \ttrain accuracy: 1.0000 \ttime: 81.2053 s\n",
      "epoch: 9 \tstep: 1650 / 3740 \ttrain loss: 0.0053 \ttrain accuracy: 1.0000 \ttime: 97.7880 s\n",
      "epoch: 9 \tstep: 1700 / 3740 \ttrain loss: 0.1571 \ttrain accuracy: 0.8750 \ttime: 176.6558 s\n",
      "epoch: 9 \tstep: 1750 / 3740 \ttrain loss: 0.0215 \ttrain accuracy: 1.0000 \ttime: 80.5634 s\n",
      "epoch: 9 \tstep: 1800 / 3740 \ttrain loss: 0.0098 \ttrain accuracy: 1.0000 \ttime: 109.6350 s\n",
      "epoch: 9 \tstep: 1850 / 3740 \ttrain loss: 0.0762 \ttrain accuracy: 1.0000 \ttime: 92.6742 s\n",
      "epoch: 9 \tstep: 1900 / 3740 \ttrain loss: 0.2113 \ttrain accuracy: 0.8750 \ttime: 108.0458 s\n",
      "epoch: 9 \tstep: 1950 / 3740 \ttrain loss: 0.0052 \ttrain accuracy: 1.0000 \ttime: 172.0611 s\n",
      "epoch: 9 \tstep: 2000 / 3740 \ttrain loss: 0.0020 \ttrain accuracy: 1.0000 \ttime: 80.9988 s\n",
      "epoch: 9 \tstep: 2050 / 3740 \ttrain loss: 0.0601 \ttrain accuracy: 1.0000 \ttime: 99.0180 s\n",
      "epoch: 9 \tstep: 2100 / 3740 \ttrain loss: 0.0272 \ttrain accuracy: 1.0000 \ttime: 127.7599 s\n",
      "epoch: 9 \tstep: 2150 / 3740 \ttrain loss: 0.0056 \ttrain accuracy: 1.0000 \ttime: 101.2715 s\n",
      "epoch: 9 \tstep: 2200 / 3740 \ttrain loss: 0.1054 \ttrain accuracy: 0.8750 \ttime: 103.3934 s\n",
      "epoch: 9 \tstep: 2250 / 3740 \ttrain loss: 0.0217 \ttrain accuracy: 1.0000 \ttime: 103.2377 s\n",
      "epoch: 9 \tstep: 2300 / 3740 \ttrain loss: 0.0504 \ttrain accuracy: 1.0000 \ttime: 92.1765 s\n",
      "epoch: 9 \tstep: 2350 / 3740 \ttrain loss: 0.0029 \ttrain accuracy: 1.0000 \ttime: 131.0599 s\n",
      "epoch: 9 \tstep: 2400 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 93.4055 s\n",
      "epoch: 9 \tstep: 2450 / 3740 \ttrain loss: 0.0093 \ttrain accuracy: 1.0000 \ttime: 99.5822 s\n",
      "epoch: 9 \tstep: 2500 / 3740 \ttrain loss: 0.0012 \ttrain accuracy: 1.0000 \ttime: 85.9913 s\n",
      "epoch: 9 \tstep: 2550 / 3740 \ttrain loss: 0.0069 \ttrain accuracy: 1.0000 \ttime: 85.2760 s\n",
      "epoch: 9 \tstep: 2600 / 3740 \ttrain loss: 0.0920 \ttrain accuracy: 1.0000 \ttime: 128.8587 s\n",
      "epoch: 9 \tstep: 2650 / 3740 \ttrain loss: 0.0833 \ttrain accuracy: 1.0000 \ttime: 83.0312 s\n",
      "epoch: 9 \tstep: 2700 / 3740 \ttrain loss: 0.0089 \ttrain accuracy: 1.0000 \ttime: 123.8734 s\n",
      "epoch: 9 \tstep: 2750 / 3740 \ttrain loss: 0.0052 \ttrain accuracy: 1.0000 \ttime: 86.8881 s\n",
      "epoch: 9 \tstep: 2800 / 3740 \ttrain loss: 0.0074 \ttrain accuracy: 1.0000 \ttime: 84.8822 s\n",
      "epoch: 9 \tstep: 2850 / 3740 \ttrain loss: 0.0036 \ttrain accuracy: 1.0000 \ttime: 82.9788 s\n",
      "epoch: 9 \tstep: 2900 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 174.1399 s\n",
      "epoch: 9 \tstep: 2950 / 3740 \ttrain loss: 0.0056 \ttrain accuracy: 1.0000 \ttime: 94.2343 s\n",
      "epoch: 9 \tstep: 3000 / 3740 \ttrain loss: 0.0023 \ttrain accuracy: 1.0000 \ttime: 138.3227 s\n",
      "epoch: 9 \tstep: 3050 / 3740 \ttrain loss: 0.1039 \ttrain accuracy: 0.8750 \ttime: 89.4692 s\n",
      "epoch: 9 \tstep: 3100 / 3740 \ttrain loss: 0.0020 \ttrain accuracy: 1.0000 \ttime: 81.7970 s\n",
      "epoch: 9 \tstep: 3150 / 3740 \ttrain loss: 0.0116 \ttrain accuracy: 1.0000 \ttime: 113.5443 s\n",
      "epoch: 9 \tstep: 3200 / 3740 \ttrain loss: 0.0021 \ttrain accuracy: 1.0000 \ttime: 91.0910 s\n",
      "epoch: 9 \tstep: 3250 / 3740 \ttrain loss: 0.0140 \ttrain accuracy: 1.0000 \ttime: 83.9999 s\n",
      "epoch: 9 \tstep: 3300 / 3740 \ttrain loss: 0.0051 \ttrain accuracy: 1.0000 \ttime: 168.1509 s\n",
      "epoch: 9 \tstep: 3350 / 3740 \ttrain loss: 0.2732 \ttrain accuracy: 0.8750 \ttime: 141.2944 s\n",
      "epoch: 9 \tstep: 3400 / 3740 \ttrain loss: 0.0110 \ttrain accuracy: 1.0000 \ttime: 81.9622 s\n",
      "epoch: 9 \tstep: 3450 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 83.1345 s\n",
      "epoch: 9 \tstep: 3500 / 3740 \ttrain loss: 0.0085 \ttrain accuracy: 1.0000 \ttime: 129.8004 s\n",
      "epoch: 9 \tstep: 3550 / 3740 \ttrain loss: 0.0189 \ttrain accuracy: 1.0000 \ttime: 128.3858 s\n",
      "epoch: 9 \tstep: 3600 / 3740 \ttrain loss: 0.1623 \ttrain accuracy: 0.8750 \ttime: 113.7826 s\n",
      "epoch: 9 \tstep: 3650 / 3740 \ttrain loss: 0.0129 \ttrain accuracy: 1.0000 \ttime: 89.6766 s\n",
      "epoch: 9 \tstep: 3700 / 3740 \ttrain loss: 0.0032 \ttrain accuracy: 1.0000 \ttime: 69.4317 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0868fb0dd549c1b44b4fabca6d72b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 40 \ttrain loss: 0.0822 \tvalid loss: 0.0609 \ttrain accuracy 0.9742 \tvalid accuracy 0.9792\n",
      "INFO: Early stopping counter 1 of 4\n",
      "epoch: 10 \tstep: 50 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 85.8731 s\n",
      "epoch: 10 \tstep: 100 / 3740 \ttrain loss: 0.1102 \ttrain accuracy: 0.8750 \ttime: 121.2073 s\n",
      "epoch: 10 \tstep: 150 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 116.3321 s\n",
      "epoch: 10 \tstep: 200 / 3740 \ttrain loss: 0.0039 \ttrain accuracy: 1.0000 \ttime: 118.3053 s\n",
      "epoch: 10 \tstep: 250 / 3740 \ttrain loss: 0.0730 \ttrain accuracy: 1.0000 \ttime: 84.7685 s\n",
      "epoch: 10 \tstep: 300 / 3740 \ttrain loss: 0.0039 \ttrain accuracy: 1.0000 \ttime: 81.7795 s\n",
      "epoch: 10 \tstep: 350 / 3740 \ttrain loss: 0.2709 \ttrain accuracy: 0.8750 \ttime: 111.6294 s\n",
      "epoch: 10 \tstep: 400 / 3740 \ttrain loss: 0.2518 \ttrain accuracy: 0.8750 \ttime: 112.0837 s\n",
      "epoch: 10 \tstep: 450 / 3740 \ttrain loss: 0.0017 \ttrain accuracy: 1.0000 \ttime: 89.5344 s\n",
      "epoch: 10 \tstep: 500 / 3740 \ttrain loss: 0.0483 \ttrain accuracy: 1.0000 \ttime: 115.0086 s\n",
      "epoch: 10 \tstep: 550 / 3740 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 114.4347 s\n",
      "epoch: 10 \tstep: 600 / 3740 \ttrain loss: 0.0138 \ttrain accuracy: 1.0000 \ttime: 105.9791 s\n",
      "epoch: 10 \tstep: 650 / 3740 \ttrain loss: 0.0817 \ttrain accuracy: 1.0000 \ttime: 184.3267 s\n",
      "epoch: 10 \tstep: 700 / 3740 \ttrain loss: 0.7803 \ttrain accuracy: 0.8750 \ttime: 106.6920 s\n",
      "epoch: 10 \tstep: 750 / 3740 \ttrain loss: 0.0039 \ttrain accuracy: 1.0000 \ttime: 82.3712 s\n",
      "epoch: 10 \tstep: 800 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 81.7587 s\n",
      "epoch: 10 \tstep: 850 / 3740 \ttrain loss: 0.0043 \ttrain accuracy: 1.0000 \ttime: 80.8538 s\n",
      "epoch: 10 \tstep: 900 / 3740 \ttrain loss: 0.5397 \ttrain accuracy: 0.8750 \ttime: 81.6633 s\n",
      "epoch: 10 \tstep: 950 / 3740 \ttrain loss: 0.0390 \ttrain accuracy: 1.0000 \ttime: 114.1897 s\n",
      "epoch: 10 \tstep: 1000 / 3740 \ttrain loss: 0.0010 \ttrain accuracy: 1.0000 \ttime: 84.9254 s\n",
      "epoch: 10 \tstep: 1050 / 3740 \ttrain loss: 0.0322 \ttrain accuracy: 1.0000 \ttime: 114.4787 s\n",
      "epoch: 10 \tstep: 1100 / 3740 \ttrain loss: 0.0267 \ttrain accuracy: 1.0000 \ttime: 112.3098 s\n",
      "epoch: 10 \tstep: 1150 / 3740 \ttrain loss: 0.0852 \ttrain accuracy: 1.0000 \ttime: 82.4204 s\n",
      "epoch: 10 \tstep: 1200 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 112.1318 s\n",
      "epoch: 10 \tstep: 1250 / 3740 \ttrain loss: 0.0899 \ttrain accuracy: 1.0000 \ttime: 81.4767 s\n",
      "epoch: 10 \tstep: 1300 / 3740 \ttrain loss: 0.3844 \ttrain accuracy: 0.8750 \ttime: 89.3835 s\n",
      "epoch: 10 \tstep: 1350 / 3740 \ttrain loss: 0.0258 \ttrain accuracy: 1.0000 \ttime: 114.3100 s\n",
      "epoch: 10 \tstep: 1400 / 3740 \ttrain loss: 0.0115 \ttrain accuracy: 1.0000 \ttime: 117.1618 s\n",
      "epoch: 10 \tstep: 1450 / 3740 \ttrain loss: 0.0598 \ttrain accuracy: 1.0000 \ttime: 95.9273 s\n",
      "epoch: 10 \tstep: 1500 / 3740 \ttrain loss: 0.0073 \ttrain accuracy: 1.0000 \ttime: 113.7894 s\n",
      "epoch: 10 \tstep: 1550 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 81.8080 s\n",
      "epoch: 10 \tstep: 1600 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 113.3754 s\n",
      "epoch: 10 \tstep: 1650 / 3740 \ttrain loss: 0.0263 \ttrain accuracy: 1.0000 \ttime: 103.3592 s\n",
      "epoch: 10 \tstep: 1700 / 3740 \ttrain loss: 0.0332 \ttrain accuracy: 1.0000 \ttime: 112.9624 s\n",
      "epoch: 10 \tstep: 1750 / 3740 \ttrain loss: 0.0144 \ttrain accuracy: 1.0000 \ttime: 113.5760 s\n",
      "epoch: 10 \tstep: 1800 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 85.0067 s\n",
      "epoch: 10 \tstep: 1850 / 3740 \ttrain loss: 0.0222 \ttrain accuracy: 1.0000 \ttime: 113.4819 s\n",
      "epoch: 10 \tstep: 1900 / 3740 \ttrain loss: 0.1738 \ttrain accuracy: 0.8750 \ttime: 85.9885 s\n",
      "epoch: 10 \tstep: 1950 / 3740 \ttrain loss: 0.0044 \ttrain accuracy: 1.0000 \ttime: 112.4783 s\n",
      "epoch: 10 \tstep: 2000 / 3740 \ttrain loss: 0.1991 \ttrain accuracy: 0.8750 \ttime: 112.1101 s\n",
      "epoch: 10 \tstep: 2050 / 3740 \ttrain loss: 0.0122 \ttrain accuracy: 1.0000 \ttime: 83.2317 s\n",
      "epoch: 10 \tstep: 2100 / 3740 \ttrain loss: 0.0484 \ttrain accuracy: 1.0000 \ttime: 109.1869 s\n",
      "epoch: 10 \tstep: 2150 / 3740 \ttrain loss: 0.0038 \ttrain accuracy: 1.0000 \ttime: 97.1150 s\n",
      "epoch: 10 \tstep: 2200 / 3740 \ttrain loss: 0.0001 \ttrain accuracy: 1.0000 \ttime: 111.9676 s\n",
      "epoch: 10 \tstep: 2250 / 3740 \ttrain loss: 0.1138 \ttrain accuracy: 0.8750 \ttime: 91.6898 s\n",
      "epoch: 10 \tstep: 2300 / 3740 \ttrain loss: 0.0674 \ttrain accuracy: 1.0000 \ttime: 113.2041 s\n",
      "epoch: 10 \tstep: 2350 / 3740 \ttrain loss: 0.3149 \ttrain accuracy: 0.8750 \ttime: 89.1248 s\n",
      "epoch: 10 \tstep: 2400 / 3740 \ttrain loss: 0.0166 \ttrain accuracy: 1.0000 \ttime: 114.1766 s\n",
      "epoch: 10 \tstep: 2450 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 91.4790 s\n",
      "epoch: 10 \tstep: 2500 / 3740 \ttrain loss: 0.0055 \ttrain accuracy: 1.0000 \ttime: 87.9282 s\n",
      "epoch: 10 \tstep: 2550 / 3740 \ttrain loss: 0.0055 \ttrain accuracy: 1.0000 \ttime: 114.9817 s\n",
      "epoch: 10 \tstep: 2600 / 3740 \ttrain loss: 0.0235 \ttrain accuracy: 1.0000 \ttime: 83.4976 s\n",
      "epoch: 10 \tstep: 2650 / 3740 \ttrain loss: 0.0075 \ttrain accuracy: 1.0000 \ttime: 85.0664 s\n",
      "epoch: 10 \tstep: 2700 / 3740 \ttrain loss: 0.0031 \ttrain accuracy: 1.0000 \ttime: 81.1147 s\n",
      "epoch: 10 \tstep: 2750 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 81.9121 s\n",
      "epoch: 10 \tstep: 2800 / 3740 \ttrain loss: 0.0500 \ttrain accuracy: 1.0000 \ttime: 82.9664 s\n",
      "epoch: 10 \tstep: 2850 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 112.3590 s\n",
      "epoch: 10 \tstep: 2900 / 3740 \ttrain loss: 0.6259 \ttrain accuracy: 0.7500 \ttime: 99.5355 s\n",
      "epoch: 10 \tstep: 2950 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 112.2312 s\n",
      "epoch: 10 \tstep: 3000 / 3740 \ttrain loss: 0.0057 \ttrain accuracy: 1.0000 \ttime: 92.4939 s\n",
      "epoch: 10 \tstep: 3050 / 3740 \ttrain loss: 0.1441 \ttrain accuracy: 0.8750 \ttime: 99.6048 s\n",
      "epoch: 10 \tstep: 3100 / 3740 \ttrain loss: 0.0395 \ttrain accuracy: 1.0000 \ttime: 82.4533 s\n",
      "epoch: 10 \tstep: 3150 / 3740 \ttrain loss: 0.0027 \ttrain accuracy: 1.0000 \ttime: 110.2586 s\n",
      "epoch: 10 \tstep: 3200 / 3740 \ttrain loss: 0.1357 \ttrain accuracy: 0.8750 \ttime: 83.1145 s\n",
      "epoch: 10 \tstep: 3250 / 3740 \ttrain loss: 0.0129 \ttrain accuracy: 1.0000 \ttime: 116.2187 s\n",
      "epoch: 10 \tstep: 3300 / 3740 \ttrain loss: 0.0267 \ttrain accuracy: 1.0000 \ttime: 119.2592 s\n",
      "epoch: 10 \tstep: 3350 / 3740 \ttrain loss: 0.0025 \ttrain accuracy: 1.0000 \ttime: 82.5382 s\n",
      "epoch: 10 \tstep: 3400 / 3740 \ttrain loss: 1.2302 \ttrain accuracy: 0.6250 \ttime: 94.8322 s\n",
      "epoch: 10 \tstep: 3450 / 3740 \ttrain loss: 0.0274 \ttrain accuracy: 1.0000 \ttime: 83.3033 s\n",
      "epoch: 10 \tstep: 3500 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 103.5226 s\n",
      "epoch: 10 \tstep: 3550 / 3740 \ttrain loss: 0.0230 \ttrain accuracy: 1.0000 \ttime: 113.5214 s\n",
      "epoch: 10 \tstep: 3600 / 3740 \ttrain loss: 0.0660 \ttrain accuracy: 1.0000 \ttime: 82.4002 s\n",
      "epoch: 10 \tstep: 3650 / 3740 \ttrain loss: 0.0202 \ttrain accuracy: 1.0000 \ttime: 85.5719 s\n",
      "epoch: 10 \tstep: 3700 / 3740 \ttrain loss: 0.0552 \ttrain accuracy: 1.0000 \ttime: 82.7466 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48db94ca010c4969af8b500da9edf4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 40 \ttrain loss: 0.0789 \tvalid loss: 0.0699 \ttrain accuracy 0.9749 \tvalid accuracy 0.9758\n",
      "INFO: Early stopping counter 2 of 4\n",
      "epoch: 11 \tstep: 50 / 3740 \ttrain loss: 0.0411 \ttrain accuracy: 1.0000 \ttime: 85.9308 s\n",
      "epoch: 11 \tstep: 100 / 3740 \ttrain loss: 0.0167 \ttrain accuracy: 1.0000 \ttime: 80.6246 s\n",
      "epoch: 11 \tstep: 150 / 3740 \ttrain loss: 0.0318 \ttrain accuracy: 1.0000 \ttime: 94.6540 s\n",
      "epoch: 11 \tstep: 200 / 3740 \ttrain loss: 0.0144 \ttrain accuracy: 1.0000 \ttime: 100.7901 s\n",
      "epoch: 11 \tstep: 250 / 3740 \ttrain loss: 0.0124 \ttrain accuracy: 1.0000 \ttime: 115.0287 s\n",
      "epoch: 11 \tstep: 300 / 3740 \ttrain loss: 0.0080 \ttrain accuracy: 1.0000 \ttime: 81.2364 s\n",
      "epoch: 11 \tstep: 350 / 3740 \ttrain loss: 0.0034 \ttrain accuracy: 1.0000 \ttime: 102.2296 s\n",
      "epoch: 11 \tstep: 400 / 3740 \ttrain loss: 0.0181 \ttrain accuracy: 1.0000 \ttime: 80.5103 s\n",
      "epoch: 11 \tstep: 450 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 112.1413 s\n",
      "epoch: 11 \tstep: 500 / 3740 \ttrain loss: 0.0200 \ttrain accuracy: 1.0000 \ttime: 87.7962 s\n",
      "epoch: 11 \tstep: 550 / 3740 \ttrain loss: 0.0184 \ttrain accuracy: 1.0000 \ttime: 80.4264 s\n",
      "epoch: 11 \tstep: 600 / 3740 \ttrain loss: 0.0046 \ttrain accuracy: 1.0000 \ttime: 113.3459 s\n",
      "epoch: 11 \tstep: 650 / 3740 \ttrain loss: 0.0015 \ttrain accuracy: 1.0000 \ttime: 80.7828 s\n",
      "epoch: 11 \tstep: 700 / 3740 \ttrain loss: 0.0682 \ttrain accuracy: 1.0000 \ttime: 86.3289 s\n",
      "epoch: 11 \tstep: 750 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 101.3321 s\n",
      "epoch: 11 \tstep: 800 / 3740 \ttrain loss: 0.0923 \ttrain accuracy: 1.0000 \ttime: 107.2168 s\n",
      "epoch: 11 \tstep: 850 / 3740 \ttrain loss: 0.0047 \ttrain accuracy: 1.0000 \ttime: 81.7163 s\n",
      "epoch: 11 \tstep: 900 / 3740 \ttrain loss: 0.0313 \ttrain accuracy: 1.0000 \ttime: 82.2394 s\n",
      "epoch: 11 \tstep: 950 / 3740 \ttrain loss: 0.0070 \ttrain accuracy: 1.0000 \ttime: 81.4417 s\n",
      "epoch: 11 \tstep: 1000 / 3740 \ttrain loss: 0.2583 \ttrain accuracy: 0.8750 \ttime: 81.8418 s\n",
      "epoch: 11 \tstep: 1050 / 3740 \ttrain loss: 0.1863 \ttrain accuracy: 0.7500 \ttime: 80.4291 s\n",
      "epoch: 11 \tstep: 1100 / 3740 \ttrain loss: 0.0038 \ttrain accuracy: 1.0000 \ttime: 112.8147 s\n",
      "epoch: 11 \tstep: 1150 / 3740 \ttrain loss: 0.1874 \ttrain accuracy: 0.8750 \ttime: 92.0336 s\n",
      "epoch: 11 \tstep: 1200 / 3740 \ttrain loss: 0.0033 \ttrain accuracy: 1.0000 \ttime: 108.0734 s\n",
      "epoch: 11 \tstep: 1250 / 3740 \ttrain loss: 0.0106 \ttrain accuracy: 1.0000 \ttime: 81.5571 s\n",
      "epoch: 11 \tstep: 1300 / 3740 \ttrain loss: 0.0243 \ttrain accuracy: 1.0000 \ttime: 98.9982 s\n",
      "epoch: 11 \tstep: 1350 / 3740 \ttrain loss: 0.0013 \ttrain accuracy: 1.0000 \ttime: 83.5636 s\n",
      "epoch: 11 \tstep: 1400 / 3740 \ttrain loss: 0.1459 \ttrain accuracy: 0.8750 \ttime: 82.5112 s\n",
      "epoch: 11 \tstep: 1450 / 3740 \ttrain loss: 0.0113 \ttrain accuracy: 1.0000 \ttime: 89.3067 s\n",
      "epoch: 11 \tstep: 1500 / 3740 \ttrain loss: 0.0943 \ttrain accuracy: 1.0000 \ttime: 83.3483 s\n",
      "epoch: 11 \tstep: 1550 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 114.6739 s\n",
      "epoch: 11 \tstep: 1600 / 3740 \ttrain loss: 0.0279 \ttrain accuracy: 1.0000 \ttime: 96.9548 s\n",
      "epoch: 11 \tstep: 1650 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 114.4935 s\n",
      "epoch: 11 \tstep: 1700 / 3740 \ttrain loss: 0.0790 \ttrain accuracy: 1.0000 \ttime: 80.8631 s\n",
      "epoch: 11 \tstep: 1750 / 3740 \ttrain loss: 0.0307 \ttrain accuracy: 1.0000 \ttime: 90.5323 s\n",
      "epoch: 11 \tstep: 1800 / 3740 \ttrain loss: 0.5786 \ttrain accuracy: 0.7500 \ttime: 83.0064 s\n",
      "epoch: 11 \tstep: 1850 / 3740 \ttrain loss: 0.0031 \ttrain accuracy: 1.0000 \ttime: 89.5151 s\n",
      "epoch: 11 \tstep: 1900 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 86.2406 s\n",
      "epoch: 11 \tstep: 1950 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 113.7462 s\n",
      "epoch: 11 \tstep: 2000 / 3740 \ttrain loss: 0.1461 \ttrain accuracy: 0.8750 \ttime: 115.6858 s\n",
      "epoch: 11 \tstep: 2050 / 3740 \ttrain loss: 0.0043 \ttrain accuracy: 1.0000 \ttime: 112.2521 s\n",
      "epoch: 11 \tstep: 2100 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 112.3499 s\n",
      "epoch: 11 \tstep: 2150 / 3740 \ttrain loss: 0.0055 \ttrain accuracy: 1.0000 \ttime: 80.6289 s\n",
      "epoch: 11 \tstep: 2200 / 3740 \ttrain loss: 0.0248 \ttrain accuracy: 1.0000 \ttime: 111.7284 s\n",
      "epoch: 11 \tstep: 2250 / 3740 \ttrain loss: 0.3477 \ttrain accuracy: 0.8750 \ttime: 84.2158 s\n",
      "epoch: 11 \tstep: 2300 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 100.7793 s\n",
      "epoch: 11 \tstep: 2350 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 109.4449 s\n",
      "epoch: 11 \tstep: 2400 / 3740 \ttrain loss: 0.0053 \ttrain accuracy: 1.0000 \ttime: 80.8008 s\n",
      "epoch: 11 \tstep: 2450 / 3740 \ttrain loss: 0.0026 \ttrain accuracy: 1.0000 \ttime: 112.7358 s\n",
      "epoch: 11 \tstep: 2500 / 3740 \ttrain loss: 0.1003 \ttrain accuracy: 1.0000 \ttime: 100.2614 s\n",
      "epoch: 11 \tstep: 2550 / 3740 \ttrain loss: 0.0014 \ttrain accuracy: 1.0000 \ttime: 113.9346 s\n",
      "epoch: 11 \tstep: 2600 / 3740 \ttrain loss: 0.0122 \ttrain accuracy: 1.0000 \ttime: 114.6137 s\n",
      "epoch: 11 \tstep: 2650 / 3740 \ttrain loss: 0.0049 \ttrain accuracy: 1.0000 \ttime: 121.6708 s\n",
      "epoch: 11 \tstep: 2700 / 3740 \ttrain loss: 0.0316 \ttrain accuracy: 1.0000 \ttime: 113.1742 s\n",
      "epoch: 11 \tstep: 2750 / 3740 \ttrain loss: 0.1534 \ttrain accuracy: 0.8750 \ttime: 84.7965 s\n",
      "epoch: 11 \tstep: 2800 / 3740 \ttrain loss: 0.0117 \ttrain accuracy: 1.0000 \ttime: 82.7038 s\n",
      "epoch: 11 \tstep: 2850 / 3740 \ttrain loss: 0.0040 \ttrain accuracy: 1.0000 \ttime: 112.0278 s\n",
      "epoch: 11 \tstep: 2900 / 3740 \ttrain loss: 0.4944 \ttrain accuracy: 0.8750 \ttime: 113.7768 s\n",
      "epoch: 11 \tstep: 2950 / 3740 \ttrain loss: 0.0040 \ttrain accuracy: 1.0000 \ttime: 112.6038 s\n",
      "epoch: 11 \tstep: 3000 / 3740 \ttrain loss: 0.0337 \ttrain accuracy: 1.0000 \ttime: 81.9988 s\n",
      "epoch: 11 \tstep: 3050 / 3740 \ttrain loss: 0.3211 \ttrain accuracy: 0.8750 \ttime: 115.3335 s\n",
      "epoch: 11 \tstep: 3100 / 3740 \ttrain loss: 0.0145 \ttrain accuracy: 1.0000 \ttime: 112.6597 s\n",
      "epoch: 11 \tstep: 3150 / 3740 \ttrain loss: 0.1319 \ttrain accuracy: 0.8750 \ttime: 108.0742 s\n",
      "epoch: 11 \tstep: 3200 / 3740 \ttrain loss: 0.0063 \ttrain accuracy: 1.0000 \ttime: 81.0206 s\n",
      "epoch: 11 \tstep: 3250 / 3740 \ttrain loss: 0.4141 \ttrain accuracy: 0.8750 \ttime: 92.2818 s\n",
      "epoch: 11 \tstep: 3300 / 3740 \ttrain loss: 0.1655 \ttrain accuracy: 0.8750 \ttime: 96.0743 s\n",
      "epoch: 11 \tstep: 3350 / 3740 \ttrain loss: 0.0037 \ttrain accuracy: 1.0000 \ttime: 107.1933 s\n",
      "epoch: 11 \tstep: 3400 / 3740 \ttrain loss: 0.0402 \ttrain accuracy: 1.0000 \ttime: 93.1206 s\n",
      "epoch: 11 \tstep: 3450 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 80.7727 s\n",
      "epoch: 11 \tstep: 3500 / 3740 \ttrain loss: 0.0024 \ttrain accuracy: 1.0000 \ttime: 80.9994 s\n",
      "epoch: 11 \tstep: 3550 / 3740 \ttrain loss: 0.0003 \ttrain accuracy: 1.0000 \ttime: 82.6498 s\n",
      "epoch: 11 \tstep: 3600 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 82.6042 s\n",
      "epoch: 11 \tstep: 3650 / 3740 \ttrain loss: 0.0005 \ttrain accuracy: 1.0000 \ttime: 91.4471 s\n",
      "epoch: 11 \tstep: 3700 / 3740 \ttrain loss: 0.0401 \ttrain accuracy: 1.0000 \ttime: 84.7144 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04c786d3c9049a1b4d93c61d905d438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 40 \ttrain loss: 0.0808 \tvalid loss: 0.0612 \ttrain accuracy 0.9741 \tvalid accuracy 0.9820\n",
      "INFO: Early stopping counter 3 of 4\n",
      "epoch: 12 \tstep: 50 / 3740 \ttrain loss: 0.0385 \ttrain accuracy: 1.0000 \ttime: 81.9021 s\n",
      "epoch: 12 \tstep: 100 / 3740 \ttrain loss: 0.0504 \ttrain accuracy: 1.0000 \ttime: 82.7409 s\n",
      "epoch: 12 \tstep: 150 / 3740 \ttrain loss: 0.0787 \ttrain accuracy: 1.0000 \ttime: 81.9677 s\n",
      "epoch: 12 \tstep: 200 / 3740 \ttrain loss: 0.0058 \ttrain accuracy: 1.0000 \ttime: 82.3927 s\n",
      "epoch: 12 \tstep: 250 / 3740 \ttrain loss: 0.0010 \ttrain accuracy: 1.0000 \ttime: 114.1700 s\n",
      "epoch: 12 \tstep: 300 / 3740 \ttrain loss: 0.0930 \ttrain accuracy: 0.8750 \ttime: 84.0315 s\n",
      "epoch: 12 \tstep: 350 / 3740 \ttrain loss: 0.5771 \ttrain accuracy: 0.8750 \ttime: 81.7139 s\n",
      "epoch: 12 \tstep: 400 / 3740 \ttrain loss: 0.0008 \ttrain accuracy: 1.0000 \ttime: 85.0683 s\n",
      "epoch: 12 \tstep: 450 / 3740 \ttrain loss: 0.0054 \ttrain accuracy: 1.0000 \ttime: 83.4876 s\n",
      "epoch: 12 \tstep: 500 / 3740 \ttrain loss: 0.0029 \ttrain accuracy: 1.0000 \ttime: 83.0641 s\n",
      "epoch: 12 \tstep: 550 / 3740 \ttrain loss: 0.0494 \ttrain accuracy: 1.0000 \ttime: 112.3709 s\n",
      "epoch: 12 \tstep: 600 / 3740 \ttrain loss: 0.0754 \ttrain accuracy: 1.0000 \ttime: 106.1242 s\n",
      "epoch: 12 \tstep: 650 / 3740 \ttrain loss: 0.0120 \ttrain accuracy: 1.0000 \ttime: 81.8145 s\n",
      "epoch: 12 \tstep: 700 / 3740 \ttrain loss: 0.0147 \ttrain accuracy: 1.0000 \ttime: 114.0259 s\n",
      "epoch: 12 \tstep: 750 / 3740 \ttrain loss: 0.2551 \ttrain accuracy: 0.8750 \ttime: 81.5624 s\n",
      "epoch: 12 \tstep: 800 / 3740 \ttrain loss: 0.0028 \ttrain accuracy: 1.0000 \ttime: 89.4266 s\n",
      "epoch: 12 \tstep: 850 / 3740 \ttrain loss: 0.0011 \ttrain accuracy: 1.0000 \ttime: 110.0691 s\n",
      "epoch: 12 \tstep: 900 / 3740 \ttrain loss: 0.0156 \ttrain accuracy: 1.0000 \ttime: 149.7850 s\n",
      "epoch: 12 \tstep: 950 / 3740 \ttrain loss: 0.0053 \ttrain accuracy: 1.0000 \ttime: 169.7206 s\n",
      "epoch: 12 \tstep: 1000 / 3740 \ttrain loss: 0.1586 \ttrain accuracy: 0.8750 \ttime: 92.9081 s\n",
      "epoch: 12 \tstep: 1050 / 3740 \ttrain loss: 0.0012 \ttrain accuracy: 1.0000 \ttime: 114.7580 s\n",
      "epoch: 12 \tstep: 1100 / 3740 \ttrain loss: 0.0087 \ttrain accuracy: 1.0000 \ttime: 116.4619 s\n",
      "epoch: 12 \tstep: 1150 / 3740 \ttrain loss: 0.0075 \ttrain accuracy: 1.0000 \ttime: 118.8423 s\n",
      "epoch: 12 \tstep: 1200 / 3740 \ttrain loss: 0.0020 \ttrain accuracy: 1.0000 \ttime: 166.6952 s\n",
      "epoch: 12 \tstep: 1250 / 3740 \ttrain loss: 0.0014 \ttrain accuracy: 1.0000 \ttime: 177.2395 s\n",
      "epoch: 12 \tstep: 1300 / 3740 \ttrain loss: 0.0021 \ttrain accuracy: 1.0000 \ttime: 80.9977 s\n",
      "epoch: 12 \tstep: 1350 / 3740 \ttrain loss: 0.0006 \ttrain accuracy: 1.0000 \ttime: 81.6875 s\n",
      "epoch: 12 \tstep: 1400 / 3740 \ttrain loss: 0.1753 \ttrain accuracy: 0.8750 \ttime: 83.6823 s\n",
      "epoch: 12 \tstep: 1450 / 3740 \ttrain loss: 0.0002 \ttrain accuracy: 1.0000 \ttime: 80.5572 s\n",
      "epoch: 12 \tstep: 1500 / 3740 \ttrain loss: 0.1787 \ttrain accuracy: 0.8750 \ttime: 80.5351 s\n",
      "epoch: 12 \tstep: 1550 / 3740 \ttrain loss: 0.0014 \ttrain accuracy: 1.0000 \ttime: 82.5231 s\n",
      "epoch: 12 \tstep: 1600 / 3740 \ttrain loss: 0.0009 \ttrain accuracy: 1.0000 \ttime: 97.9107 s\n",
      "epoch: 12 \tstep: 1650 / 3740 \ttrain loss: 0.0014 \ttrain accuracy: 1.0000 \ttime: 96.1447 s\n",
      "epoch: 12 \tstep: 1700 / 3740 \ttrain loss: 0.0031 \ttrain accuracy: 1.0000 \ttime: 82.6033 s\n",
      "epoch: 12 \tstep: 1750 / 3740 \ttrain loss: 0.0007 \ttrain accuracy: 1.0000 \ttime: 81.9901 s\n",
      "epoch: 12 \tstep: 1800 / 3740 \ttrain loss: 0.0085 \ttrain accuracy: 1.0000 \ttime: 102.4744 s\n",
      "epoch: 12 \tstep: 1850 / 3740 \ttrain loss: 0.0803 \ttrain accuracy: 1.0000 \ttime: 83.2593 s\n",
      "epoch: 12 \tstep: 1900 / 3740 \ttrain loss: 0.0015 \ttrain accuracy: 1.0000 \ttime: 112.0251 s\n",
      "epoch: 12 \tstep: 1950 / 3740 \ttrain loss: 0.3274 \ttrain accuracy: 0.8750 \ttime: 81.7371 s\n",
      "epoch: 12 \tstep: 2000 / 3740 \ttrain loss: 0.0371 \ttrain accuracy: 1.0000 \ttime: 89.5404 s\n",
      "epoch: 12 \tstep: 2050 / 3740 \ttrain loss: 0.0172 \ttrain accuracy: 1.0000 \ttime: 98.6668 s\n",
      "epoch: 12 \tstep: 2100 / 3740 \ttrain loss: 0.0032 \ttrain accuracy: 1.0000 \ttime: 103.2885 s\n",
      "epoch: 12 \tstep: 2150 / 3740 \ttrain loss: 0.1299 \ttrain accuracy: 1.0000 \ttime: 80.7657 s\n",
      "epoch: 12 \tstep: 2200 / 3740 \ttrain loss: 0.0054 \ttrain accuracy: 1.0000 \ttime: 81.3688 s\n",
      "epoch: 12 \tstep: 2250 / 3740 \ttrain loss: 0.0023 \ttrain accuracy: 1.0000 \ttime: 113.2216 s\n",
      "epoch: 12 \tstep: 2300 / 3740 \ttrain loss: 0.0150 \ttrain accuracy: 1.0000 \ttime: 82.3989 s\n",
      "epoch: 12 \tstep: 2350 / 3740 \ttrain loss: 0.0017 \ttrain accuracy: 1.0000 \ttime: 148.2878 s\n",
      "epoch: 12 \tstep: 2400 / 3740 \ttrain loss: 0.0343 \ttrain accuracy: 1.0000 \ttime: 132.9551 s\n",
      "epoch: 12 \tstep: 2450 / 3740 \ttrain loss: 0.0020 \ttrain accuracy: 1.0000 \ttime: 132.1000 s\n",
      "epoch: 12 \tstep: 2500 / 3740 \ttrain loss: 0.0092 \ttrain accuracy: 1.0000 \ttime: 89.3318 s\n",
      "epoch: 12 \tstep: 2550 / 3740 \ttrain loss: 0.0027 \ttrain accuracy: 1.0000 \ttime: 133.9099 s\n",
      "epoch: 12 \tstep: 2600 / 3740 \ttrain loss: 0.0982 \ttrain accuracy: 0.8750 \ttime: 106.7256 s\n",
      "epoch: 12 \tstep: 2650 / 3740 \ttrain loss: 0.0506 \ttrain accuracy: 1.0000 \ttime: 88.5213 s\n",
      "epoch: 12 \tstep: 2700 / 3740 \ttrain loss: 0.0069 \ttrain accuracy: 1.0000 \ttime: 89.5123 s\n",
      "epoch: 12 \tstep: 2750 / 3740 \ttrain loss: 0.0088 \ttrain accuracy: 1.0000 \ttime: 90.2978 s\n",
      "epoch: 12 \tstep: 2800 / 3740 \ttrain loss: 0.0004 \ttrain accuracy: 1.0000 \ttime: 70.1670 s\n",
      "epoch: 12 \tstep: 2850 / 3740 \ttrain loss: 0.0459 \ttrain accuracy: 1.0000 \ttime: 68.9738 s\n",
      "epoch: 12 \tstep: 2900 / 3740 \ttrain loss: 0.0123 \ttrain accuracy: 1.0000 \ttime: 69.2577 s\n",
      "epoch: 12 \tstep: 2950 / 3740 \ttrain loss: 0.0210 \ttrain accuracy: 1.0000 \ttime: 90.7547 s\n",
      "epoch: 12 \tstep: 3000 / 3740 \ttrain loss: 0.0050 \ttrain accuracy: 1.0000 \ttime: 91.6658 s\n",
      "epoch: 12 \tstep: 3050 / 3740 \ttrain loss: 0.0212 \ttrain accuracy: 1.0000 \ttime: 96.0620 s\n",
      "epoch: 12 \tstep: 3100 / 3740 \ttrain loss: 0.0106 \ttrain accuracy: 1.0000 \ttime: 71.1331 s\n",
      "epoch: 12 \tstep: 3150 / 3740 \ttrain loss: 0.0090 \ttrain accuracy: 1.0000 \ttime: 89.1420 s\n",
      "epoch: 12 \tstep: 3200 / 3740 \ttrain loss: 0.2423 \ttrain accuracy: 0.8750 \ttime: 28025.6994 s\n",
      "epoch: 12 \tstep: 3250 / 3740 \ttrain loss: 0.0435 \ttrain accuracy: 1.0000 \ttime: 90.6321 s\n",
      "epoch: 12 \tstep: 3300 / 3740 \ttrain loss: 0.0050 \ttrain accuracy: 1.0000 \ttime: 151.2154 s\n",
      "epoch: 12 \tstep: 3350 / 3740 \ttrain loss: 0.1477 \ttrain accuracy: 0.8750 \ttime: 131.5182 s\n",
      "epoch: 12 \tstep: 3400 / 3740 \ttrain loss: 0.0038 \ttrain accuracy: 1.0000 \ttime: 99.8783 s\n",
      "epoch: 12 \tstep: 3450 / 3740 \ttrain loss: 0.0784 \ttrain accuracy: 1.0000 \ttime: 69.3998 s\n",
      "epoch: 12 \tstep: 3500 / 3740 \ttrain loss: 0.0094 \ttrain accuracy: 1.0000 \ttime: 90.7737 s\n",
      "epoch: 12 \tstep: 3550 / 3740 \ttrain loss: 0.0154 \ttrain accuracy: 1.0000 \ttime: 76.9492 s\n",
      "epoch: 12 \tstep: 3600 / 3740 \ttrain loss: 0.0036 \ttrain accuracy: 1.0000 \ttime: 76.2759 s\n",
      "epoch: 12 \tstep: 3650 / 3740 \ttrain loss: 0.1644 \ttrain accuracy: 0.8750 \ttime: 83.6207 s\n",
      "epoch: 12 \tstep: 3700 / 3740 \ttrain loss: 0.0026 \ttrain accuracy: 1.0000 \ttime: 83.1522 s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b653e226254b7e9bb600d2b260d10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 40 \ttrain loss: 0.0735 \tvalid loss: 0.0562 \ttrain accuracy 0.9763 \tvalid accuracy 0.9836\n",
      "INFO: Early stopping counter 4 of 4\n",
      "INFO: Early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130e6a81f69a447e8d15413173c92bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest loss: 0.0614 \ttest accuracy 0.9812\n"
     ]
    }
   ],
   "source": [
    "run(roberta, print_freq=500)  # cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5c91bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_bert_accuracy = 0.9812  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d8d7f1",
   "metadata": {},
   "source": [
    "__Вывод:__ Модель с использованием тязыковой модели BERT, показала метрику accuracy = 0.9812 на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768145ee",
   "metadata": {},
   "source": [
    "## Итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "347bcb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.9824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bidirectional_LSTM</td>\n",
       "      <td>0.9774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM_PackedSequence</td>\n",
       "      <td>0.9826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transformers + BERT</td>\n",
       "      <td>0.9812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  accuracy\n",
       "0                  CNN    0.9824\n",
       "1   Bidirectional_LSTM    0.9774\n",
       "2  LSTM_PackedSequence    0.9826\n",
       "3  Transformers + BERT    0.9812"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# соберем результаты в таблицу\n",
    "model_name = ['CNN',\\\n",
    "              'Bidirectional_LSTM', \n",
    "              'LSTM_PackedSequence',\n",
    "              'Transformers + BERT']\n",
    "\n",
    "accuracy = [cnn_accuracy, \n",
    "            lstm_accuracy, \n",
    "            lstm_packed_accuracy, \n",
    "            transformers_bert_accuracy]\n",
    "\n",
    "result = pd.DataFrame({'Model': model_name,\n",
    "                        'accuracy': accuracy})\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f47021",
   "metadata": {},
   "source": [
    "__Вывод:__ \n",
    "\n",
    "Нами были протестированная модель CNN, Bidirectional_LSTM, LSTM+PackedSequence, Transformers + BERT. \n",
    "\n",
    "Лучше всего тебя показала модель LSTM+PackedSequence. Удалось добиться метрики accuracy=0.9826."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9d0ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
