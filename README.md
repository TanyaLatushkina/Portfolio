1) В ходе работы нам были предоставлены 4-и датасета.

base.csv - анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.

train.csv - обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …) , вектор признаков И id товара из base.csv, который максимально похож на него (по мнению экспертов).

validation.csv - датасет с товарами (уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из base.csv

validation_answer.csv - правильные ответы к предыдущему файлу

2) Данный хорошо подготовлены, отсутствуют пропуска и дубликаты. Все признаки кроме 6 21 25 33 44 59 65 70 имеют нормальное распределение. Встречаются как отрицальные, так и положительные, большой разброс зрначений.

Данные состоящие из 71 признаков и 2918139 записей в base. Train и valid bvttn 100000 значений.

Изучили признак 33, он имеет 1568 уникальных значений. Это явно категориальный признак. Сложно предположить, что за категория, это явно не цвет и не размер. Возможно это город изготовления товара.

3) Была проведена подготовка данных, а именно: убрали категориальные данные, которые плохо влияли на мерику, изменили тип данныех, записали название признаков в нижнем регистре, перезаписали index. Для масштабирования данных был применен RobustScaler, он показал себя лучше при анализе метрики. Подобрали число кластеров для Faiss.

4) Для нахождения 5-ти вариантов наиболее похожих товаров из base для train выборки. Была применина библиотека Faiss. Для этого мы воспользовались методом IndexHNSWFlat. k_neighbors = 10, nprobe = 10. Обучили индекс на base. На тренировочной выборке удалось добиться метрику accurasy@5 = 71.95.

5) При использовании бибилиотеки Faiss для нахождения 5-ти вариантов нахождения наиболее похожих товаров из base для valid выборки мы применили метод IndexHNSWFlat, с параметрами k_neighbors = 10, nprobe = 10. На валидационной выборке удалось добиться метрики accurasy@5 = 71.8.

​
